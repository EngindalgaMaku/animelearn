{
  "categories": [
    {
      "name": "Data Science",
      "slug": "data-science",
      "color": "#14B8A6",
      "icon": "üìà",
      "description": "Python for data analysis and machine learning",
      "isActive": true
    },
    {
      "name": "Advanced Python",
      "slug": "advanced-python",
      "color": "#F44336",
      "icon": "üî¥",
      "description": "Advanced Python concepts and techniques",
      "isActive": true
    },
    {
      "name": "Python Basics",
      "slug": "python-basics",
      "color": "#10B981",
      "icon": "üêç",
      "description": "Fundamental Python concepts for beginners",
      "isActive": true
    },
    {
      "name": "Code Tricks",
      "slug": "code-tricks",
      "color": "#FF9800",
      "icon": "‚ö°",
      "description": "Python tricks and one-liners",
      "isActive": true
    },
    {
      "name": "Best Practices",
      "slug": "best-practices",
      "color": "#06B6D4",
      "icon": "‚ú®",
      "description": "Python coding best practices and tips",
      "isActive": true
    },
    {
      "name": "Data Structures",
      "slug": "data-structures",
      "color": "#3B82F6",
      "icon": "üìä",
      "description": "Lists, dictionaries, sets, and tuples",
      "isActive": true
    },
    {
      "name": "Functions & Modules",
      "slug": "functions-modules",
      "color": "#8B5CF6",
      "icon": "‚öôÔ∏è",
      "description": "Functions, parameters, and importing modules",
      "isActive": true
    },
    {
      "name": "Object-Oriented Programming",
      "slug": "oop",
      "color": "#F59E0B",
      "icon": "üèóÔ∏è",
      "description": "Classes, objects, inheritance, and polymorphism",
      "isActive": true
    },
    {
      "name": "File Operations",
      "slug": "file-operations",
      "color": "#EF4444",
      "icon": "üìÅ",
      "description": "Reading and writing files in Python",
      "isActive": true
    },
    {
      "name": "Web Development",
      "slug": "web-development",
      "color": "#EC4899",
      "icon": "üåê",
      "description": "Python for web development and APIs",
      "isActive": true
    },
    {
      "name": "Testing & Debugging",
      "slug": "testing-debugging",
      "color": "#F97316",
      "icon": "üîß",
      "description": "Testing, debugging, and code quality",
      "isActive": true
    },
    {
      "name": "Performance & Optimization",
      "slug": "performance",
      "color": "#84CC16",
      "icon": "‚ö°",
      "description": "Optimizing Python code for better performance",
      "isActive": true
    }
  ],
  "tips": [
    {
      "title": "Python List Comprehensions",
      "content": "List comprehensions provide a concise way to create lists. They are more readable and often faster than traditional for loops.",
      "codeExample": "# Traditional way\nsquares = []\nfor i in range(10):\n    squares.append(i**2)\n\n# List comprehension - more Pythonic\nsquares = [i**2 for i in range(10)]\n\n# With condition\neven_squares = [i**2 for i in range(10) if i % 2 == 0]\n\nprint(squares)  # [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]",
      "difficulty": "beginner",
      "categorySlug": "python-basics",
      "xpReward": 15,
      "tags": [
        "list-comprehension",
        "loops",
        "python-basics"
      ],
      "estimatedMinutes": 3,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "python-list-comprehensions",
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:27:59.685Z"
    },
    {
      "title": "F-Strings for String Formatting",
      "content": "F-strings (formatted string literals) are the modern and preferred way to format strings in Python 3.6+.",
      "codeExample": "name = \"Python\"\nversion = 3.11\nscore = 95.5\n\n# F-string formatting\nmessage = f\"Hello, {name} {version}!\"\nprint(message)  # Hello, Python 3.11!\n\n# With expressions\nresult = f\"Score: {score:.1f}% ({score/100:.2%})\"\nprint(result)  # Score: 95.5% (95.50%)\n\n# Multi-line f-strings\ninfo = f\"\"\"\nName: {name}\nVersion: {version}\nScore: {score}%\n\"\"\"",
      "difficulty": "beginner",
      "categorySlug": "python-basics",
      "xpReward": 12,
      "tags": [
        "f-strings",
        "string-formatting",
        "python-3.6"
      ],
      "estimatedMinutes": 2,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "f-strings-for-string-formatting",
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:27:59.878Z"
    },
    {
      "title": "Dictionary Merge in Python 3.9+",
      "content": "Python 3.9 introduced the merge (|) and update (|=) operators for dictionaries.",
      "codeExample": "# Python 3.9+ dictionary merge operators\ndict1 = {\"a\": 1, \"b\": 2}\ndict2 = {\"c\": 3, \"d\": 4}\ndict3 = {\"b\": 20, \"e\": 5}\n\n# Merge dictionaries (creates new dict)\nmerged = dict1 | dict2 | dict3\nprint(merged)  # {\"a\": 1, \"b\": 20, \"c\": 3, \"d\": 4, \"e\": 5}\n\n# Update in-place\ndict1 |= dict2\nprint(dict1)  # {\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4}\n\n# Before Python 3.9\nmerged_old = {**dict1, **dict2, **dict3}",
      "difficulty": "intermediate",
      "categorySlug": "code-tricks",
      "xpReward": 18,
      "tags": [
        "dictionaries",
        "python-3.9",
        "merge",
        "operators"
      ],
      "estimatedMinutes": 3,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "dictionary-merge-in-python-3-9",
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:27:59.972Z"
    },
    {
      "title": "Context Managers and \"with\" Statement",
      "content": "Context managers ensure proper resource management and cleanup using the \"with\" statement.",
      "codeExample": "# File handling with context manager\nwith open('example.txt', 'r') as file:\n    content = file.read()\n# File is automatically closed\n\n# Custom context manager\nfrom contextlib import contextmanager\n\n@contextmanager\ndef timer():\n    import time\n    start = time.time()\n    try:\n        yield\n    finally:\n        end = time.time()\n        print(f\"Time taken: {end - start:.2f} seconds\")\n\n# Usage\nwith timer():\n    # Some time-consuming operation\n    import time\n    time.sleep(1)",
      "difficulty": "advanced",
      "categorySlug": "advanced-python",
      "xpReward": 25,
      "tags": [
        "context-managers",
        "with-statement",
        "resource-management"
      ],
      "estimatedMinutes": 5,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "context-managers-and-with-statement",
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:28:00.071Z"
    },
    {
      "title": "Enumerate vs Range",
      "content": "Use enumerate() instead of range(len()) when you need both index and value.",
      "codeExample": "fruits = ['apple', 'banana', 'cherry']\n\n# ‚ùå Not Pythonic\nfor i in range(len(fruits)):\n    print(f\"{i}: {fruits[i]}\")\n\n# ‚úÖ Pythonic way\nfor i, fruit in enumerate(fruits):\n    print(f\"{i}: {fruit}\")\n\n# With custom start value\nfor i, fruit in enumerate(fruits, start=1):\n    print(f\"{i}: {fruit}\")\n\n# Output:\n# 1: apple\n# 2: banana  \n# 3: cherry",
      "difficulty": "beginner",
      "categorySlug": "best-practices",
      "xpReward": 10,
      "tags": [
        "enumerate",
        "loops",
        "best-practices",
        "pythonic"
      ],
      "estimatedMinutes": 2,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "enumerate-vs-range",
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:28:00.163Z"
    },
    {
      "title": "Pandas DataFrame Quick Tips",
      "content": "Essential pandas operations for data manipulation and analysis.",
      "codeExample": "import pandas as pd\n\n# Create DataFrame\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'age': [25, 30, 35],\n    'city': ['NY', 'LA', 'Chicago']\n}\ndf = pd.DataFrame(data)\n\n# Quick info\nprint(df.info())\nprint(df.describe())\n\n# Filter data\nyoung_people = df[df['age'] < 30]\n\n# Group and aggregate\ncity_stats = df.groupby('city')['age'].agg(['mean', 'count'])\n\n# Chain operations\nresult = (df\n    .query('age > 25')\n    .sort_values('age')\n    .reset_index(drop=True)\n)",
      "difficulty": "intermediate",
      "categorySlug": "data-science",
      "xpReward": 20,
      "tags": [
        "pandas",
        "dataframe",
        "data-science",
        "analysis"
      ],
      "estimatedMinutes": 4,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "pandas-dataframe-quick-tips",
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:28:00.263Z"
    },
    {
      "title": "Understanding Python Variables",
      "content": "In Python, variables are containers for storing data values. Unlike other programming languages, Python has no command for declaring a variable. A variable is created the moment you first assign a value to it. Python is dynamically typed, which means you don't need to specify the data type.",
      "codeExample": "# Creating variables\nname = \"Alice\"\nage = 25\nheight = 5.7\nis_student = True\n\n# Python automatically determines the type\nprint(type(name))    # <class 'str'>\nprint(type(age))     # <class 'int'>\nprint(type(height))  # <class 'float'>\nprint(type(is_student)) # <class 'bool'>",
      "difficulty": "beginner",
      "categorySlug": "python-basics",
      "xpReward": 10,
      "tags": [
        "variables",
        "types",
        "basics"
      ],
      "estimatedMinutes": 3,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "understanding-python-variables",
      "metaDescription": "In Python, variables are containers for storing data values. Unlike other programming languages, Python has no command for declaring a variable. A variable is c...",
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:30:46.821Z"
    },
    {
      "title": "Python String Formatting Made Easy",
      "content": "Python offers several ways to format strings. The most modern and readable approach is using f-strings (formatted string literals), introduced in Python 3.6. F-strings provide a concise and readable way to include expressions inside string literals.",
      "codeExample": "# F-string formatting (Python 3.6+)\nname = \"Bob\"\nage = 30\nscore = 95.5\n\n# Clean and readable\nmessage = f\"Hello {name}, you are {age} years old and scored {score:.1f}%\"\nprint(message)\n\n# You can even include expressions\nprint(f\"Next year, {name} will be {age + 1} years old\")\n\n# Older methods (still valid but less preferred)\nmessage_old = \"Hello {}, you are {} years old\".format(name, age)\nmessage_oldest = \"Hello %s, you are %d years old\" % (name, age)",
      "difficulty": "beginner",
      "categorySlug": "python-basics",
      "xpReward": 15,
      "tags": [
        "strings",
        "formatting",
        "f-strings"
      ],
      "estimatedMinutes": 4,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "python-string-formatting-made-easy",
      "metaDescription": "Python offers several ways to format strings. The most modern and readable approach is using f-strings (formatted string literals), introduced in Python 3.6. F-...",
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:30:47.019Z"
    },
    {
      "title": "List Comprehensions: Pythonic Way to Create Lists",
      "content": "List comprehensions provide a concise way to create lists. They're more readable and often faster than traditional for loops. The basic syntax is: [expression for item in iterable if condition]",
      "codeExample": "# Traditional way with for loop\nsquares = []\nfor x in range(10):\n    squares.append(x**2)\n\n# List comprehension - more Pythonic!\nsquares = [x**2 for x in range(10)]\n\n# With condition\neven_squares = [x**2 for x in range(10) if x % 2 == 0]\n\n# Nested loops\nmatrix = [[i*j for j in range(3)] for i in range(3)]\n\n# Working with strings\nwords = [\"hello\", \"world\", \"python\", \"programming\"]\nlengths = [len(word) for word in words]\nuppercase = [word.upper() for word in words if len(word) > 5]",
      "difficulty": "intermediate",
      "categorySlug": "data-structures",
      "xpReward": 20,
      "tags": [
        "lists",
        "comprehensions",
        "loops"
      ],
      "estimatedMinutes": 5,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "list-comprehensions-pythonic-way-to-create-lists",
      "metaDescription": "List comprehensions provide a concise way to create lists. They're more readable and often faster than traditional for loops. The basic syntax is: [expression f...",
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:30:47.115Z"
    },
    {
      "title": "Dictionary Tricks and Best Practices",
      "content": "Dictionaries are one of Python's most powerful data structures. Here are some advanced techniques to work with them more effectively, including the get() method, dictionary comprehensions, and merging dictionaries.",
      "codeExample": "# Safe access with get() method\nuser = {\"name\": \"Alice\", \"age\": 25}\nemail = user.get(\"email\", \"No email provided\")  # Returns default if key missing\n\n# Dictionary comprehensions\nsquares_dict = {x: x**2 for x in range(5)}\nfiltered_dict = {k: v for k, v in user.items() if k != \"age\"}\n\n# Merging dictionaries (Python 3.9+)\ndict1 = {\"a\": 1, \"b\": 2}\ndict2 = {\"c\": 3, \"d\": 4}\nmerged = dict1 | dict2  # New in Python 3.9\n\n# For older Python versions\nmerged_old = {**dict1, **dict2}\n\n# Counter for counting items\nfrom collections import Counter\ntext = \"hello world\"\nletter_count = Counter(text)\nprint(letter_count)  # Counter({'l': 3, 'o': 2, 'h': 1, ...})",
      "difficulty": "intermediate",
      "categorySlug": "data-structures",
      "xpReward": 18,
      "tags": [
        "dictionaries",
        "collections",
        "data-structures"
      ],
      "estimatedMinutes": 6,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "dictionary-tricks-and-best-practices",
      "metaDescription": "Dictionaries are one of Python's most powerful data structures. Here are some advanced techniques to work with them more effectively, including the get() method...",
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:30:47.211Z"
    },
    {
      "title": "Function Parameters: *args and **kwargs Explained",
      "content": "Understanding *args and **kwargs is crucial for writing flexible Python functions. *args allows a function to accept any number of positional arguments, while **kwargs allows any number of keyword arguments.",
      "codeExample": "# Basic function with *args\ndef sum_all(*args):\n    return sum(args)\n\nprint(sum_all(1, 2, 3, 4, 5))  # 15\n\n# Function with **kwargs\ndef print_info(**kwargs):\n    for key, value in kwargs.items():\n        print(f\"{key}: {value}\")\n\nprint_info(name=\"Alice\", age=30, city=\"New York\")\n\n# Combining both\ndef flexible_function(required_param, *args, **kwargs):\n    print(f\"Required: {required_param}\")\n    print(f\"Extra positional args: {args}\")\n    print(f\"Keyword args: {kwargs}\")\n\nflexible_function(\"Hello\", 1, 2, 3, name=\"Bob\", age=25)\n\n# Unpacking arguments\nnumbers = [1, 2, 3, 4, 5]\nprint(sum_all(*numbers))  # Unpacking list\n\ninfo = {\"name\": \"Charlie\", \"age\": 35}\nprint_info(**info)  # Unpacking dictionary",
      "difficulty": "advanced",
      "categorySlug": "functions-modules",
      "xpReward": 25,
      "tags": [
        "functions",
        "parameters",
        "args",
        "kwargs"
      ],
      "estimatedMinutes": 7,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "function-parameters-args-and-kwargs-explained",
      "metaDescription": "Understanding *args and **kwargs is crucial for writing flexible Python functions. *args allows a function to accept any number of positional arguments, while *...",
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:30:47.308Z"
    },
    {
      "title": "Class Properties and Decorators",
      "content": "Python's @property decorator allows you to define methods that can be accessed like attributes. This is useful for data validation, computed properties, and maintaining backward compatibility when refactoring.",
      "codeExample": "class Temperature:\n    def __init__(self, celsius=0):\n        self._celsius = celsius\n    \n    @property\n    def celsius(self):\n        return self._celsius\n    \n    @celsius.setter\n    def celsius(self, value):\n        if value < -273.15:\n            raise ValueError(\"Temperature below absolute zero is not possible\")\n        self._celsius = value\n    \n    @property\n    def fahrenheit(self):\n        return (self._celsius * 9/5) + 32\n    \n    @fahrenheit.setter\n    def fahrenheit(self, value):\n        self.celsius = (value - 32) * 5/9\n    \n    @property\n    def kelvin(self):\n        return self._celsius + 273.15\n\n# Usage\ntemp = Temperature(25)\nprint(f\"Celsius: {temp.celsius}¬∞C\")\nprint(f\"Fahrenheit: {temp.fahrenheit}¬∞F\")\nprint(f\"Kelvin: {temp.kelvin}K\")\n\ntemp.fahrenheit = 100  # Sets celsius internally\nprint(f\"New Celsius: {temp.celsius}¬∞C\")",
      "difficulty": "advanced",
      "categorySlug": "oop",
      "xpReward": 30,
      "tags": [
        "classes",
        "properties",
        "decorators",
        "oop"
      ],
      "estimatedMinutes": 8,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "class-properties-and-decorators",
      "metaDescription": "Python's @property decorator allows you to define methods that can be accessed like attributes. This is useful for data validation, computed properties, and mai...",
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:30:47.405Z"
    },
    {
      "title": "Context Managers and File Handling",
      "content": "The 'with' statement in Python is used to create context managers that automatically handle resource cleanup. This is especially useful for file operations, ensuring files are properly closed even if an error occurs.",
      "codeExample": "# Proper way to handle files\nwith open('example.txt', 'w') as file:\n    file.write('Hello, World!')\n# File is automatically closed here, even if an error occurred\n\n# Reading files safely\ntry:\n    with open('data.txt', 'r') as file:\n        content = file.read()\n        print(content)\nexcept FileNotFoundError:\n    print(\"File not found!\")\n\n# Creating your own context manager\nclass DatabaseConnection:\n    def __enter__(self):\n        print(\"Connecting to database...\")\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        print(\"Closing database connection...\")\n        if exc_type:\n            print(f\"An error occurred: {exc_val}\")\n    \n    def query(self, sql):\n        return f\"Executing: {sql}\"\n\n# Using custom context manager\nwith DatabaseConnection() as db:\n    result = db.query(\"SELECT * FROM users\")\n    print(result)",
      "difficulty": "intermediate",
      "categorySlug": "file-operations",
      "xpReward": 22,
      "tags": [
        "files",
        "context-managers",
        "with-statement"
      ],
      "estimatedMinutes": 6,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "context-managers-and-file-handling",
      "metaDescription": "The 'with' statement in Python is used to create context managers that automatically handle resource cleanup. This is especially useful for file operations, ens...",
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:30:47.544Z"
    },
    {
      "title": "Python Naming Conventions and PEP 8",
      "content": "Following Python's naming conventions makes your code more readable and maintainable. PEP 8 is the official style guide for Python code and provides guidelines for naming variables, functions, classes, and more.",
      "codeExample": "# Variables and functions: snake_case\nuser_name = \"alice\"\ntotal_score = 100\n\ndef calculate_average(numbers):\n    return sum(numbers) / len(numbers)\n\n# Classes: PascalCase\nclass UserAccount:\n    def __init__(self, username):\n        self.username = username\n        self._private_data = []  # Single underscore for \"internal use\"\n        self.__secret = \"hidden\"  # Double underscore for name mangling\n\n# Constants: UPPER_CASE\nMAX_CONNECTIONS = 100\nAPI_BASE_URL = \"https://api.example.com\"\n\n# Modules and packages: lowercase with underscores\nimport json_parser\nfrom my_package import utility_functions\n\n# Avoid these naming patterns:\n# - Single character names (except for loops: i, j, k)\n# - Names that are too similar: data1, data2\n# - Built-in names: list, dict, str, etc.\n\n# Good naming examples\ndef get_user_by_id(user_id):\n    pass\n\nclass EmailValidator:\n    pass\n\nTIMEOUT_SECONDS = 30",
      "difficulty": "beginner",
      "categorySlug": "best-practices",
      "xpReward": 12,
      "tags": [
        "pep8",
        "naming",
        "conventions",
        "style"
      ],
      "estimatedMinutes": 4,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "python-naming-conventions-and-pep-8",
      "metaDescription": "Following Python's naming conventions makes your code more readable and maintainable. PEP 8 is the official style guide for Python code and provides guidelines ...",
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:30:47.641Z"
    },
    {
      "title": "Error Handling Best Practices",
      "content": "Proper error handling is crucial for writing robust Python applications. Use specific exception types, avoid bare except clauses, and always clean up resources properly.",
      "codeExample": "# Specific exception handling\ndef divide_numbers(a, b):\n    try:\n        result = a / b\n        return result\n    except ZeroDivisionError:\n        print(\"Cannot divide by zero!\")\n        return None\n    except TypeError:\n        print(\"Both arguments must be numbers!\")\n        return None\n\n# Multiple exceptions\ndef process_data(filename):\n    try:\n        with open(filename, 'r') as file:\n            data = json.load(file)\n            return data['results']\n    except FileNotFoundError:\n        print(f\"File {filename} not found\")\n    except json.JSONDecodeError:\n        print(\"Invalid JSON format\")\n    except KeyError as e:\n        print(f\"Missing key: {e}\")\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        raise  # Re-raise for debugging\n\n# Using finally for cleanup\ndef risky_operation():\n    resource = None\n    try:\n        resource = acquire_resource()\n        # Do something risky\n        return process(resource)\n    except Exception as e:\n        log_error(e)\n        raise\n    finally:\n        if resource:\n            cleanup_resource(resource)\n\n# Custom exceptions\nclass ValidationError(Exception):\n    \"\"\"Raised when data validation fails\"\"\"\n    pass\n\ndef validate_email(email):\n    if '@' not in email:\n        raise ValidationError(f\"Invalid email format: {email}\")",
      "difficulty": "intermediate",
      "categorySlug": "best-practices",
      "xpReward": 20,
      "tags": [
        "exceptions",
        "error-handling",
        "try-except"
      ],
      "estimatedMinutes": 7,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "error-handling-best-practices",
      "metaDescription": "Proper error handling is crucial for writing robust Python applications. Use specific exception types, avoid bare except clauses, and always clean up resources ...",
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:30:47.733Z"
    },
    {
      "title": "Python Generators and Memory Efficiency",
      "content": "Generators are a powerful feature for creating memory-efficient iterators. They generate values on-demand instead of storing everything in memory, making them perfect for processing large datasets.",
      "codeExample": "# Generator function with yield\ndef fibonacci_generator(n):\n    a, b = 0, 1\n    count = 0\n    while count < n:\n        yield a\n        a, b = b, a + b\n        count += 1\n\n# Using the generator\nfib = fibonacci_generator(10)\nfor num in fib:\n    print(num, end=\" \")\n\n# Generator expressions (like list comprehensions)\nsquares_gen = (x**2 for x in range(1000000))  # Memory efficient!\nsquares_list = [x**2 for x in range(1000000)]  # Uses lots of memory\n\n# Reading large files efficiently\ndef read_large_file(file_path):\n    with open(file_path, 'r') as file:\n        for line in file:\n            yield line.strip()\n\n# Processing data in chunks\ndef process_data_stream(data_source):\n    batch = []\n    for item in data_source:\n        batch.append(item)\n        if len(batch) >= 100:  # Process in batches of 100\n            yield batch\n            batch = []\n    if batch:  # Don't forget the last batch\n        yield batch\n\n# Generator vs List comparison\nimport sys\ngen = (x for x in range(1000))\nlst = [x for x in range(1000)]\nprint(f\"Generator size: {sys.getsizeof(gen)} bytes\")\nprint(f\"List size: {sys.getsizeof(lst)} bytes\")",
      "difficulty": "advanced",
      "categorySlug": "best-practices",
      "xpReward": 28,
      "tags": [
        "generators",
        "yield",
        "memory",
        "efficiency"
      ],
      "estimatedMinutes": 8,
      "prerequisites": [],
      "relatedTips": [],
      "slug": "python-generators-and-memory-efficiency",
      "metaDescription": "Generators are a powerful feature for creating memory-efficient iterators. They generate values on-demand instead of storing everything in memory, making them p...",
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": "2025-08-11T09:30:47.913Z"
    },
    {
      "title": "Python Operators and Expressions",
      "content": "Python provides various operators for mathematical calculations, comparisons, and logical operations. Understanding operator precedence and short-circuit evaluation is crucial for writing efficient code.",
      "codeExample": "# Arithmetic operators\na, b = 10, 3\nprint(f\"Addition: {a + b}\")        # 13\nprint(f\"Subtraction: {a - b}\")     # 7\nprint(f\"Multiplication: {a * b}\")  # 30\nprint(f\"Division: {a / b}\")        # 3.333...\nprint(f\"Floor division: {a // b}\") # 3\nprint(f\"Modulo: {a % b}\")          # 1\nprint(f\"Exponentiation: {a ** b}\") # 1000\n\n# Comparison operators\nprint(f\"Equal: {a == b}\")          # False\nprint(f\"Not equal: {a != b}\")      # True\nprint(f\"Greater than: {a > b}\")    # True\n\n# Logical operators\nx, y = True, False\nprint(f\"AND: {x and y}\")           # False\nprint(f\"OR: {x or y}\")             # True\nprint(f\"NOT: {not x}\")             # False\n\n# Short-circuit evaluation\ndef expensive_operation():\n    print(\"This won't be called!\")\n    return True\n\nresult = False and expensive_operation()  # expensive_operation() not called",
      "difficulty": "beginner",
      "categorySlug": "python-basics",
      "xpReward": 12,
      "tags": [
        "operators",
        "expressions",
        "arithmetic"
      ],
      "estimatedMinutes": 5,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Control Flow: if, elif, else",
      "content": "Python's conditional statements allow you to execute different code blocks based on conditions. The 'elif' keyword is Python's way of saying 'else if'.",
      "codeExample": "# Basic if statement\nage = 18\nif age >= 18:\n    print(\"You are an adult\")\nelse:\n    print(\"You are a minor\")\n\n# Multiple conditions with elif\nscore = 85\nif score >= 90:\n    grade = \"A\"\nelif score >= 80:\n    grade = \"B\"\nelif score >= 70:\n    grade = \"C\"\nelif score >= 60:\n    grade = \"D\"\nelse:\n    grade = \"F\"\n\nprint(f\"Your grade is: {grade}\")\n\n# Combining conditions\nusername = \"admin\"\npassword = \"secret123\"\nif username == \"admin\" and password == \"secret123\":\n    print(\"Access granted\")\nelif username == \"admin\":\n    print(\"Wrong password\")\nelse:\n    print(\"User not found\")\n\n# Ternary operator (conditional expression)\nmessage = \"Even\" if 10 % 2 == 0 else \"Odd\"\nprint(message)  # Even",
      "difficulty": "beginner",
      "categorySlug": "python-basics",
      "xpReward": 14,
      "tags": [
        "conditionals",
        "if-else",
        "control-flow"
      ],
      "estimatedMinutes": 4,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Loops: for and while",
      "content": "Python provides two types of loops: 'for' loops for iterating over sequences, and 'while' loops for repeated execution based on a condition.",
      "codeExample": "# For loop with range\nfor i in range(5):\n    print(f\"Count: {i}\")\n\n# For loop with list\nfruits = [\"apple\", \"banana\", \"cherry\"]\nfor fruit in fruits:\n    print(f\"I like {fruit}\")\n\n# For loop with enumerate (index + value)\nfor index, fruit in enumerate(fruits):\n    print(f\"{index}: {fruit}\")\n\n# While loop\ncount = 0\nwhile count < 3:\n    print(f\"While count: {count}\")\n    count += 1\n\n# Loop control: break and continue\nfor i in range(10):\n    if i == 3:\n        continue  # Skip this iteration\n    if i == 7:\n        break     # Exit the loop\n    print(i)\n\n# Nested loops\nfor i in range(3):\n    for j in range(2):\n        print(f\"i={i}, j={j}\")",
      "difficulty": "beginner",
      "categorySlug": "python-basics",
      "xpReward": 16,
      "tags": [
        "loops",
        "for",
        "while",
        "iteration"
      ],
      "estimatedMinutes": 6,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Input and Output Operations",
      "content": "Python provides simple ways to get user input and display output. Understanding input validation and formatting output is essential for interactive programs.",
      "codeExample": "# Basic input and output\nname = input(\"What's your name? \")\nprint(f\"Hello, {name}!\")\n\n# Type conversion for input\nage_str = input(\"What's your age? \")\nage = int(age_str)  # Convert to integer\nprint(f\"Next year you'll be {age + 1}\")\n\n# Input validation\nwhile True:\n    try:\n        number = int(input(\"Enter a number: \"))\n        break  # Exit loop if conversion successful\n    except ValueError:\n        print(\"Please enter a valid number!\")\n\n# Multiple inputs on one line\nx, y = input(\"Enter two numbers: \").split()\nx, y = int(x), int(y)\nprint(f\"Sum: {x + y}\")\n\n# Formatted output\nprint(\"Name:\", name)\nprint(\"Age:\", age)\nprint(\"Numbers:\", x, y, sep=\" | \")\nprint(\"Sum is\", x + y, end=\"!\\n\")\n\n# Using print parameters\nprint(\"Loading\", end=\"\")\nfor i in range(3):\n    print(\".\", end=\"\", flush=True)\n    # time.sleep(1)  # Uncomment for effect\nprint(\" Done!\")",
      "difficulty": "beginner",
      "categorySlug": "python-basics",
      "xpReward": 13,
      "tags": [
        "input",
        "output",
        "print",
        "user-interaction"
      ],
      "estimatedMinutes": 5,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Python Comments and Documentation",
      "content": "Writing clear comments and documentation is crucial for maintaining code. Python supports single-line, multi-line comments, and docstrings for documentation.",
      "codeExample": "# Single-line comment\nx = 5  # Inline comment\n\n# Multi-line comments using multiple # symbols\n# This is a longer explanation\n# that spans multiple lines\n# describing complex logic\n\n\"\"\"\nMulti-line string can serve as\nblock comments, though not recommended\nfor regular comments\n\"\"\"\n\ndef calculate_area(radius):\n    \"\"\"\n    Calculate the area of a circle.\n    \n    Args:\n        radius (float): The radius of the circle\n        \n    Returns:\n        float: The area of the circle\n        \n    Raises:\n        ValueError: If radius is negative\n    \"\"\"\n    if radius < 0:\n        raise ValueError(\"Radius cannot be negative\")\n    \n    import math\n    return math.pi * radius ** 2\n\n# Good commenting practices\ndef process_user_data(users):\n    # Filter active users only\n    active_users = [user for user in users if user.get('active')]\n    \n    # Sort by registration date (newest first)\n    active_users.sort(key=lambda u: u['reg_date'], reverse=True)\n    \n    # Return top 10 users\n    return active_users[:10]\n\n# TODO: Add error handling\n# FIXME: This function is inefficient\n# NOTE: Consider using database query instead",
      "difficulty": "beginner",
      "categorySlug": "python-basics",
      "xpReward": 8,
      "tags": [
        "comments",
        "documentation",
        "docstrings"
      ],
      "estimatedMinutes": 3,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Python Indentation and Code Structure",
      "content": "Python uses indentation to define code blocks instead of braces. Consistent indentation is crucial for code readability and functionality.",
      "codeExample": "# Correct indentation\nif True:\n    print(\"This is indented correctly\")\n    if True:\n        print(\"This is nested indentation\")\n    print(\"Back to first level\")\n\n# Function with proper indentation\ndef greet_user(name):\n    if name:\n        print(f\"Hello, {name}!\")\n        if len(name) > 10:\n            print(\"That's a long name!\")\n        else:\n            print(\"Nice name!\")\n    else:\n        print(\"Hello, Anonymous!\")\n\n# Class with proper indentation\nclass Student:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n    \n    def study(self, subject):\n        print(f\"{self.name} is studying {subject}\")\n        if subject == \"Python\":\n            print(\"Great choice!\")\n\n# Good practices for long lines\nvery_long_variable_name = (\n    \"This is a very long string that \"\n    \"spans multiple lines for better \"\n    \"readability\"\n)\n\n# Function with many parameters\ndef complex_function(\n    parameter_one,\n    parameter_two,\n    parameter_three,\n    parameter_four\n):\n    return parameter_one + parameter_two\n\n# List spanning multiple lines\nfruits = [\n    \"apple\",\n    \"banana\", \n    \"cherry\",\n    \"date\"\n]",
      "difficulty": "beginner",
      "categorySlug": "python-basics",
      "xpReward": 10,
      "tags": [
        "indentation",
        "structure",
        "formatting"
      ],
      "estimatedMinutes": 4,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Sets: Unique Collections and Set Operations",
      "content": "Sets are unordered collections of unique elements. They're perfect for removing duplicates and performing mathematical set operations like union, intersection, and difference.",
      "codeExample": "# Creating sets\nnumbers = {1, 2, 3, 4, 5}\nempty_set = set()  # Note: {} creates a dict, not a set!\n\n# Converting from list (removes duplicates)\nduplicates = [1, 2, 2, 3, 3, 3, 4]\nunique_numbers = set(duplicates)\nprint(unique_numbers)  # {1, 2, 3, 4}\n\n# Set operations\nset1 = {1, 2, 3, 4}\nset2 = {3, 4, 5, 6}\n\n# Union (all elements)\nunion = set1 | set2  # or set1.union(set2)\nprint(union)  # {1, 2, 3, 4, 5, 6}\n\n# Intersection (common elements)\nintersection = set1 & set2  # or set1.intersection(set2)\nprint(intersection)  # {3, 4}\n\n# Difference (elements in set1 but not set2)\ndifference = set1 - set2  # or set1.difference(set2)\nprint(difference)  # {1, 2}\n\n# Symmetric difference (elements in either set but not both)\nsym_diff = set1 ^ set2  # or set1.symmetric_difference(set2)\nprint(sym_diff)  # {1, 2, 5, 6}\n\n# Practical example: finding common interests\nalice_interests = {\"python\", \"machine learning\", \"data science\", \"cooking\"}\nbob_interests = {\"python\", \"web development\", \"cooking\", \"travel\"}\ncommon = alice_interests & bob_interests\nprint(f\"Common interests: {common}\")",
      "difficulty": "intermediate",
      "categorySlug": "data-structures",
      "xpReward": 16,
      "tags": [
        "sets",
        "unique",
        "operations"
      ],
      "estimatedMinutes": 5,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Tuples: Immutable Sequences",
      "content": "Tuples are immutable sequences, making them perfect for storing data that shouldn't change. They're also hashable, so they can be used as dictionary keys.",
      "codeExample": "# Creating tuples\ncoordinates = (10, 20)\nsingle_item = (42,)  # Note the comma for single-item tuple\nempty_tuple = ()\n\n# Tuple unpacking\npoint = (3, 4)\nx, y = point\nprint(f\"x: {x}, y: {y}\")\n\n# Multiple assignment\nname, age, city = (\"Alice\", 25, \"New York\")\n\n# Swapping variables (using tuple unpacking)\na, b = 1, 2\na, b = b, a  # Now a=2, b=1\n\n# Named tuples for better readability\nfrom collections import namedtuple\n\nPerson = namedtuple('Person', ['name', 'age', 'city'])\nalice = Person(\"Alice\", 25, \"New York\")\nprint(alice.name)  # More readable than alice[0]\nprint(alice._asdict())  # Convert to dictionary\n\n# Tuple as dictionary key\nlocations = {\n    (0, 0): \"Origin\",\n    (1, 0): \"East\",\n    (0, 1): \"North\"\n}\n\n# Returning multiple values from function\ndef get_name_age():\n    return \"Bob\", 30\n\nname, age = get_name_age()\n\n# Tuple methods\nnumbers = (1, 2, 3, 2, 4, 2)\nprint(numbers.count(2))  # 3\nprint(numbers.index(3))  # 2",
      "difficulty": "beginner",
      "categorySlug": "data-structures",
      "xpReward": 14,
      "tags": [
        "tuples",
        "immutable",
        "unpacking"
      ],
      "estimatedMinutes": 4,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Working with Nested Data Structures",
      "content": "Real-world data often comes in nested formats like lists of dictionaries or dictionaries containing lists. Learning to navigate and manipulate these structures is essential.",
      "codeExample": "# Complex nested structure\ncompany = {\n    \"name\": \"Tech Corp\",\n    \"employees\": [\n        {\n            \"name\": \"Alice\",\n            \"department\": \"Engineering\",\n            \"skills\": [\"Python\", \"JavaScript\", \"SQL\"],\n            \"projects\": [\n                {\"name\": \"Web App\", \"status\": \"active\"},\n                {\"name\": \"API\", \"status\": \"completed\"}\n            ]\n        },\n        {\n            \"name\": \"Bob\", \n            \"department\": \"Data Science\",\n            \"skills\": [\"Python\", \"R\", \"Machine Learning\"],\n            \"projects\": [\n                {\"name\": \"ML Model\", \"status\": \"active\"}\n            ]\n        }\n    ]\n}\n\n# Accessing nested data\nfirst_employee = company[\"employees\"][0]\nalice_skills = first_employee[\"skills\"]\nfirst_project = first_employee[\"projects\"][0][\"name\"]\n\n# Safe access with get()\ndef safe_get_nested(data, *keys):\n    for key in keys:\n        if isinstance(data, dict) and key in data:\n            data = data[key]\n        else:\n            return None\n    return data\n\n# Usage: safely get Alice's first project status\nstatus = safe_get_nested(company, \"employees\", 0, \"projects\", 0, \"status\")\n\n# Finding data in nested structures\ndef find_employees_by_skill(company, skill):\n    employees_with_skill = []\n    for employee in company[\"employees\"]:\n        if skill in employee[\"skills\"]:\n            employees_with_skill.append(employee[\"name\"])\n    return employees_with_skill\n\npython_developers = find_employees_by_skill(company, \"Python\")\n\n# Flattening nested lists\nall_skills = []\nfor employee in company[\"employees\"]:\n    all_skills.extend(employee[\"skills\"])\n\n# Remove duplicates\nunique_skills = list(set(all_skills))\n\n# Using list comprehension for the same result\nall_skills_comp = [skill \n                  for employee in company[\"employees\"] \n                  for skill in employee[\"skills\"]]",
      "difficulty": "intermediate",
      "categorySlug": "data-structures",
      "xpReward": 22,
      "tags": [
        "nested",
        "data-structures",
        "navigation"
      ],
      "estimatedMinutes": 7,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Slicing and Indexing Mastery",
      "content": "Python's slicing syntax is powerful and flexible. Understanding advanced slicing techniques can make your code more concise and readable.",
      "codeExample": "# Basic indexing\ntext = \"Python Programming\"\nprint(text[0])    # 'P' (first character)\nprint(text[-1])   # 'g' (last character)\nprint(text[-2])   # 'n' (second to last)\n\n# Basic slicing [start:end:step]\nprint(text[0:6])    # 'Python' (characters 0-5)\nprint(text[7:])     # 'Programming' (from index 7 to end)\nprint(text[:6])     # 'Python' (from start to index 5)\nprint(text[:])      # 'Python Programming' (entire string)\n\n# Step parameter\nnumbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nprint(numbers[::2])    # [0, 2, 4, 6, 8] (every 2nd element)\nprint(numbers[1::2])   # [1, 3, 5, 7, 9] (every 2nd, starting from index 1)\nprint(numbers[::-1])   # [9, 8, 7, 6, 5, 4, 3, 2, 1, 0] (reverse)\n\n# Advanced slicing tricks\n# Reverse a string\nreversed_text = text[::-1]\n\n# Get last 3 characters\nlast_three = text[-3:]\n\n# Remove first and last character\nmiddle = text[1:-1]\n\n# Extract every 3rd character starting from index 1\npattern = text[1::3]\n\n# Slicing with negative step\n# Get every 2nd character in reverse\nreverse_every_second = text[::-2]\n\n# Matrix slicing (2D lists)\nmatrix = [\n    [1, 2, 3, 4],\n    [5, 6, 7, 8], \n    [9, 10, 11, 12]\n]\n\n# Get first two rows\nfirst_two_rows = matrix[:2]\n\n# Get first two columns of all rows\nfirst_two_cols = [row[:2] for row in matrix]\n\n# Slice assignment (modifying lists)\nnumbers = [0, 1, 2, 3, 4, 5]\nnumbers[2:4] = [20, 30]  # Replace elements 2 and 3\nprint(numbers)  # [0, 1, 20, 30, 4, 5]",
      "difficulty": "intermediate",
      "categorySlug": "data-structures",
      "xpReward": 17,
      "tags": [
        "slicing",
        "indexing",
        "sequences"
      ],
      "estimatedMinutes": 6,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Lambda Functions and Functional Programming",
      "content": "Lambda functions are small, anonymous functions that can have any number of arguments but can only have one expression. They're useful for short functions used with map(), filter(), and sort().",
      "codeExample": "# Basic lambda function\nsquare = lambda x: x ** 2\nprint(square(5))  # 25\n\n# Lambda with multiple arguments\nadd = lambda x, y: x + y\nprint(add(3, 5))  # 8\n\n# Using lambda with map()\nnumbers = [1, 2, 3, 4, 5]\nsquared = list(map(lambda x: x ** 2, numbers))\nprint(squared)  # [1, 4, 9, 16, 25]\n\n# Using lambda with filter()\neven_numbers = list(filter(lambda x: x % 2 == 0, numbers))\nprint(even_numbers)  # [2, 4]\n\n# Using lambda with sort()\nstudents = [(\"Alice\", 85), (\"Bob\", 92), (\"Charlie\", 78)]\n# Sort by grade (second element)\nstudents.sort(key=lambda student: student[1])\nprint(students)  # [('Charlie', 78), ('Alice', 85), ('Bob', 92)]\n\n# Lambda in list comprehensions alternative\n# Instead of: [lambda x: x ** 2 for x in range(5)]\n# Use: [x ** 2 for x in range(5)]\n\n# More complex example with sorted()\npeople = [\n    {\"name\": \"Alice\", \"age\": 30},\n    {\"name\": \"Bob\", \"age\": 25},\n    {\"name\": \"Charlie\", \"age\": 35}\n]\n\n# Sort by age\nsorted_by_age = sorted(people, key=lambda person: person[\"age\"])\n\n# When NOT to use lambda (prefer def for clarity)\n# Bad: \nprocess = lambda data: [item.upper().strip() for item in data if len(item) > 3]\n\n# Good:\ndef process_data(data):\n    return [item.upper().strip() for item in data if len(item) > 3]",
      "difficulty": "intermediate",
      "categorySlug": "functions-modules",
      "xpReward": 20,
      "tags": [
        "lambda",
        "functional-programming",
        "map",
        "filter"
      ],
      "estimatedMinutes": 6,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Decorators: Enhancing Functions",
      "content": "Decorators are a powerful feature that allows you to modify or enhance functions and classes. They're widely used in frameworks like Flask and Django.",
      "codeExample": "# Simple decorator\ndef my_decorator(func):\n    def wrapper():\n        print(\"Something before the function\")\n        func()\n        print(\"Something after the function\")\n    return wrapper\n\n@my_decorator\ndef say_hello():\n    print(\"Hello!\")\n\nsay_hello()  # Output: Something before..., Hello!, Something after...\n\n# Decorator with arguments\ndef repeat(times):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            for _ in range(times):\n                result = func(*args, **kwargs)\n            return result\n        return wrapper\n    return decorator\n\n@repeat(3)\ndef greet(name):\n    print(f\"Hello, {name}!\")\n\ngreet(\"Alice\")  # Prints \"Hello, Alice!\" 3 times\n\n# Preserving function metadata\nimport functools\n\ndef timer(func):\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        import time\n        start = time.time()\n        result = func(*args, **kwargs)\n        end = time.time()\n        print(f\"{func.__name__} took {end - start:.4f} seconds\")\n        return result\n    return wrapper\n\n@timer\ndef slow_function():\n    \"\"\"A slow function for demonstration\"\"\"\n    import time\n    time.sleep(1)\n    return \"Done\"\n\n# Class decorators\ndef add_str_method(cls):\n    def __str__(self):\n        return f\"{cls.__name__} instance\"\n    cls.__str__ = __str__\n    return cls\n\n@add_str_method\nclass MyClass:\n    pass",
      "difficulty": "advanced",
      "categorySlug": "functions-modules",
      "xpReward": 28,
      "tags": [
        "decorators",
        "functions",
        "advanced"
      ],
      "estimatedMinutes": 8,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Module Import Strategies and Best Practices",
      "content": "Understanding different import strategies helps you write cleaner, more maintainable code. Learn when to use different import styles and how to organize your modules effectively.",
      "codeExample": "# Different import styles\nimport math\nimport os as operating_system\nfrom datetime import datetime, timedelta\nfrom collections import defaultdict, Counter\nfrom pathlib import Path\n\n# Importing everything (generally discouraged)\n# from math import *  # Don't do this!\n\n# Relative imports (for packages)\n# from . import sibling_module\n# from ..parent import parent_module\n# from .subpackage import module\n\n# Dynamic imports\nimport importlib\n\ndef dynamic_import(module_name):\n    try:\n        module = importlib.import_module(module_name)\n        return module\n    except ImportError:\n        print(f\"Module {module_name} not found\")\n        return None\n\n# Conditional imports\ntry:\n    import numpy as np\n    HAS_NUMPY = True\nexcept ImportError:\n    HAS_NUMPY = False\n    print(\"NumPy not available\")\n\n# Creating an __init__.py file for a package\n\"\"\"\n# __init__.py example\nfrom .core import main_function\nfrom .utils import helper_function\nfrom .constants import VERSION\n\n__all__ = ['main_function', 'helper_function', 'VERSION']\n\"\"\"\n\n# Module search path\nimport sys\nprint(\"Python module search paths:\")\nfor path in sys.path:\n    print(f\"  {path}\")\n\n# Adding custom paths\nsys.path.insert(0, '/path/to/custom/modules')\n\n# Lazy imports for performance\ndef get_heavy_library():\n    import heavy_computation_library\n    return heavy_computation_library\n\n# Use only when needed\n# heavy_lib = get_heavy_library()\n\n# Creating a simple package structure\n\"\"\"\nmy_package/\n    __init__.py\n    core.py\n    utils.py\n    subpackage/\n        __init__.py\n        advanced.py\n\"\"\"",
      "difficulty": "intermediate",
      "categorySlug": "functions-modules",
      "xpReward": 22,
      "tags": [
        "modules",
        "imports",
        "packages"
      ],
      "estimatedMinutes": 6,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Generators: Memory-Efficient Iteration",
      "content": "Generators are functions that return an iterator object. They're memory-efficient because they generate values on-demand rather than storing all values in memory at once.",
      "codeExample": "# Simple generator function\ndef countdown(n):\n    while n > 0:\n        yield n\n        n -= 1\n\n# Using the generator\nfor number in countdown(5):\n    print(number)  # Prints 5, 4, 3, 2, 1\n\n# Generator expressions (like list comprehensions)\nsquares = (x**2 for x in range(10))\nprint(next(squares))  # 0\nprint(next(squares))  # 1\n\n# Infinite generator\ndef fibonacci():\n    a, b = 0, 1\n    while True:\n        yield a\n        a, b = b, a + b\n\n# Take first 10 Fibonacci numbers\nfib = fibonacci()\nfirst_ten = [next(fib) for _ in range(10)]\nprint(first_ten)  # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n\n# Generator for reading large files\ndef read_large_file(file_path):\n    with open(file_path, 'r') as file:\n        for line in file:\n            yield line.strip()\n\n# Memory-efficient file processing\n# for line in read_large_file('huge_file.txt'):\n#     process(line)\n\n# Generator with send() method\ndef accumulator():\n    total = 0\n    while True:\n        value = yield total\n        if value is not None:\n            total += value\n\nacc = accumulator()\nnext(acc)  # Prime the generator\nprint(acc.send(10))  # 10\nprint(acc.send(5))   # 15\nprint(acc.send(3))   # 18\n\n# Pipeline of generators\ndef numbers():\n    for i in range(10):\n        yield i\n\ndef squares(nums):\n    for num in nums:\n        yield num ** 2\n\ndef evens(nums):\n    for num in nums:\n        if num % 2 == 0:\n            yield num\n\n# Chain generators together\npipeline = evens(squares(numbers()))\nresult = list(pipeline)  # [0, 4, 16, 36, 64]\n\n# Generator vs List - memory comparison\nimport sys\n\n# List (all values in memory)\nlist_comp = [x**2 for x in range(1000)]\nprint(f\"List size: {sys.getsizeof(list_comp)} bytes\")\n\n# Generator (values created on demand)\ngen_comp = (x**2 for x in range(1000))\nprint(f\"Generator size: {sys.getsizeof(gen_comp)} bytes\")",
      "difficulty": "intermediate",
      "categorySlug": "functions-modules",
      "xpReward": 24,
      "tags": [
        "generators",
        "memory",
        "iteration",
        "yield"
      ],
      "estimatedMinutes": 7,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Function Annotations and Type Hints",
      "content": "Type hints make your code more readable and help catch errors early. They're especially useful in larger codebases and when working with teams.",
      "codeExample": "# Basic type hints\ndef greet(name: str, age: int) -> str:\n    return f\"Hello {name}, you are {age} years old\"\n\ndef add_numbers(a: int, b: int) -> int:\n    return a + b\n\n# Type hints for complex types\nfrom typing import List, Dict, Optional, Union, Tuple, Callable\n\ndef process_items(items: List[str]) -> Dict[str, int]:\n    return {item: len(item) for item in items}\n\ndef get_user_info(user_id: int) -> Optional[Dict[str, str]]:\n    # Returns user info dict or None if not found\n    if user_id > 0:\n        return {\"name\": \"Alice\", \"email\": \"alice@example.com\"}\n    return None\n\n# Union types (multiple possible types)\ndef process_id(user_id: Union[int, str]) -> str:\n    return str(user_id)\n\n# Function that takes another function\ndef apply_operation(\n    numbers: List[int],\n    operation: Callable[[int], int]\n) -> List[int]:\n    return [operation(num) for num in numbers]\n\n# Example usage\ndef square(x: int) -> int:\n    return x ** 2\n\nresult = apply_operation([1, 2, 3, 4], square)\n\n# Class annotations\nclass Person:\n    def __init__(self, name: str, age: int) -> None:\n        self.name: str = name\n        self.age: int = age\n    \n    def get_info(self) -> Dict[str, Union[str, int]]:\n        return {\"name\": self.name, \"age\": self.age}\n\n# Variable annotations\ncount: int = 0\nnames: List[str] = []\nscores: Dict[str, float] = {}\n\n# Generic types\nfrom typing import TypeVar, Generic\n\nT = TypeVar('T')\n\nclass Stack(Generic[T]):\n    def __init__(self) -> None:\n        self._items: List[T] = []\n    \n    def push(self, item: T) -> None:\n        self._items.append(item)\n    \n    def pop(self) -> T:\n        return self._items.pop()\n\n# Using generics\nstring_stack: Stack[str] = Stack()\nnumber_stack: Stack[int] = Stack()\n\n# NewType for better type safety\nfrom typing import NewType\n\nUserId = NewType('UserId', int)\n\ndef get_user_name(user_id: UserId) -> str:\n    return f\"User {user_id}\"\n\n# Must explicitly create UserId\nuser_id = UserId(12345)\nname = get_user_name(user_id)\n\n# Type checking with mypy\n# Install: pip install mypy\n# Run: mypy your_script.py",
      "difficulty": "intermediate",
      "categorySlug": "functions-modules",
      "xpReward": 26,
      "tags": [
        "type-hints",
        "annotations",
        "typing",
        "mypy"
      ],
      "estimatedMinutes": 8,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Classes and Objects Fundamentals",
      "content": "Classes are blueprints for creating objects. They encapsulate data (attributes) and behavior (methods) into a single unit. Understanding the basics of class creation and object instantiation is fundamental to OOP in Python.",
      "codeExample": "# Basic class definition\nclass Dog:\n    # Class attribute (shared by all instances)\n    species = \"Canis lupus\"\n    \n    def __init__(self, name, age, breed):\n        # Instance attributes (unique to each object)\n        self.name = name\n        self.age = age\n        self.breed = breed\n    \n    # Instance method\n    def bark(self):\n        return f\"{self.name} says Woof!\"\n    \n    def get_info(self):\n        return f\"{self.name} is a {self.age}-year-old {self.breed}\"\n    \n    # Method with parameters\n    def celebrate_birthday(self):\n        self.age += 1\n        return f\"Happy birthday {self.name}! Now {self.age} years old.\"\n\n# Creating objects (instances)\ndog1 = Dog(\"Buddy\", 3, \"Golden Retriever\")\ndog2 = Dog(\"Max\", 5, \"German Shepherd\")\n\n# Accessing attributes\nprint(dog1.name)  # Buddy\nprint(dog1.species)  # Canis lupus\n\n# Calling methods\nprint(dog1.bark())  # Buddy says Woof!\nprint(dog1.get_info())  # Buddy is a 3-year-old Golden Retriever\n\n# Modifying attributes\ndog1.age = 4\nprint(dog1.celebrate_birthday())  # Happy birthday Buddy! Now 5 years old.\n\n# Class vs instance attributes\nprint(Dog.species)  # Accessing class attribute via class\nDog.species = \"Domestic Dog\"  # Modifying class attribute\nprint(dog1.species)  # Both instances see the change\n\n# Instance attribute shadows class attribute\ndog1.species = \"Special Dog\"\nprint(dog1.species)  # Special Dog (instance attribute)\nprint(dog2.species)  # Domestic Dog (class attribute)",
      "difficulty": "beginner",
      "categorySlug": "oop",
      "xpReward": 18,
      "tags": [
        "classes",
        "objects",
        "methods",
        "attributes"
      ],
      "estimatedMinutes": 6,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Inheritance and Method Overriding",
      "content": "Inheritance allows a class to inherit attributes and methods from another class. It promotes code reuse and establishes a hierarchical relationship between classes.",
      "codeExample": "# Base class (parent)\nclass Animal:\n    def __init__(self, name, species):\n        self.name = name\n        self.species = species\n        self.is_alive = True\n    \n    def speak(self):\n        return f\"{self.name} makes a sound\"\n    \n    def eat(self, food):\n        return f\"{self.name} eats {food}\"\n    \n    def sleep(self):\n        return f\"{self.name} is sleeping\"\n\n# Derived class (child) - inherits from Animal\nclass Dog(Animal):\n    def __init__(self, name, breed):\n        # Call parent constructor\n        super().__init__(name, \"Canine\")\n        self.breed = breed\n    \n    # Method overriding\n    def speak(self):\n        return f\"{self.name} barks: Woof!\"\n    \n    # Additional method specific to Dog\n    def fetch(self, item):\n        return f\"{self.name} fetches the {item}\"\n\nclass Cat(Animal):\n    def __init__(self, name, color):\n        super().__init__(name, \"Feline\")\n        self.color = color\n    \n    # Method overriding\n    def speak(self):\n        return f\"{self.name} meows: Meow!\"\n    \n    def climb(self):\n        return f\"{self.name} climbs up high\"\n\n# Using inheritance\ndog = Dog(\"Rex\", \"Labrador\")\ncat = Cat(\"Whiskers\", \"Orange\")\n\n# Inherited methods\nprint(dog.eat(\"kibble\"))  # Rex eats kibble\nprint(cat.sleep())  # Whiskers is sleeping\n\n# Overridden methods\nprint(dog.speak())  # Rex barks: Woof!\nprint(cat.speak())  # Whiskers meows: Meow!\n\n# Child-specific methods\nprint(dog.fetch(\"ball\"))  # Rex fetches the ball\nprint(cat.climb())  # Whiskers climbs up high\n\n# Multiple inheritance\nclass FlyingMixin:\n    def fly(self):\n        return f\"{self.name} is flying\"\n\nclass Bird(Animal, FlyingMixin):\n    def __init__(self, name, wingspan):\n        super().__init__(name, \"Avian\")\n        self.wingspan = wingspan\n    \n    def speak(self):\n        return f\"{self.name} chirps\"\n\neagle = Bird(\"Eagle\", 200)\nprint(eagle.fly())  # Eagle is flying\nprint(eagle.speak())  # Eagle chirps\n\n# Method Resolution Order (MRO)\nprint(Bird.__mro__)",
      "difficulty": "intermediate",
      "categorySlug": "oop",
      "xpReward": 24,
      "tags": [
        "inheritance",
        "super",
        "overriding",
        "polymorphism"
      ],
      "estimatedMinutes": 8,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Properties and Encapsulation",
      "content": "Properties provide a way to customize access to instance attributes. They allow you to define methods that can be accessed like attributes, enabling data validation and computed properties.",
      "codeExample": "# Using properties for validation and computed values\nclass Temperature:\n    def __init__(self, celsius=0):\n        self._celsius = celsius\n    \n    @property\n    def celsius(self):\n        return self._celsius\n    \n    @celsius.setter\n    def celsius(self, value):\n        if value < -273.15:\n            raise ValueError(\"Temperature cannot be below absolute zero\")\n        self._celsius = value\n    \n    @property\n    def fahrenheit(self):\n        return (self._celsius * 9/5) + 32\n    \n    @fahrenheit.setter\n    def fahrenheit(self, value):\n        self.celsius = (value - 32) * 5/9\n    \n    @property\n    def kelvin(self):\n        return self._celsius + 273.15\n\n# Using properties\ntemp = Temperature(25)\nprint(f\"Celsius: {temp.celsius}\")     # 25\nprint(f\"Fahrenheit: {temp.fahrenheit}\")  # 77.0\nprint(f\"Kelvin: {temp.kelvin}\")       # 298.15\n\n# Setting through property\ntemp.fahrenheit = 100\nprint(f\"Celsius: {temp.celsius}\")     # 37.777...\n\n# Validation in action\ntry:\n    temp.celsius = -300  # Raises ValueError\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n\n# Private attributes and name mangling\nclass BankAccount:\n    def __init__(self, initial_balance=0):\n        self.__balance = initial_balance  # Private attribute\n        self._account_number = \"12345\"    # Protected (convention)\n    \n    @property\n    def balance(self):\n        return self.__balance\n    \n    def deposit(self, amount):\n        if amount > 0:\n            self.__balance += amount\n            return f\"Deposited {amount} dollars. New balance: {self.__balance} dollars\"\n        return \"Invalid deposit amount\"\n    \n    def withdraw(self, amount):\n        if 0 < amount <= self.__balance:\n            self.__balance -= amount\n            return f\"Withdrew {amount} dollars. New balance: {self.__balance} dollars\"\n        return \"Insufficient funds or invalid amount\"\n    \n    def __str__(self):\n        return f\"Account balance: {self.__balance} dollars\"\n\naccount = BankAccount(1000)\nprint(account.balance)  # 1000\nprint(account.deposit(500))  # Deposited $500. New balance: $1500\n\n# Cannot access private attribute directly\n# print(account.__balance)  # AttributeError\n\n# But can access via name mangling (not recommended)\nprint(account._BankAccount__balance)  # 1500\n\n# Property with getter, setter, and deleter\nclass Person:\n    def __init__(self, first_name, last_name):\n        self.first_name = first_name\n        self.last_name = last_name\n        self._full_name = None\n    \n    @property\n    def full_name(self):\n        return f\"{self.first_name} {self.last_name}\"\n    \n    @full_name.setter\n    def full_name(self, value):\n        names = value.split()\n        if len(names) >= 2:\n            self.first_name = names[0]\n            self.last_name = \" \".join(names[1:])\n        else:\n            raise ValueError(\"Full name must contain at least first and last name\")\n    \n    @full_name.deleter\n    def full_name(self):\n        self.first_name = \"\"\n        self.last_name = \"\"\n\nperson = Person(\"John\", \"Doe\")\nprint(person.full_name)  # John Doe\nperson.full_name = \"Jane Smith\"\nprint(person.first_name)  # Jane\nprint(person.last_name)   # Smith",
      "difficulty": "intermediate",
      "categorySlug": "oop",
      "xpReward": 26,
      "tags": [
        "properties",
        "encapsulation",
        "getters",
        "setters"
      ],
      "estimatedMinutes": 9,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Special Methods (Magic Methods)",
      "content": "Special methods (dunder methods) allow your classes to integrate with Python's built-in functions and operators. They start and end with double underscores and define how objects behave with operators, comparisons, and built-in functions.",
      "codeExample": "# Comprehensive example of special methods\nclass Vector:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n    \n    # String representations\n    def __str__(self):\n        return f\"Vector({self.x}, {self.y})\"\n    \n    def __repr__(self):\n        return f\"Vector(x={self.x}, y={self.y})\"\n    \n    # Arithmetic operations\n    def __add__(self, other):\n        if isinstance(other, Vector):\n            return Vector(self.x + other.x, self.y + other.y)\n        return NotImplemented\n    \n    def __sub__(self, other):\n        if isinstance(other, Vector):\n            return Vector(self.x - other.x, self.y - other.y)\n        return NotImplemented\n    \n    def __mul__(self, scalar):\n        if isinstance(scalar, (int, float)):\n            return Vector(self.x * scalar, self.y * scalar)\n        return NotImplemented\n    \n    def __rmul__(self, scalar):\n        return self.__mul__(scalar)\n    \n    # Comparison operations\n    def __eq__(self, other):\n        if isinstance(other, Vector):\n            return self.x == other.x and self.y == other.y\n        return False\n    \n    def __lt__(self, other):\n        if isinstance(other, Vector):\n            return self.magnitude() < other.magnitude()\n        return NotImplemented\n    \n    def __le__(self, other):\n        return self < other or self == other\n    \n    # Length and boolean conversion\n    def __len__(self):\n        return int((self.x**2 + self.y**2)**0.5)\n    \n    def __bool__(self):\n        return self.x != 0 or self.y != 0\n    \n    def magnitude(self):\n        return (self.x**2 + self.y**2)**0.5\n    \n    # Container-like behavior\n    def __getitem__(self, index):\n        if index == 0:\n            return self.x\n        elif index == 1:\n            return self.y\n        else:\n            raise IndexError(\"Vector index out of range\")\n    \n    def __setitem__(self, index, value):\n        if index == 0:\n            self.x = value\n        elif index == 1:\n            self.y = value\n        else:\n            raise IndexError(\"Vector index out of range\")\n\n# Using the Vector class\nv1 = Vector(3, 4)\nv2 = Vector(1, 2)\n\n# String representation\nprint(str(v1))   # Vector(3, 4)\nprint(repr(v1))  # Vector(x=3, y=4)\n\n# Arithmetic\nv3 = v1 + v2     # Vector(4, 6)\nv4 = v1 * 2      # Vector(6, 8)\nv5 = 3 * v1      # Vector(9, 12) - uses __rmul__\n\n# Comparisons\nprint(v1 == v2)  # False\nprint(v1 < v2)   # False (based on magnitude)\n\n# Built-in functions\nprint(len(v1))   # 5 (magnitude as int)\nprint(bool(Vector(0, 0)))  # False\nprint(bool(v1))  # True\n\n# Container-like access\nprint(v1[0])     # 3 (x coordinate)\nprint(v1[1])     # 4 (y coordinate)\nv1[0] = 5        # Set x to 5\n\n# Context manager example\nclass FileManager:\n    def __init__(self, filename, mode):\n        self.filename = filename\n        self.mode = mode\n        self.file = None\n    \n    def __enter__(self):\n        print(f\"Opening {self.filename}\")\n        self.file = open(self.filename, self.mode)\n        return self.file\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        print(f\"Closing {self.filename}\")\n        if self.file:\n            self.file.close()\n        return False  # Don't suppress exceptions\n\n# Usage with 'with' statement\n# with FileManager('test.txt', 'w') as f:\n#     f.write('Hello, World!')",
      "difficulty": "advanced",
      "categorySlug": "oop",
      "xpReward": 30,
      "tags": [
        "magic-methods",
        "dunder",
        "operators",
        "special-methods"
      ],
      "estimatedMinutes": 10,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Class Methods, Static Methods, and Metaclasses",
      "content": "Understanding different types of methods and advanced class concepts like metaclasses helps you write more flexible and powerful object-oriented code.",
      "codeExample": "# Class methods and static methods\nclass Person:\n    population = 0\n    \n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n        Person.population += 1\n    \n    # Instance method (regular method)\n    def introduce(self):\n        return f\"Hi, I'm {self.name} and I'm {self.age} years old\"\n    \n    # Class method - works with the class, not instance\n    @classmethod\n    def get_population(cls):\n        return f\"Total population: {cls.population}\"\n    \n    @classmethod\n    def create_baby(cls, name):\n        return cls(name, 0)  # Alternative constructor\n    \n    # Static method - doesn't need class or instance\n    @staticmethod\n    def is_adult(age):\n        return age >= 18\n    \n    @staticmethod\n    def validate_name(name):\n        return isinstance(name, str) and len(name) > 0\n\n# Usage examples\nperson1 = Person(\"Alice\", 25)\nperson2 = Person(\"Bob\", 30)\n\n# Instance method\nprint(person1.introduce())\n\n# Class method\nprint(Person.get_population())  # Total population: 2\n\n# Alternative constructor\nbaby = Person.create_baby(\"Charlie\")\nprint(baby.introduce())  # Hi, I'm Charlie and I'm 0 years old\n\n# Static methods\nprint(Person.is_adult(25))  # True\nprint(Person.validate_name(\"Alice\"))  # True\n\n# Abstract base classes\nfrom abc import ABC, abstractmethod\n\nclass Shape(ABC):\n    @abstractmethod\n    def area(self):\n        pass\n    \n    @abstractmethod\n    def perimeter(self):\n        pass\n    \n    # Concrete method\n    def describe(self):\n        return f\"This is a shape with area {self.area()}\"\n\nclass Rectangle(Shape):\n    def __init__(self, width, height):\n        self.width = width\n        self.height = height\n    \n    def area(self):\n        return self.width * self.height\n    \n    def perimeter(self):\n        return 2 * (self.width + self.height)\n\n# Cannot instantiate abstract class\n# shape = Shape()  # TypeError\n\n# Can instantiate concrete implementation\nrect = Rectangle(5, 3)\nprint(rect.area())  # 15\nprint(rect.describe())  # This is a shape with area 15\n\n# Simple metaclass example\nclass SingletonMeta(type):\n    _instances = {}\n    \n    def __call__(cls, *args, **kwargs):\n        if cls not in cls._instances:\n            cls._instances[cls] = super().__call__(*args, **kwargs)\n        return cls._instances[cls]\n\nclass Database(metaclass=SingletonMeta):\n    def __init__(self):\n        self.connection = \"Connected to database\"\n    \n    def query(self, sql):\n        return f\"Executing: {sql}\"\n\n# Singleton behavior\ndb1 = Database()\ndb2 = Database()\nprint(db1 is db2)  # True - same instance\n\n# Property decorator alternative\nclass Circle:\n    def __init__(self, radius):\n        self._radius = radius\n    \n    @property\n    def radius(self):\n        return self._radius\n    \n    @radius.setter\n    def radius(self, value):\n        if value <= 0:\n            raise ValueError(\"Radius must be positive\")\n        self._radius = value\n    \n    @property\n    def area(self):\n        import math\n        return math.pi * self._radius ** 2\n    \n    @property\n    def diameter(self):\n        return 2 * self._radius\n\ncircle = Circle(5)\nprint(f\"Area: {circle.area:.2f}\")  # Area: 78.54\nprint(f\"Diameter: {circle.diameter}\")  # Diameter: 10",
      "difficulty": "advanced",
      "categorySlug": "oop",
      "xpReward": 32,
      "tags": [
        "classmethod",
        "staticmethod",
        "metaclass",
        "abc"
      ],
      "estimatedMinutes": 12,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "File Reading and Writing Best Practices",
      "content": "Python provides several ways to work with files. Understanding the different modes and best practices for file operations helps you handle data safely and efficiently.",
      "codeExample": "# Basic file operations with context manager\n# Reading files\nwith open('data.txt', 'r') as file:\n    content = file.read()  # Read entire file\n    print(content)\n\n# Reading line by line (memory efficient for large files)\nwith open('data.txt', 'r') as file:\n    for line in file:\n        print(line.strip())  # Remove newline characters\n\n# Reading all lines into a list\nwith open('data.txt', 'r') as file:\n    lines = file.readlines()\n\n# Reading specific number of characters\nwith open('data.txt', 'r') as file:\n    chunk = file.read(100)  # Read first 100 characters\n\n# Writing files\nwith open('output.txt', 'w') as file:\n    file.write(\"Hello, World!\\n\")\n    file.write(\"This is a new line.\")\n\n# Appending to files\nwith open('output.txt', 'a') as file:\n    file.write(\"\\nThis line is appended.\")\n\n# Writing multiple lines\nlines_to_write = [\"Line 1\\n\", \"Line 2\\n\", \"Line 3\\n\"]\nwith open('output.txt', 'w') as file:\n    file.writelines(lines_to_write)\n\n# Different file modes\n# 'r' - Read (default)\n# 'w' - Write (overwrites existing file)\n# 'a' - Append\n# 'x' - Create (fails if file exists)\n# 'b' - Binary mode (e.g., 'rb', 'wb')\n# 't' - Text mode (default)\n# '+' - Read and write (e.g., 'r+')\n\n# Working with CSV files\nimport csv\n\n# Writing CSV\ndata = [\n    ['Name', 'Age', 'City'],\n    ['Alice', '25', 'New York'],\n    ['Bob', '30', 'San Francisco']\n]\n\nwith open('people.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerows(data)\n\n# Reading CSV\nwith open('people.csv', 'r') as file:\n    reader = csv.reader(file)\n    for row in reader:\n        print(row)\n\n# CSV with dictionaries\nwith open('people.csv', 'r') as file:\n    reader = csv.DictReader(file)\n    for row in reader:\n        print(f\"Name: {row['Name']}, Age: {row['Age']}\")\n\n# Error handling\ntry:\n    with open('nonexistent.txt', 'r') as file:\n        content = file.read()\nexcept FileNotFoundError:\n    print(\"File not found!\")\nexcept PermissionError:\n    print(\"Permission denied!\")\nexcept IOError:\n    print(\"I/O error occurred!\")",
      "difficulty": "beginner",
      "categorySlug": "file-operations",
      "xpReward": 16,
      "tags": [
        "files",
        "reading",
        "writing",
        "csv"
      ],
      "estimatedMinutes": 6,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Working with Paths and Directories",
      "content": "The pathlib module provides an object-oriented approach to working with file paths. It's more readable and cross-platform compatible than string operations.",
      "codeExample": "# Using pathlib for better path handling\nfrom pathlib import Path\nimport os\nimport shutil\n\n# Creating Path objects\nhome = Path.home()  # User's home directory\ncurrent = Path.cwd()  # Current working directory\nfile_path = Path('data/files/document.txt')\n\n# Path operations\nprint(f\"Home directory: {home}\")\nprint(f\"Current directory: {current}\")\nprint(f\"File exists: {file_path.exists()}\")\nprint(f\"Is file: {file_path.is_file()}\")\nprint(f\"Is directory: {file_path.is_dir()}\")\n\n# Path components\nfile_path = Path('/home/user/documents/report.pdf')\nprint(f\"Parent: {file_path.parent}\")  # /home/user/documents\nprint(f\"Name: {file_path.name}\")      # report.pdf\nprint(f\"Stem: {file_path.stem}\")      # report\nprint(f\"Suffix: {file_path.suffix}\")  # .pdf\nprint(f\"Parts: {file_path.parts}\")    # ('/', 'home', 'user', 'documents', 'report.pdf')\n\n# Joining paths (cross-platform)\nbase_dir = Path('projects')\nsub_dir = base_dir / 'python' / 'scripts'\nfile_path = sub_dir / 'main.py'\nprint(file_path)  # projects/python/scripts/main.py\n\n# Creating directories\nnew_dir = Path('new_project/src/utils')\nnew_dir.mkdir(parents=True, exist_ok=True)  # Create all parent directories\n\n# Listing directory contents\ndata_dir = Path('.')\nfor item in data_dir.iterdir():\n    if item.is_file():\n        print(f\"File: {item.name}\")\n    elif item.is_dir():\n        print(f\"Directory: {item.name}\")\n\n# Finding files with patterns\n# Find all Python files\npython_files = list(Path('.').rglob('*.py'))\nfor py_file in python_files:\n    print(py_file)\n\n# Find files with specific name pattern\nconfig_files = list(Path('.').rglob('*config*'))\n\n# Working with file metadata\nfile_path = Path('example.txt')\nif file_path.exists():\n    stat = file_path.stat()\n    print(f\"Size: {stat.st_size} bytes\")\n    print(f\"Modified: {stat.st_mtime}\")\n    \n# File operations\nsource = Path('source.txt')\ndestination = Path('backup/source_backup.txt')\n\n# Copy file\ndestination.parent.mkdir(exist_ok=True)\nshutil.copy2(source, destination)\n\n# Move/rename file\nold_name = Path('old_file.txt')\nnew_name = Path('new_file.txt')\nif old_name.exists():\n    old_name.rename(new_name)\n\n# Delete file\ntemp_file = Path('temp.txt')\nif temp_file.exists():\n    temp_file.unlink()  # Delete file\n\n# Delete directory\ntemp_dir = Path('temp_directory')\nif temp_dir.exists():\n    shutil.rmtree(temp_dir)  # Delete directory and contents\n\n# Cross-platform path handling\n# Don't do this: path = 'folder\\\\file.txt'  # Windows only\n# Do this instead:\npath = Path('folder') / 'file.txt'  # Works on all platforms\n\n# Working with absolute and relative paths\nrelative_path = Path('data/file.txt')\nabsolute_path = relative_path.resolve()\nprint(f\"Absolute path: {absolute_path}\")",
      "difficulty": "intermediate",
      "categorySlug": "file-operations",
      "xpReward": 20,
      "tags": [
        "pathlib",
        "directories",
        "file-system",
        "cross-platform"
      ],
      "estimatedMinutes": 7,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "JSON and Configuration Files",
      "content": "Working with JSON files is common in modern applications. Python's json module makes it easy to read, write, and manipulate JSON data for configuration files, APIs, and data storage.",
      "codeExample": "import json\nfrom pathlib import Path\n\n# Basic JSON operations\ndata = {\n    \"name\": \"Alice\",\n    \"age\": 30,\n    \"skills\": [\"Python\", \"JavaScript\", \"SQL\"],\n    \"is_active\": True,\n    \"projects\": [\n        {\"name\": \"Web App\", \"status\": \"completed\"},\n        {\"name\": \"API\", \"status\": \"in_progress\"}\n    ]\n}\n\n# Writing JSON to file\nwith open('user_data.json', 'w') as file:\n    json.dump(data, file, indent=2)\n\n# Reading JSON from file\nwith open('user_data.json', 'r') as file:\n    loaded_data = json.load(file)\n    print(loaded_data[\"name\"])  # Alice\n\n# Converting to/from JSON strings\njson_string = json.dumps(data, indent=2)\nparsed_data = json.loads(json_string)\n\n# Pretty printing JSON\nprint(json.dumps(data, indent=2, sort_keys=True))\n\n# Configuration file management\nclass ConfigManager:\n    def __init__(self, config_file='config.json'):\n        self.config_file = Path(config_file)\n        self.config = self.load_config()\n    \n    def load_config(self):\n        if self.config_file.exists():\n            with open(self.config_file, 'r') as file:\n                return json.load(file)\n        else:\n            # Default configuration\n            return {\n                \"database\": {\n                    \"host\": \"localhost\",\n                    \"port\": 5432,\n                    \"name\": \"myapp\"\n                },\n                \"api\": {\n                    \"base_url\": \"https://api.example.com\",\n                    \"timeout\": 30\n                },\n                \"logging\": {\n                    \"level\": \"INFO\",\n                    \"file\": \"app.log\"\n                }\n            }\n    \n    def save_config(self):\n        with open(self.config_file, 'w') as file:\n            json.dump(self.config, file, indent=2)\n    \n    def get(self, key_path, default=None):\n        \"\"\"Get nested configuration value using dot notation\"\"\"\n        keys = key_path.split('.')\n        value = self.config\n        for key in keys:\n            if isinstance(value, dict) and key in value:\n                value = value[key]\n            else:\n                return default\n        return value\n    \n    def set(self, key_path, value):\n        \"\"\"Set nested configuration value using dot notation\"\"\"\n        keys = key_path.split('.')\n        config = self.config\n        for key in keys[:-1]:\n            if key not in config:\n                config[key] = {}\n            config = config[key]\n        config[keys[-1]] = value\n        self.save_config()\n\n# Using the configuration manager\nconfig = ConfigManager()\nprint(config.get('database.host'))  # localhost\nconfig.set('database.host', 'production-server')\n\n# Handling JSON errors\ndef safe_json_load(file_path):\n    try:\n        with open(file_path, 'r') as file:\n            return json.load(file)\n    except FileNotFoundError:\n        print(f\"File {file_path} not found\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {file_path}: {e}\")\n        return None\n\n# Working with nested JSON data\nnested_data = {\n    \"users\": [\n        {\n            \"id\": 1,\n            \"profile\": {\n                \"personal\": {\n                    \"name\": \"Alice\",\n                    \"email\": \"alice@example.com\"\n                },\n                \"preferences\": {\n                    \"theme\": \"dark\",\n                    \"notifications\": True\n                }\n            }\n        }\n    ]\n}\n\n# Safely accessing nested data\ndef get_nested_value(data, keys, default=None):\n    for key in keys:\n        if isinstance(data, dict) and key in data:\n            data = data[key]\n        elif isinstance(data, list) and isinstance(key, int) and 0 <= key < len(data):\n            data = data[key]\n        else:\n            return default\n    return data\n\n# Usage\nuser_name = get_nested_value(nested_data, [\"users\", 0, \"profile\", \"personal\", \"name\"])\nprint(user_name)  # Alice\n\n# Custom JSON encoder for special types\nimport datetime\n\nclass DateTimeEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, datetime.datetime):\n            return obj.isoformat()\n        return super().default(obj)\n\n# Using custom encoder\ndata_with_datetime = {\n    \"timestamp\": datetime.datetime.now(),\n    \"message\": \"Hello World\"\n}\n\njson_str = json.dumps(data_with_datetime, cls=DateTimeEncoder)\nprint(json_str)",
      "difficulty": "intermediate",
      "categorySlug": "file-operations",
      "xpReward": 22,
      "tags": [
        "json",
        "configuration",
        "data-storage",
        "serialization"
      ],
      "estimatedMinutes": 8,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Binary Files and Advanced File Operations",
      "content": "Working with binary files, handling large files efficiently, and performing advanced file operations like compression and encryption are important skills for real-world applications.",
      "codeExample": "# Binary file operations\nimport pickle\nimport gzip\nimport zipfile\nimport tarfile\nfrom pathlib import Path\n\n# Working with binary files\n# Writing binary data\nbinary_data = b'\\x89PNG\\r\\n\\x1a\\n'  # PNG file signature\nwith open('test.bin', 'wb') as file:\n    file.write(binary_data)\n\n# Reading binary data\nwith open('test.bin', 'rb') as file:\n    data = file.read()\n    print(f\"Read {len(data)} bytes\")\n\n# Pickling (serializing Python objects)\ndata_to_pickle = {\n    'numbers': [1, 2, 3, 4, 5],\n    'text': 'Hello, World!',\n    'nested': {'key': 'value'}\n}\n\n# Save object to file\nwith open('data.pickle', 'wb') as file:\n    pickle.dump(data_to_pickle, file)\n\n# Load object from file\nwith open('data.pickle', 'rb') as file:\n    loaded_data = pickle.load(file)\n    print(loaded_data)\n\n# Working with compressed files\n# Gzip compression\ntext_data = \"This is some text that will be compressed.\" * 100\n\n# Compress and save\nwith gzip.open('compressed.txt.gz', 'wt') as file:\n    file.write(text_data)\n\n# Read compressed file\nwith gzip.open('compressed.txt.gz', 'rt') as file:\n    decompressed = file.read()\n\n# ZIP file operations\n# Creating a ZIP file\nwith zipfile.ZipFile('archive.zip', 'w') as zip_file:\n    zip_file.write('file1.txt')\n    zip_file.write('file2.txt')\n    # Add file with different name in archive\n    zip_file.write('source.txt', 'renamed_in_zip.txt')\n\n# Reading from ZIP file\nwith zipfile.ZipFile('archive.zip', 'r') as zip_file:\n    # List contents\n    for file_info in zip_file.filelist:\n        print(f\"File: {file_info.filename}, Size: {file_info.file_size}\")\n    \n    # Extract all files\n    zip_file.extractall('extracted_files/')\n    \n    # Extract specific file\n    zip_file.extract('file1.txt', 'specific_extraction/')\n    \n    # Read file directly from ZIP\n    with zip_file.open('file1.txt') as file:\n        content = file.read().decode('utf-8')\n\n# Large file processing (memory efficient)\ndef process_large_file(file_path, chunk_size=1024*1024):  # 1MB chunks\n    \"\"\"Process large file in chunks to avoid memory issues\"\"\"\n    total_size = 0\n    line_count = 0\n    \n    with open(file_path, 'r') as file:\n        while True:\n            chunk = file.read(chunk_size)\n            if not chunk:\n                break\n            \n            total_size += len(chunk)\n            line_count += chunk.count('\\n')\n    \n    return total_size, line_count\n\n# File locking (platform dependent)\nimport fcntl  # Unix/Linux only\nimport msvcrt  # Windows only\n\ndef lock_file_unix(file_obj):\n    \"\"\"Lock file on Unix/Linux systems\"\"\"\n    try:\n        fcntl.flock(file_obj.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)\n        return True\n    except (IOError, OSError):\n        return False\n\ndef lock_file_windows(file_obj):\n    \"\"\"Lock file on Windows systems\"\"\"\n    try:\n        msvcrt.locking(file_obj.fileno(), msvcrt.LK_NBLCK, 1)\n        return True\n    except (IOError, OSError):\n        return False\n\n# Temporary files\nimport tempfile\n\n# Create temporary file\nwith tempfile.NamedTemporaryFile(mode='w', delete=False) as temp_file:\n    temp_file.write(\"Temporary data\")\n    temp_file_path = temp_file.name\n\n# Use temporary directory\nwith tempfile.TemporaryDirectory() as temp_dir:\n    temp_path = Path(temp_dir)\n    (temp_path / 'temp_file.txt').write_text(\"Temporary file in temp directory\")\n    # Directory and contents automatically deleted when exiting context\n\n# File monitoring and watching\nimport time\nimport hashlib\n\ndef file_changed(file_path, last_hash=None):\n    \"\"\"Check if file has changed by comparing hash\"\"\"\n    try:\n        with open(file_path, 'rb') as file:\n            content = file.read()\n            current_hash = hashlib.md5(content).hexdigest()\n            return current_hash != last_hash, current_hash\n    except FileNotFoundError:\n        return False, None\n\n# Memory mapping for large files\nimport mmap\n\ndef search_in_large_file(file_path, search_term):\n    \"\"\"Search in large file using memory mapping\"\"\"\n    with open(file_path, 'rb') as file:\n        with mmap.mmap(file.fileno(), 0, access=mmap.ACCESS_READ) as mmapped_file:\n            index = mmapped_file.find(search_term.encode())\n            return index if index != -1 else None\n\n# Atomic file operations\ndef atomic_write(file_path, content):\n    \"\"\"Write file atomically to prevent corruption\"\"\"\n    temp_path = f\"{file_path}.tmp\"\n    try:\n        with open(temp_path, 'w') as temp_file:\n            temp_file.write(content)\n        \n        # Atomic rename (platform dependent)\n        Path(temp_path).rename(file_path)\n    except Exception:\n        # Clean up temporary file if operation fails\n        Path(temp_path).unlink(missing_ok=True)\n        raise",
      "difficulty": "advanced",
      "categorySlug": "file-operations",
      "xpReward": 28,
      "tags": [
        "binary",
        "compression",
        "pickle",
        "large-files",
        "advanced"
      ],
      "estimatedMinutes": 10,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Code Style and PEP 8 Guidelines",
      "content": "PEP 8 is the official style guide for Python code. Following these conventions makes your code more readable and consistent with the Python community standards.",
      "codeExample": "# Good naming conventions\nclass UserManager:  # Class names: CapWords\n    def __init__(self):\n        self.user_count = 0  # Instance variables: lowercase_with_underscores\n    \n    def get_user_info(self, user_id):  # Function names: lowercase_with_underscores\n        \"\"\"Get user information by ID.\"\"\"  # Docstrings for functions\n        return f\"User {user_id}\"\n\n# Constants\nMAX_CONNECTIONS = 100  # Constants: UPPERCASE_WITH_UNDERSCORES\nDEFAULT_TIMEOUT = 30\n\n# Good indentation and spacing\ndef calculate_total(items, tax_rate=0.08, discount=0.0):\n    \"\"\"\n    Calculate total with tax and discount.\n    \n    Args:\n        items (list): List of item prices\n        tax_rate (float): Tax rate (default 0.08)\n        discount (float): Discount rate (default 0.0)\n    \n    Returns:\n        float: Total amount after tax and discount\n    \"\"\"\n    subtotal = sum(items)\n    discounted_total = subtotal * (1 - discount)\n    total_with_tax = discounted_total * (1 + tax_rate)\n    return round(total_with_tax, 2)\n\n# Line length (max 79 characters for code, 72 for comments)\ndef long_function_name(\n    parameter_one, parameter_two, parameter_three,\n    parameter_four, parameter_five\n):\n    return parameter_one + parameter_two\n\n# Imports organization\n# 1. Standard library imports\nimport os\nimport sys\nfrom pathlib import Path\n\n# 2. Related third party imports\nimport requests\nimport numpy as np\n\n# 3. Local application/library specific imports\nfrom myproject.utils import helper_function\nfrom myproject.models import User\n\n# Good use of whitespace\n# Yes:\nif x == 4:\n    print(x, y)\n    x, y = y, x\n\n# No:\n# if x == 4 : print x , y ; x , y = y , x\n\n# List comprehensions vs traditional loops\n# Good - simple and readable\nsquares = [x**2 for x in range(10)]\n\n# Bad - too complex for list comprehension\n# result = [complicated_function(x) for x in items if complex_condition(x)]\n\n# Better - use regular loop for complex logic\nresult = []\nfor x in items:\n    if complex_condition(x):\n        result.append(complicated_function(x))\n\n# Avoid lambda for complex operations\n# Good\ndef is_adult(person):\n    return person.age >= 18\n\nadults = filter(is_adult, people)\n\n# Bad\n# adults = filter(lambda p: p.age >= 18 and p.status == 'active', people)\n\n# String quotes consistency\nmessage = \"Use double quotes for strings\"\nchar = 'a'  # Single quotes for single characters\nsql_query = '''\nSELECT * FROM users\nWHERE name = \"John\"\n'''  # Triple quotes for multi-line strings",
      "difficulty": "beginner",
      "categorySlug": "best-practices",
      "xpReward": 15,
      "tags": [
        "pep8",
        "style",
        "conventions",
        "readability"
      ],
      "estimatedMinutes": 5,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Error Handling and Exception Management",
      "content": "Proper error handling makes your code more robust and user-friendly. Understanding when and how to use exceptions helps prevent crashes and provides meaningful error messages.",
      "codeExample": "# Basic exception handling\ntry:\n    result = 10 / 0\nexcept ZeroDivisionError:\n    print(\"Cannot divide by zero\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\nelse:\n    print(f\"Result: {result}\")  # Runs if no exception\nfinally:\n    print(\"This always runs\")  # Cleanup code\n\n# Specific exception handling\ndef process_user_input(user_input):\n    try:\n        # Try to convert input to integer\n        number = int(user_input)\n        \n        # Try to perform calculation\n        result = 100 / number\n        \n        return result\n        \n    except ValueError:\n        raise ValueError(f\"'{user_input}' is not a valid number\")\n    except ZeroDivisionError:\n        raise ValueError(\"Number cannot be zero\")\n    except Exception as e:\n        # Log unexpected errors\n        print(f\"Unexpected error processing '{user_input}': {e}\")\n        raise\n\n# Custom exceptions\nclass ValidationError(Exception):\n    \"\"\"Raised when data validation fails\"\"\"\n    pass\n\nclass DatabaseError(Exception):\n    \"\"\"Raised when database operations fail\"\"\"\n    def __init__(self, message, error_code=None):\n        super().__init__(message)\n        self.error_code = error_code\n\n# Using custom exceptions\ndef validate_email(email):\n    if '@' not in email:\n        raise ValidationError(f\"Invalid email format: {email}\")\n    return True\n\ndef save_user(user_data):\n    try:\n        validate_email(user_data['email'])\n        # Simulate database save\n        if not user_data.get('name'):\n            raise DatabaseError(\"Name is required\", error_code=\"MISSING_NAME\")\n        print(\"User saved successfully\")\n    except ValidationError as e:\n        print(f\"Validation failed: {e}\")\n    except DatabaseError as e:\n        print(f\"Database error ({e.error_code}): {e}\")\n\n# Context managers for resource management\nclass DatabaseConnection:\n    def __enter__(self):\n        print(\"Connecting to database...\")\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        print(\"Closing database connection...\")\n        if exc_type:\n            print(f\"Exception occurred: {exc_val}\")\n        return False  # Don't suppress exceptions\n\n# Using context manager\ntry:\n    with DatabaseConnection() as db:\n        # Database operations here\n        # Connection automatically closed even if exception occurs\n        pass\nexcept Exception as e:\n    print(f\"Database operation failed: {e}\")\n\n# Logging instead of print statements\nimport logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\nlogger = logging.getLogger(__name__)\n\ndef risky_operation():\n    try:\n        # Some risky operation\n        logger.info(\"Starting risky operation\")\n        result = complex_calculation()\n        logger.info(\"Operation completed successfully\")\n        return result\n    except Exception as e:\n        logger.error(f\"Operation failed: {e}\", exc_info=True)\n        raise\n\n# Graceful degradation\ndef get_user_preferences(user_id):\n    try:\n        # Try to get from cache first\n        return cache.get(f\"user_prefs_{user_id}\")\n    except CacheError:\n        logger.warning(\"Cache unavailable, fetching from database\")\n        try:\n            return database.get_user_preferences(user_id)\n        except DatabaseError:\n            logger.error(\"Database unavailable, using defaults\")\n            return get_default_preferences()\n\n# Assertion for debugging (not for production error handling)\ndef calculate_area(width, height):\n    assert width > 0, \"Width must be positive\"\n    assert height > 0, \"Height must be positive\"\n    return width * height\n\n# Don't catch exceptions just to re-raise\n# Bad:\n# try:\n#     risky_function()\n# except Exception as e:\n#     raise e\n\n# Good - let it propagate or handle meaningfully:\n# risky_function()  # Or handle the specific exception",
      "difficulty": "intermediate",
      "categorySlug": "best-practices",
      "xpReward": 22,
      "tags": [
        "exceptions",
        "error-handling",
        "logging",
        "debugging"
      ],
      "estimatedMinutes": 7,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Code Organization and Project Structure",
      "content": "Organizing your code into logical modules and packages makes it maintainable, testable, and reusable. Good project structure follows established conventions.",
      "codeExample": "# Recommended project structure\n\"\"\"\nmy_project/\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ requirements.txt\n‚îú‚îÄ‚îÄ setup.py\n‚îú‚îÄ‚îÄ .gitignore\n‚îú‚îÄ‚îÄ tests/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îú‚îÄ‚îÄ test_models.py\n‚îÇ   ‚îú‚îÄ‚îÄ test_utils.py\n‚îÇ   ‚îî‚îÄ‚îÄ test_integration.py\n‚îú‚îÄ‚îÄ docs/\n‚îÇ   ‚îú‚îÄ‚îÄ api.md\n‚îÇ   ‚îî‚îÄ‚îÄ user_guide.md\n‚îú‚îÄ‚îÄ my_project/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îú‚îÄ‚îÄ main.py\n‚îÇ   ‚îú‚îÄ‚îÄ config.py\n‚îÇ   ‚îú‚îÄ‚îÄ models/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ product.py\n‚îÇ   ‚îú‚îÄ‚îÄ utils/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ helpers.py\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validators.py\n‚îÇ   ‚îî‚îÄ‚îÄ api/\n‚îÇ       ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ       ‚îú‚îÄ‚îÄ routes.py\n‚îÇ       ‚îî‚îÄ‚îÄ handlers.py\n‚îî‚îÄ‚îÄ scripts/\n    ‚îú‚îÄ‚îÄ setup_db.py\n    ‚îî‚îÄ‚îÄ migrate_data.py\n\"\"\"\n\n# __init__.py files for packages\n# my_project/__init__.py\n\"\"\"\nMain package initialization.\n\"\"\"\n__version__ = \"1.0.0\"\n__author__ = \"Your Name\"\n\nfrom .main import main_function\nfrom .config import settings\n\n# models/__init__.py\nfrom .user import User\nfrom .product import Product\n\n__all__ = ['User', 'Product']\n\n# Configuration management\n# config.py\nimport os\nfrom pathlib import Path\n\nclass Config:\n    \"\"\"Base configuration\"\"\"\n    BASE_DIR = Path(__file__).parent\n    SECRET_KEY = os.environ.get('SECRET_KEY', 'dev-secret-key')\n    DEBUG = False\n    \nclass DevelopmentConfig(Config):\n    \"\"\"Development configuration\"\"\"\n    DEBUG = True\n    DATABASE_URL = 'sqlite:///dev.db'\n    \nclass ProductionConfig(Config):\n    \"\"\"Production configuration\"\"\"\n    DATABASE_URL = os.environ.get('DATABASE_URL')\n    \nclass TestingConfig(Config):\n    \"\"\"Testing configuration\"\"\"\n    TESTING = True\n    DATABASE_URL = 'sqlite:///:memory:'\n\n# Configuration factory\ndef get_config():\n    env = os.environ.get('FLASK_ENV', 'development')\n    if env == 'production':\n        return ProductionConfig()\n    elif env == 'testing':\n        return TestingConfig()\n    else:\n        return DevelopmentConfig()\n\n# Modular code organization\n# models/user.py\nfrom dataclasses import dataclass\nfrom typing import Optional, List\n\n@dataclass\nclass User:\n    \"\"\"User model with validation\"\"\"\n    id: int\n    username: str\n    email: str\n    is_active: bool = True\n    \n    def __post_init__(self):\n        self.validate()\n    \n    def validate(self):\n        if not self.username or len(self.username) < 3:\n            raise ValueError(\"Username must be at least 3 characters\")\n        if '@' not in self.email:\n            raise ValueError(\"Invalid email format\")\n    \n    @classmethod\n    def create(cls, username: str, email: str) -> 'User':\n        \"\"\"Factory method to create user\"\"\"\n        # Generate ID (in real app, this would be from database)\n        user_id = hash(username) % 10000\n        return cls(id=user_id, username=username, email=email)\n\n# utils/helpers.py\nfrom typing import Any, Dict, List\nimport json\n\ndef safe_get(dictionary: Dict[str, Any], key: str, default: Any = None) -> Any:\n    \"\"\"Safely get value from dictionary\"\"\"\n    return dictionary.get(key, default)\n\ndef load_json_file(file_path: str) -> Dict[str, Any]:\n    \"\"\"Load JSON file with error handling\"\"\"\n    try:\n        with open(file_path, 'r') as file:\n            return json.load(file)\n    except (FileNotFoundError, json.JSONDecodeError) as e:\n        print(f\"Error loading {file_path}: {e}\")\n        return {}\n\ndef chunk_list(lst: List[Any], chunk_size: int) -> List[List[Any]]:\n    \"\"\"Split list into chunks of specified size\"\"\"\n    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n\n# main.py - entry point\nimport sys\nfrom pathlib import Path\n\n# Add project root to Python path\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\nfrom my_project.config import get_config\nfrom my_project.models import User\nfrom my_project.utils.helpers import load_json_file\n\ndef main():\n    \"\"\"Main application entry point\"\"\"\n    config = get_config()\n    print(f\"Starting application in {config.__class__.__name__} mode\")\n    \n    # Application logic here\n    user = User.create(\"alice\", \"alice@example.com\")\n    print(f\"Created user: {user}\")\n\nif __name__ == \"__main__\":\n    main()\n\n# setup.py for package distribution\nfrom setuptools import setup, find_packages\n\nwith open(\"README.md\", \"r\", encoding=\"utf-8\") as fh:\n    long_description = fh.read()\n\nsetup(\n    name=\"my-project\",\n    version=\"1.0.0\",\n    author=\"Your Name\",\n    author_email=\"your.email@example.com\",\n    description=\"A short description of your project\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    packages=find_packages(),\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    python_requires=\">=3.8\",\n    install_requires=[\n        \"requests>=2.25.0\",\n        \"click>=8.0.0\",\n    ],\n    entry_points={\n        \"console_scripts\": [\n            \"my-project=my_project.main:main\",\n        ],\n    },\n)",
      "difficulty": "intermediate",
      "categorySlug": "best-practices",
      "xpReward": 24,
      "tags": [
        "organization",
        "structure",
        "modules",
        "packages"
      ],
      "estimatedMinutes": 8,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Performance Best Practices",
      "content": "Writing efficient Python code requires understanding performance implications of different approaches. Small changes can lead to significant performance improvements.",
      "codeExample": "# List comprehensions vs traditional loops\nimport time\n\n# Timing decorator\ndef timing_decorator(func):\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        result = func(*args, **kwargs)\n        end = time.time()\n        print(f\"{func.__name__} took {end - start:.4f} seconds\")\n        return result\n    return wrapper\n\n# List comprehensions are faster\n@timing_decorator\ndef traditional_loop():\n    result = []\n    for i in range(100000):\n        if i % 2 == 0:\n            result.append(i ** 2)\n    return result\n\n@timing_decorator\ndef list_comprehension():\n    return [i ** 2 for i in range(100000) if i % 2 == 0]\n\n# Generator expressions for memory efficiency\n@timing_decorator\ndef generator_expression():\n    return (i ** 2 for i in range(100000) if i % 2 == 0)\n\n# Using built-in functions (often implemented in C)\n@timing_decorator\ndef using_map_filter():\n    evens = filter(lambda x: x % 2 == 0, range(100000))\n    return list(map(lambda x: x ** 2, evens))\n\n# String concatenation optimization\n# Slow - creates new string each time\n@timing_decorator\ndef slow_string_concat():\n    result = \"\"\n    for i in range(1000):\n        result += f\"Number {i} \"\n    return result\n\n# Fast - join is optimized for string concatenation\n@timing_decorator\ndef fast_string_concat():\n    parts = []\n    for i in range(1000):\n        parts.append(f\"Number {i} \")\n    return \"\".join(parts)\n\n# Even better - direct list comprehension with join\n@timing_decorator\ndef fastest_string_concat():\n    return \" \".join(f\"Number {i}\" for i in range(1000))\n\n# Dictionary vs list for lookups\n@timing_decorator\ndef list_lookup():\n    items = list(range(10000))\n    return 9999 in items  # O(n) operation\n\n@timing_decorator\ndef dict_lookup():\n    items = {i: True for i in range(10000)}\n    return 9999 in items  # O(1) operation\n\n# Set operations for unique items\n@timing_decorator\ndef list_unique():\n    items = [1, 2, 3, 4, 5] * 1000\n    unique = []\n    for item in items:\n        if item not in unique:\n            unique.append(item)\n    return unique\n\n@timing_decorator\ndef set_unique():\n    items = [1, 2, 3, 4, 5] * 1000\n    return list(set(items))\n\n# Local variable access is faster\n@timing_decorator\ndef global_access():\n    total = 0\n    for i in range(100000):\n        total += len(str(i))  # Global function lookup each time\n    return total\n\n@timing_decorator\ndef local_access():\n    str_func = str  # Local reference\n    len_func = len\n    total = 0\n    for i in range(100000):\n        total += len_func(str_func(i))\n    return total\n\n# Using collections.defaultdict vs dict.setdefault\nfrom collections import defaultdict\n\n@timing_decorator\ndef using_setdefault():\n    counter = {}\n    for i in range(10000):\n        key = i % 100\n        counter.setdefault(key, 0)\n        counter[key] += 1\n    return counter\n\n@timing_decorator\ndef using_defaultdict():\n    counter = defaultdict(int)\n    for i in range(10000):\n        key = i % 100\n        counter[key] += 1\n    return dict(counter)\n\n# Memory-efficient iteration\ndef memory_efficient_processing(large_dataset):\n    \"\"\"Process large dataset without loading everything into memory\"\"\"\n    \n    # Instead of loading all data\n    # data = [expensive_operation(item) for item in large_dataset]\n    \n    # Use generator for lazy evaluation\n    processed_data = (expensive_operation(item) for item in large_dataset)\n    \n    # Process one item at a time\n    results = []\n    for item in processed_data:\n        if meets_criteria(item):\n            results.append(item)\n        \n        # Optional: limit memory usage\n        if len(results) > 1000:\n            yield results\n            results = []\n    \n    if results:\n        yield results\n\ndef expensive_operation(item):\n    return item ** 2\n\ndef meets_criteria(item):\n    return item > 100\n\n# Caching for expensive computations\nfrom functools import lru_cache\n\n@lru_cache(maxsize=128)\ndef expensive_fibonacci(n):\n    if n < 2:\n        return n\n    return expensive_fibonacci(n-1) + expensive_fibonacci(n-2)\n\n# Without cache: fibonacci(30) takes long time\n# With cache: subsequent calls are instant\n\n# Profile your code\nimport cProfile\nimport pstats\n\ndef profile_function(func, *args, **kwargs):\n    \"\"\"Profile a function to identify bottlenecks\"\"\"\n    profiler = cProfile.Profile()\n    profiler.enable()\n    \n    result = func(*args, **kwargs)\n    \n    profiler.disable()\n    stats = pstats.Stats(profiler)\n    stats.sort_stats('cumulative')\n    stats.print_stats(10)  # Show top 10 functions\n    \n    return result\n\n# Memory profiling with memory_profiler\n# pip install memory-profiler\n# @profile\n# def memory_intensive_function():\n#     big_list = [i for i in range(1000000)]\n#     return sum(big_list)\n\n# Run with: python -m memory_profiler your_script.py",
      "difficulty": "advanced",
      "categorySlug": "best-practices",
      "xpReward": 28,
      "tags": [
        "performance",
        "optimization",
        "efficiency",
        "profiling"
      ],
      "estimatedMinutes": 10,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Security Best Practices",
      "content": "Writing secure Python code requires awareness of common vulnerabilities and implementing proper security measures. Security should be considered from the beginning of development.",
      "codeExample": "# Input validation and sanitization\nimport re\nimport hashlib\nimport secrets\nimport hmac\nfrom pathlib import Path\n\ndef validate_email(email):\n    \"\"\"Validate email format\"\"\"\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return re.match(pattern, email) is not None\n\ndef sanitize_filename(filename):\n    \"\"\"Sanitize filename to prevent directory traversal\"\"\"\n    # Remove path separators and dangerous characters\n    sanitized = re.sub(r'[<>:\"/\\|?*]', '', filename)\n    sanitized = sanitized.replace('..', '')\n    return sanitized[:255]  # Limit length\n\ndef validate_user_input(user_input, max_length=1000):\n    \"\"\"Basic input validation\"\"\"\n    if not isinstance(user_input, str):\n        raise ValueError(\"Input must be a string\")\n    \n    if len(user_input) > max_length:\n        raise ValueError(f\"Input too long (max {max_length} characters)\")\n    \n    # Remove potentially dangerous characters\n    dangerous_chars = ['<', '>', '\"', \"'\", '&', '%', ';']\n    for char in dangerous_chars:\n        if char in user_input:\n            raise ValueError(f\"Invalid character detected: {char}\")\n    \n    return user_input.strip()\n\n# Password security\nclass PasswordManager:\n    @staticmethod\n    def hash_password(password: str) -> tuple:\n        \"\"\"Hash password with salt\"\"\"\n        # Generate random salt\n        salt = secrets.token_hex(16)\n        \n        # Hash password with salt\n        password_hash = hashlib.pbkdf2_hmac(\n            'sha256',\n            password.encode('utf-8'),\n            salt.encode('utf-8'),\n            100000  # Number of iterations\n        )\n        \n        return salt, password_hash.hex()\n    \n    @staticmethod\n    def verify_password(password: str, salt: str, stored_hash: str) -> bool:\n        \"\"\"Verify password against stored hash\"\"\"\n        password_hash = hashlib.pbkdf2_hmac(\n            'sha256',\n            password.encode('utf-8'),\n            salt.encode('utf-8'),\n            100000\n        )\n        \n        return hmac.compare_digest(password_hash.hex(), stored_hash)\n    \n    @staticmethod\n    def generate_secure_password(length=12):\n        \"\"\"Generate cryptographically secure password\"\"\"\n        alphabet = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&*\"\n        return ''.join(secrets.choice(alphabet) for _ in range(length))\n\n# Secure file operations\ndef secure_file_read(file_path, allowed_extensions=None):\n    \"\"\"Securely read file with validation\"\"\"\n    path = Path(file_path)\n    \n    # Validate file extension\n    if allowed_extensions and path.suffix.lower() not in allowed_extensions:\n        raise ValueError(f\"File type not allowed: {path.suffix}\")\n    \n    # Prevent directory traversal\n    if '..' in str(path) or path.is_absolute():\n        raise ValueError(\"Invalid file path\")\n    \n    # Check if file exists and is a file\n    if not path.exists() or not path.is_file():\n        raise FileNotFoundError(\"File not found\")\n    \n    # Read file safely\n    try:\n        with open(path, 'r', encoding='utf-8') as file:\n            return file.read()\n    except UnicodeDecodeError:\n        raise ValueError(\"File contains invalid characters\")\n\n# SQL injection prevention (using parameterized queries)\nimport sqlite3\n\nclass SafeDatabase:\n    def __init__(self, db_path):\n        self.connection = sqlite3.connect(db_path)\n        self.cursor = self.connection.cursor()\n    \n    def get_user_by_id(self, user_id):\n        \"\"\"Safe database query using parameterized statements\"\"\"\n        # Safe - uses parameterized query\n        query = \"SELECT * FROM users WHERE id = ?\"\n        self.cursor.execute(query, (user_id,))\n        return self.cursor.fetchone()\n    \n    def search_users(self, name_pattern):\n        \"\"\"Safe search with LIKE parameter\"\"\"\n        # Safe - parameterized LIKE query\n        query = \"SELECT * FROM users WHERE name LIKE ?\"\n        self.cursor.execute(query, (f\"%{name_pattern}%\",))\n        return self.cursor.fetchall()\n    \n    def unsafe_query(self, user_input):\n        \"\"\"NEVER DO THIS - vulnerable to SQL injection\"\"\"\n        # Dangerous - string formatting\n        # query = f\"SELECT * FROM users WHERE name = '{user_input}'\"\n        # self.cursor.execute(query)\n        \n        # This would allow: user_input = \"'; DROP TABLE users; --\"\n        raise NotImplementedError(\"This method demonstrates unsafe practices\")\n\n# Environment variables for sensitive data\nimport os\n\ndef get_secret(secret_name, default=None):\n    \"\"\"Get secret from environment variables\"\"\"\n    secret = os.environ.get(secret_name, default)\n    if secret is None:\n        raise ValueError(f\"Required secret '{secret_name}' not found\")\n    return secret\n\n# Configuration class with security considerations\nclass SecureConfig:\n    def __init__(self):\n        # Never hardcode secrets!\n        self.database_url = get_secret('DATABASE_URL')\n        self.api_key = get_secret('API_KEY')\n        self.secret_key = get_secret('SECRET_KEY')\n        \n        # Public configuration\n        self.debug = os.environ.get('DEBUG', 'False').lower() == 'true'\n        self.max_upload_size = int(os.environ.get('MAX_UPLOAD_SIZE', '10485760'))  # 10MB\n\n# Secure random token generation\ndef generate_secure_token(length=32):\n    \"\"\"Generate cryptographically secure random token\"\"\"\n    return secrets.token_urlsafe(length)\n\ndef generate_csrf_token():\n    \"\"\"Generate CSRF token\"\"\"\n    return secrets.token_hex(16)\n\n# Rate limiting helper\nimport time\nfrom collections import defaultdict\n\nclass RateLimiter:\n    def __init__(self, max_requests=100, window_seconds=3600):\n        self.max_requests = max_requests\n        self.window_seconds = window_seconds\n        self.requests = defaultdict(list)\n    \n    def is_allowed(self, identifier):\n        \"\"\"Check if request is within rate limit\"\"\"\n        now = time.time()\n        window_start = now - self.window_seconds\n        \n        # Clean old requests\n        self.requests[identifier] = [\n            req_time for req_time in self.requests[identifier]\n            if req_time > window_start\n        ]\n        \n        # Check if under limit\n        if len(self.requests[identifier]) < self.max_requests:\n            self.requests[identifier].append(now)\n            return True\n        \n        return False\n\n# Data validation with type hints\nfrom typing import Union, Optional\nimport json\n\ndef safe_json_loads(data: str) -> Union[dict, list]:\n    \"\"\"Safely parse JSON with validation\"\"\"\n    try:\n        parsed = json.loads(data)\n        if not isinstance(parsed, (dict, list)):\n            raise ValueError(\"JSON must be object or array\")\n        return parsed\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON: {e}\")\n\n# Logging security events\nimport logging\n\nsecurity_logger = logging.getLogger('security')\nsecurity_logger.setLevel(logging.WARNING)\n\ndef log_security_event(event_type, details, user_id=None):\n    \"\"\"Log security-related events\"\"\"\n    security_logger.warning(\n        f\"Security Event: {event_type} | User: {user_id} | Details: {details}\"\n    )\n\n# Example usage\ndef login_attempt(username, password, ip_address):\n    \"\"\"Example secure login function\"\"\"\n    rate_limiter = RateLimiter(max_requests=5, window_seconds=300)  # 5 attempts per 5 minutes\n    \n    if not rate_limiter.is_allowed(ip_address):\n        log_security_event(\"RATE_LIMIT_EXCEEDED\", f\"IP: {ip_address}\")\n        raise ValueError(\"Too many login attempts\")\n    \n    # Validate input\n    username = validate_user_input(username, max_length=50)\n    \n    # Check credentials (using secure password verification)\n    # ... password verification logic ...\n    \n    log_security_event(\"LOGIN_ATTEMPT\", f\"Username: {username}, IP: {ip_address}\")",
      "difficulty": "advanced",
      "categorySlug": "best-practices",
      "xpReward": 30,
      "tags": [
        "security",
        "validation",
        "encryption",
        "authentication"
      ],
      "estimatedMinutes": 12,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Flask Fundamentals for Web Development",
      "content": "Flask is a lightweight and flexible Python web framework. Understanding Flask basics helps you build web applications and APIs quickly and efficiently.",
      "codeExample": "# Basic Flask application\nfrom flask import Flask, request, jsonify, render_template\nimport json\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'your-secret-key-here'\n\n# Basic route\n@app.route('/')\ndef home():\n    return '<h1>Welcome to Flask!</h1>'\n\n# Route with parameters\n@app.route('/user/<username>')\ndef user_profile(username):\n    return f'<h1>User: {username}</h1>'\n\n# Route with multiple HTTP methods\n@app.route('/api/users', methods=['GET', 'POST'])\ndef users():\n    if request.method == 'GET':\n        # Return all users\n        users = [\n            {'id': 1, 'name': 'Alice'},\n            {'id': 2, 'name': 'Bob'}\n        ]\n        return jsonify(users)\n    \n    elif request.method == 'POST':\n        # Create new user\n        data = request.get_json()\n        new_user = {\n            'id': 3,\n            'name': data.get('name', 'Unknown')\n        }\n        return jsonify(new_user), 201\n\n# Query parameters\n@app.route('/search')\ndef search():\n    query = request.args.get('q', '')\n    category = request.args.get('category', 'all')\n    \n    results = {\n        'query': query,\n        'category': category,\n        'results': ['item1', 'item2', 'item3']\n    }\n    return jsonify(results)\n\n# Error handling\n@app.errorhandler(404)\ndef not_found(error):\n    return jsonify({'error': 'Not found'}), 404\n\n@app.errorhandler(500)\ndef internal_error(error):\n    return jsonify({'error': 'Internal server error'}), 500\n\n# Before request middleware\n@app.before_request\ndef before_request():\n    print(f\"Request: {request.method} {request.url}\")\n\n# Template rendering\n@app.route('/profile/<username>')\ndef profile(username):\n    user_data = {\n        'username': username,\n        'email': f'{username}@example.com',\n        'joined': '2023-01-01'\n    }\n    return render_template('profile.html', user=user_data)\n\n# File uploads\n@app.route('/upload', methods=['POST'])\ndef upload_file():\n    if 'file' not in request.files:\n        return jsonify({'error': 'No file provided'}), 400\n    \n    file = request.files['file']\n    if file.filename == '':\n        return jsonify({'error': 'No file selected'}), 400\n    \n    if file:\n        filename = file.filename\n        file.save(f'uploads/{filename}')\n        return jsonify({'message': f'File {filename} uploaded successfully'})\n\n# Configuration\nclass Config:\n    SECRET_KEY = 'dev-secret-key'\n    DEBUG = True\n    DATABASE_URL = 'sqlite:///app.db'\n\napp.config.from_object(Config)\n\nif __name__ == '__main__':\n    app.run(debug=True, host='0.0.0.0', port=5000)",
      "difficulty": "intermediate",
      "categorySlug": "web-development",
      "xpReward": 24,
      "tags": [
        "flask",
        "web-framework",
        "api",
        "routes"
      ],
      "estimatedMinutes": 8,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Working with APIs and HTTP Requests",
      "content": "Making HTTP requests and consuming APIs is essential for modern web development. The requests library provides an elegant interface for HTTP operations.",
      "codeExample": "import requests\nimport json\nfrom typing import Dict, Any, Optional\n\n# Basic HTTP requests\ndef make_api_request():\n    # GET request\n    response = requests.get('https://api.github.com/users/octocat')\n    \n    if response.status_code == 200:\n        user_data = response.json()\n        print(f\"User: {user_data['name']}\")\n        print(f\"Public repos: {user_data['public_repos']}\")\n    else:\n        print(f\"Error: {response.status_code}\")\n\n# POST request with data\ndef create_user(user_data):\n    url = 'https://jsonplaceholder.typicode.com/users'\n    \n    response = requests.post(\n        url,\n        json=user_data,\n        headers={'Content-Type': 'application/json'}\n    )\n    \n    if response.status_code == 201:\n        return response.json()\n    else:\n        raise Exception(f\"Failed to create user: {response.status_code}\")\n\n# API client class\nclass APIClient:\n    def __init__(self, base_url: str, api_key: Optional[str] = None):\n        self.base_url = base_url.rstrip('/')\n        self.session = requests.Session()\n        \n        if api_key:\n            self.session.headers.update({'Authorization': f'Bearer {api_key}'})\n    \n    def get(self, endpoint: str, params: Optional[Dict] = None) -> Dict[str, Any]:\n        \"\"\"Make GET request\"\"\"\n        url = f\"{self.base_url}/{endpoint.lstrip('/')}\"\n        response = self.session.get(url, params=params)\n        response.raise_for_status()\n        return response.json()\n    \n    def post(self, endpoint: str, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Make POST request\"\"\"\n        url = f\"{self.base_url}/{endpoint.lstrip('/')}\"\n        response = self.session.post(url, json=data)\n        response.raise_for_status()\n        return response.json()\n    \n    def put(self, endpoint: str, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Make PUT request\"\"\"\n        url = f\"{self.base_url}/{endpoint.lstrip('/')}\"\n        response = self.session.put(url, json=data)\n        response.raise_for_status()\n        return response.json()\n    \n    def delete(self, endpoint: str) -> bool:\n        \"\"\"Make DELETE request\"\"\"\n        url = f\"{self.base_url}/{endpoint.lstrip('/')}\"\n        response = self.session.delete(url)\n        response.raise_for_status()\n        return True\n\n# Using the API client\nclient = APIClient('https://jsonplaceholder.typicode.com', api_key='your-api-key')\n\n# Get all posts\nposts = client.get('/posts')\nprint(f\"Found {len(posts)} posts\")\n\n# Get specific post\npost = client.get('/posts/1')\nprint(f\"Post title: {post['title']}\")\n\n# Create new post\nnew_post = {\n    'title': 'My New Post',\n    'body': 'This is the content of my post',\n    'userId': 1\n}\ncreated_post = client.post('/posts', new_post)\n\n# Error handling and retries\nimport time\nfrom requests.adapters import HTTPAdapter\nfrom requests.packages.urllib3.util.retry import Retry\n\ndef create_session_with_retries():\n    session = requests.Session()\n    \n    # Configure retry strategy\n    retry_strategy = Retry(\n        total=3,  # Total number of retries\n        backoff_factor=1,  # Wait time between retries\n        status_forcelist=[429, 500, 502, 503, 504],  # HTTP status codes to retry\n    )\n    \n    adapter = HTTPAdapter(max_retries=retry_strategy)\n    session.mount(\"http://\", adapter)\n    session.mount(\"https://\", adapter)\n    \n    return session\n\n# Rate limiting\nclass RateLimitedAPIClient:\n    def __init__(self, base_url: str, requests_per_second: float = 1.0):\n        self.base_url = base_url\n        self.min_interval = 1.0 / requests_per_second\n        self.last_request_time = 0\n        self.session = create_session_with_retries()\n    \n    def _wait_if_needed(self):\n        current_time = time.time()\n        time_since_last_request = current_time - self.last_request_time\n        \n        if time_since_last_request < self.min_interval:\n            sleep_time = self.min_interval - time_since_last_request\n            time.sleep(sleep_time)\n        \n        self.last_request_time = time.time()\n    \n    def get(self, endpoint: str, params: Optional[Dict] = None) -> Dict[str, Any]:\n        self._wait_if_needed()\n        url = f\"{self.base_url}/{endpoint.lstrip('/')}\"\n        response = self.session.get(url, params=params, timeout=30)\n        response.raise_for_status()\n        return response.json()\n\n# Async requests with asyncio and aiohttp\nimport asyncio\nimport aiohttp\n\nasync def fetch_multiple_urls(urls):\n    \"\"\"Fetch multiple URLs concurrently\"\"\"\n    async with aiohttp.ClientSession() as session:\n        tasks = []\n        for url in urls:\n            task = asyncio.create_task(fetch_url(session, url))\n            tasks.append(task)\n        \n        results = await asyncio.gather(*tasks)\n        return results\n\nasync def fetch_url(session, url):\n    \"\"\"Fetch single URL\"\"\"\n    try:\n        async with session.get(url) as response:\n            return await response.json()\n    except Exception as e:\n        return {'error': str(e), 'url': url}\n\n# Usage\n# urls = [\n#     'https://jsonplaceholder.typicode.com/posts/1',\n#     'https://jsonplaceholder.typicode.com/posts/2',\n#     'https://jsonplaceholder.typicode.com/posts/3'\n# ]\n# results = asyncio.run(fetch_multiple_urls(urls))",
      "difficulty": "intermediate",
      "categorySlug": "web-development",
      "xpReward": 26,
      "tags": [
        "api",
        "requests",
        "http",
        "client"
      ],
      "estimatedMinutes": 9,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Database Integration with SQLAlchemy",
      "content": "SQLAlchemy is Python's most popular SQL toolkit and Object-Relational Mapping (ORM) library. It provides a high-level interface for database operations.",
      "codeExample": "from sqlalchemy import create_engine, Column, Integer, String, DateTime, ForeignKey\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, relationship\nfrom datetime import datetime\n\n# Database setup\nBase = declarative_base()\n\n# Model definitions\nclass User(Base):\n    __tablename__ = 'users'\n    \n    id = Column(Integer, primary_key=True)\n    username = Column(String(50), unique=True, nullable=False)\n    email = Column(String(100), unique=True, nullable=False)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    \n    # Relationship to posts\n    posts = relationship(\"Post\", back_populates=\"author\")\n    \n    def __repr__(self):\n        return f\"<User(username='{self.username}', email='{self.email}')>\"\n\nclass Post(Base):\n    __tablename__ = 'posts'\n    \n    id = Column(Integer, primary_key=True)\n    title = Column(String(200), nullable=False)\n    content = Column(String(1000))\n    user_id = Column(Integer, ForeignKey('users.id'))\n    created_at = Column(DateTime, default=datetime.utcnow)\n    \n    # Relationship to user\n    author = relationship(\"User\", back_populates=\"posts\")\n    \n    def __repr__(self):\n        return f\"<Post(title='{self.title}')>\"\n\n# Database connection and session management\nclass DatabaseManager:\n    def __init__(self, database_url='sqlite:///example.db'):\n        self.engine = create_engine(database_url)\n        self.SessionLocal = sessionmaker(bind=self.engine)\n        \n        # Create tables\n        Base.metadata.create_all(bind=self.engine)\n    \n    def get_session(self):\n        \"\"\"Get database session\"\"\"\n        return self.SessionLocal()\n    \n    def close_session(self, session):\n        \"\"\"Close database session\"\"\"\n        session.close()\n\n# Database operations\nclass UserRepository:\n    def __init__(self, db_manager):\n        self.db_manager = db_manager\n    \n    def create_user(self, username: str, email: str) -> User:\n        \"\"\"Create a new user\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            user = User(username=username, email=email)\n            session.add(user)\n            session.commit()\n            session.refresh(user)\n            return user\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_user_by_id(self, user_id: int) -> User:\n        \"\"\"Get user by ID\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            return session.query(User).filter(User.id == user_id).first()\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_user_by_username(self, username: str) -> User:\n        \"\"\"Get user by username\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            return session.query(User).filter(User.username == username).first()\n        finally:\n            self.db_manager.close_session(session)\n    \n    def update_user(self, user_id: int, **kwargs) -> User:\n        \"\"\"Update user\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            user = session.query(User).filter(User.id == user_id).first()\n            if user:\n                for key, value in kwargs.items():\n                    setattr(user, key, value)\n                session.commit()\n                session.refresh(user)\n            return user\n        finally:\n            self.db_manager.close_session(session)\n    \n    def delete_user(self, user_id: int) -> bool:\n        \"\"\"Delete user\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            user = session.query(User).filter(User.id == user_id).first()\n            if user:\n                session.delete(user)\n                session.commit()\n                return True\n            return False\n        finally:\n            self.db_manager.close_session(session)\n\n# Context manager for sessions\nfrom contextlib import contextmanager\n\n@contextmanager\ndef get_db_session(db_manager):\n    \"\"\"Context manager for database sessions\"\"\"\n    session = db_manager.get_session()\n    try:\n        yield session\n        session.commit()\n    except Exception:\n        session.rollback()\n        raise\n    finally:\n        session.close()\n\n# Using context manager\ndef create_user_with_posts(db_manager, username, email, post_titles):\n    \"\"\"Create user with multiple posts in a transaction\"\"\"\n    with get_db_session(db_manager) as session:\n        # Create user\n        user = User(username=username, email=email)\n        session.add(user)\n        session.flush()  # Get user.id without committing\n        \n        # Create posts\n        for title in post_titles:\n            post = Post(title=title, user_id=user.id)\n            session.add(post)\n        \n        # Commit happens automatically if no exception\n\n# Raw SQL queries\ndef execute_raw_sql(db_manager, query, params=None):\n    \"\"\"Execute raw SQL query\"\"\"\n    with get_db_session(db_manager) as session:\n        result = session.execute(query, params or {})\n        return result.fetchall()\n\n# Complex queries\ndef get_users_with_post_count(db_manager):\n    \"\"\"Get users with their post counts\"\"\"\n    with get_db_session(db_manager) as session:\n        from sqlalchemy import func\n        \n        result = session.query(\n            User.username,\n            User.email,\n            func.count(Post.id).label('post_count')\n        ).outerjoin(Post).group_by(User.id).all()\n        \n        return [\n            {\n                'username': row.username,\n                'email': row.email,\n                'post_count': row.post_count\n            }\n            for row in result\n        ]\n\n# Usage example\nif __name__ == \"__main__\":\n    # Initialize database\n    db_manager = DatabaseManager()\n    user_repo = UserRepository(db_manager)\n    \n    # Create users\n    user1 = user_repo.create_user(\"alice\", \"alice@example.com\")\n    user2 = user_repo.create_user(\"bob\", \"bob@example.com\")\n    \n    # Create posts\n    create_user_with_posts(\n        db_manager, \"charlie\", \"charlie@example.com\",\n        [\"First Post\", \"Second Post\", \"Third Post\"]\n    )\n    \n    # Query users\n    users_with_posts = get_users_with_post_count(db_manager)\n    for user_info in users_with_posts:\n        print(f\"{user_info['username']}: {user_info['post_count']} posts\")",
      "difficulty": "advanced",
      "categorySlug": "web-development",
      "xpReward": 30,
      "tags": [
        "sqlalchemy",
        "orm",
        "database",
        "sql"
      ],
      "estimatedMinutes": 12,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Authentication and Session Management",
      "content": "Implementing secure authentication and session management is crucial for web applications. This includes user registration, login, password security, and session handling.",
      "codeExample": "import hashlib\nimport secrets\nimport jwt\nfrom datetime import datetime, timedelta\nfrom functools import wraps\nfrom flask import Flask, request, jsonify, session\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'your-very-secret-key'\n\n# User storage (in production, use a database)\nusers_db = {}\nsessions_db = {}\n\nclass User:\n    def __init__(self, username, email, password_hash, salt):\n        self.id = secrets.token_hex(8)\n        self.username = username\n        self.email = email\n        self.password_hash = password_hash\n        self.salt = salt\n        self.created_at = datetime.utcnow()\n        self.is_active = True\n\nclass AuthManager:\n    @staticmethod\n    def hash_password(password):\n        \"\"\"Hash password with salt\"\"\"\n        salt = secrets.token_hex(16)\n        password_hash = hashlib.pbkdf2_hmac(\n            'sha256',\n            password.encode('utf-8'),\n            salt.encode('utf-8'),\n            100000\n        )\n        return password_hash.hex(), salt\n    \n    @staticmethod\n    def verify_password(password, stored_hash, salt):\n        \"\"\"Verify password against stored hash\"\"\"\n        password_hash = hashlib.pbkdf2_hmac(\n            'sha256',\n            password.encode('utf-8'),\n            salt.encode('utf-8'),\n            100000\n        )\n        return password_hash.hex() == stored_hash\n    \n    @staticmethod\n    def generate_token(user_id, expires_in_hours=24):\n        \"\"\"Generate JWT token\"\"\"\n        payload = {\n            'user_id': user_id,\n            'exp': datetime.utcnow() + timedelta(hours=expires_in_hours),\n            'iat': datetime.utcnow()\n        }\n        return jwt.encode(payload, app.config['SECRET_KEY'], algorithm='HS256')\n    \n    @staticmethod\n    def verify_token(token):\n        \"\"\"Verify JWT token\"\"\"\n        try:\n            payload = jwt.decode(token, app.config['SECRET_KEY'], algorithms=['HS256'])\n            return payload['user_id']\n        except jwt.ExpiredSignatureError:\n            return None\n        except jwt.InvalidTokenError:\n            return None\n\n# Authentication decorator\ndef login_required(f):\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        token = request.headers.get('Authorization')\n        if not token:\n            return jsonify({'error': 'No token provided'}), 401\n        \n        if token.startswith('Bearer '):\n            token = token[7:]\n        \n        user_id = AuthManager.verify_token(token)\n        if not user_id:\n            return jsonify({'error': 'Invalid or expired token'}), 401\n        \n        # Add user to request context\n        request.current_user_id = user_id\n        return f(*args, **kwargs)\n    \n    return decorated_function\n\n# Registration endpoint\n@app.route('/register', methods=['POST'])\ndef register():\n    data = request.get_json()\n    \n    # Validate input\n    username = data.get('username', '').strip()\n    email = data.get('email', '').strip()\n    password = data.get('password', '')\n    \n    if not username or not email or not password:\n        return jsonify({'error': 'All fields are required'}), 400\n    \n    if len(password) < 8:\n        return jsonify({'error': 'Password must be at least 8 characters'}), 400\n    \n    # Check if user already exists\n    for user in users_db.values():\n        if user.username == username or user.email == email:\n            return jsonify({'error': 'User already exists'}), 409\n    \n    # Create user\n    password_hash, salt = AuthManager.hash_password(password)\n    user = User(username, email, password_hash, salt)\n    users_db[user.id] = user\n    \n    # Generate token\n    token = AuthManager.generate_token(user.id)\n    \n    return jsonify({\n        'message': 'User created successfully',\n        'token': token,\n        'user': {\n            'id': user.id,\n            'username': user.username,\n            'email': user.email\n        }\n    }), 201\n\n# Login endpoint\n@app.route('/login', methods=['POST'])\ndef login():\n    data = request.get_json()\n    \n    username = data.get('username', '').strip()\n    password = data.get('password', '')\n    \n    if not username or not password:\n        return jsonify({'error': 'Username and password required'}), 400\n    \n    # Find user\n    user = None\n    for u in users_db.values():\n        if u.username == username or u.email == username:\n            user = u\n            break\n    \n    if not user or not AuthManager.verify_password(password, user.password_hash, user.salt):\n        return jsonify({'error': 'Invalid credentials'}), 401\n    \n    # Generate token\n    token = AuthManager.generate_token(user.id)\n    \n    return jsonify({\n        'message': 'Login successful',\n        'token': token,\n        'user': {\n            'id': user.id,\n            'username': user.username,\n            'email': user.email\n        }\n    })\n\n# Protected endpoint\n@app.route('/profile', methods=['GET'])\n@login_required\ndef get_profile():\n    user = users_db.get(request.current_user_id)\n    if not user:\n        return jsonify({'error': 'User not found'}), 404\n    \n    return jsonify({\n        'user': {\n            'id': user.id,\n            'username': user.username,\n            'email': user.email,\n            'created_at': user.created_at.isoformat()\n        }\n    })\n\n# Session-based authentication (alternative to JWT)\nclass SessionManager:\n    @staticmethod\n    def create_session(user_id):\n        \"\"\"Create a new session\"\"\"\n        session_id = secrets.token_urlsafe(32)\n        session_data = {\n            'user_id': user_id,\n            'created_at': datetime.utcnow(),\n            'last_accessed': datetime.utcnow()\n        }\n        sessions_db[session_id] = session_data\n        return session_id\n    \n    @staticmethod\n    def get_session(session_id):\n        \"\"\"Get session data\"\"\"\n        session_data = sessions_db.get(session_id)\n        if not session_data:\n            return None\n        \n        # Check if session is expired (24 hours)\n        if datetime.utcnow() - session_data['created_at'] > timedelta(hours=24):\n            del sessions_db[session_id]\n            return None\n        \n        # Update last accessed\n        session_data['last_accessed'] = datetime.utcnow()\n        return session_data\n    \n    @staticmethod\n    def delete_session(session_id):\n        \"\"\"Delete session\"\"\"\n        if session_id in sessions_db:\n            del sessions_db[session_id]\n\n# Password reset functionality\nreset_tokens = {}\n\n@app.route('/reset-password-request', methods=['POST'])\ndef reset_password_request():\n    data = request.get_json()\n    email = data.get('email', '').strip()\n    \n    # Find user by email\n    user = None\n    for u in users_db.values():\n        if u.email == email:\n            user = u\n            break\n    \n    if user:\n        # Generate reset token\n        reset_token = secrets.token_urlsafe(32)\n        reset_tokens[reset_token] = {\n            'user_id': user.id,\n            'expires_at': datetime.utcnow() + timedelta(hours=1)\n        }\n        \n        # In production, send email with reset link\n        print(f\"Reset token for {email}: {reset_token}\")\n    \n    # Always return success for security\n    return jsonify({'message': 'If account exists, reset email sent'})\n\n@app.route('/reset-password', methods=['POST'])\ndef reset_password():\n    data = request.get_json()\n    token = data.get('token', '')\n    new_password = data.get('password', '')\n    \n    if not token or not new_password:\n        return jsonify({'error': 'Token and password required'}), 400\n    \n    if len(new_password) < 8:\n        return jsonify({'error': 'Password must be at least 8 characters'}), 400\n    \n    # Verify reset token\n    reset_data = reset_tokens.get(token)\n    if not reset_data or datetime.utcnow() > reset_data['expires_at']:\n        return jsonify({'error': 'Invalid or expired token'}), 400\n    \n    # Update password\n    user = users_db.get(reset_data['user_id'])\n    if user:\n        password_hash, salt = AuthManager.hash_password(new_password)\n        user.password_hash = password_hash\n        user.salt = salt\n        \n        # Remove reset token\n        del reset_tokens[token]\n        \n        return jsonify({'message': 'Password reset successful'})\n    \n    return jsonify({'error': 'User not found'}), 404\n\nif __name__ == '__main__':\n    app.run(debug=True)",
      "difficulty": "advanced",
      "categorySlug": "web-development",
      "xpReward": 32,
      "tags": [
        "authentication",
        "security",
        "jwt",
        "sessions"
      ],
      "estimatedMinutes": 14,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "NumPy Arrays and Vectorized Operations",
      "content": "NumPy is the foundation of Python's scientific computing stack. Understanding arrays and vectorized operations is essential for efficient numerical computations and data manipulation.",
      "codeExample": "import numpy as np\nimport time\n\n# Creating NumPy arrays\narr1d = np.array([1, 2, 3, 4, 5])\narr2d = np.array([[1, 2, 3], [4, 5, 6]])\narr3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n\nprint(f\"1D array: {arr1d}\")\nprint(f\"2D array:\\n{arr2d}\")\nprint(f\"Shape: {arr2d.shape}, Size: {arr2d.size}, Dtype: {arr2d.dtype}\")\n\n# Array creation functions\nzeros = np.zeros((3, 4))          # All zeros\nones = np.ones((2, 3))            # All ones\nidentity = np.eye(3)              # Identity matrix\narange = np.arange(0, 10, 2)      # Range array [0, 2, 4, 6, 8]\nlinspace = np.linspace(0, 1, 5)   # 5 evenly spaced values from 0 to 1\nrandom_arr = np.random.random((3, 3))  # Random values\n\n# Array indexing and slicing\narr = np.array([[1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12]])\n\nprint(f\"Element at [1, 2]: {arr[1, 2]}\")      # 7\nprint(f\"First row: {arr[0, :]}\")               # [1 2 3 4]\nprint(f\"Last column: {arr[:, -1]}\")            # [4 8 12]\nprint(f\"Subarray:\\n{arr[1:, 1:3]}\")          # [[6 7], [10 11]]\n\n# Boolean indexing\ndata = np.array([1, 5, 3, 8, 2, 9])\nmask = data > 5\nprint(f\"Values > 5: {data[mask]}\")             # [8 9]\n\n# Vectorized operations (much faster than loops)\ndef compare_performance():\n    # Create large arrays\n    size = 1000000\n    arr1 = np.random.random(size)\n    arr2 = np.random.random(size)\n    \n    # Python loop (slow)\n    start = time.time()\n    result_loop = []\n    for i in range(len(arr1)):\n        result_loop.append(arr1[i] + arr2[i])\n    loop_time = time.time() - start\n    \n    # NumPy vectorized operation (fast)\n    start = time.time()\n    result_vector = arr1 + arr2\n    vector_time = time.time() - start\n    \n    print(f\"Loop time: {loop_time:.4f}s\")\n    print(f\"Vectorized time: {vector_time:.4f}s\")\n    print(f\"Speedup: {loop_time/vector_time:.1f}x\")\n\n# Mathematical operations\narr = np.array([1, 4, 9, 16, 25])\nprint(f\"Square root: {np.sqrt(arr)}\")          # [1. 2. 3. 4. 5.]\nprint(f\"Natural log: {np.log(arr)}\")\nprint(f\"Sin values: {np.sin(arr)}\")\n\n# Array reshaping and manipulation\noriginal = np.arange(12)\nreshaped = original.reshape(3, 4)\nflattened = reshaped.flatten()\ntransposed = reshaped.T\n\nprint(f\"Original: {original}\")\nprint(f\"Reshaped:\\n{reshaped}\")\nprint(f\"Transposed:\\n{transposed}\")\n\n# Aggregation functions\ndata = np.random.normal(50, 15, 1000)  # Normal distribution\nprint(f\"Mean: {np.mean(data):.2f}\")\nprint(f\"Median: {np.median(data):.2f}\")\nprint(f\"Std deviation: {np.std(data):.2f}\")\nprint(f\"Min: {np.min(data):.2f}, Max: {np.max(data):.2f}\")\n\n# Axis-based operations\nmatrix = np.random.randint(1, 10, (3, 4))\nprint(f\"Matrix:\\n{matrix}\")\nprint(f\"Sum along rows (axis=1): {np.sum(matrix, axis=1)}\")\nprint(f\"Mean along columns (axis=0): {np.mean(matrix, axis=0)}\")\n\n# Broadcasting (operations between arrays of different shapes)\narr = np.array([[1, 2, 3],\n                [4, 5, 6]])\nscalar = 10\nvector = np.array([1, 2, 3])\n\nprint(f\"Array + scalar:\\n{arr + scalar}\")\nprint(f\"Array + vector:\\n{arr + vector}\")    # Vector broadcasts to match rows\n\n# Useful array functions\narr = np.array([3, 1, 4, 1, 5, 9, 2, 6])\nprint(f\"Sorted: {np.sort(arr)}\")\nprint(f\"Unique values: {np.unique(arr)}\")\nprint(f\"Arg max: {np.argmax(arr)}\")            # Index of maximum value\nprint(f\"Where > 4: {np.where(arr > 4)}\")      # Indices where condition is true",
      "difficulty": "intermediate",
      "categorySlug": "data-science",
      "xpReward": 24,
      "tags": [
        "numpy",
        "arrays",
        "vectorization",
        "scientific-computing"
      ],
      "estimatedMinutes": 8,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Pandas for Data Manipulation",
      "content": "Pandas is the cornerstone of data analysis in Python. It provides powerful data structures (Series and DataFrame) and tools for data cleaning, transformation, and analysis.",
      "codeExample": "import pandas as pd\nimport numpy as np\n\n# Creating DataFrames\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n    'age': [25, 30, 35, 28, 32],\n    'city': ['New York', 'London', 'Tokyo', 'Paris', 'Sydney'],\n    'salary': [50000, 60000, 70000, 55000, 65000]\n}\ndf = pd.DataFrame(data)\nprint(\"DataFrame:\")\nprint(df)\nprint(f\"\\nShape: {df.shape}\")\nprint(f\"\\nData types:\\n{df.dtypes}\")\n\n# Reading data from files\n# df = pd.read_csv('data.csv')\n# df = pd.read_excel('data.xlsx')\n# df = pd.read_json('data.json')\n\n# Basic DataFrame operations\nprint(f\"\\nFirst 3 rows:\\n{df.head(3)}\")\nprint(f\"\\nLast 2 rows:\\n{df.tail(2)}\")\nprint(f\"\\nColumn names: {df.columns.tolist()}\")\nprint(f\"\\nBasic statistics:\\n{df.describe()}\")\n\n# Selecting data\nprint(f\"\\nNames column:\\n{df['name']}\")\nprint(f\"\\nMultiple columns:\\n{df[['name', 'salary']]}\")\nprint(f\"\\nFirst 3 rows, first 2 columns:\\n{df.iloc[0:3, 0:2]}\")\nprint(f\"\\nRows where age > 30:\\n{df[df['age'] > 30]}\")\n\n# Adding and modifying columns\ndf['bonus'] = df['salary'] * 0.1\ndf['total_compensation'] = df['salary'] + df['bonus']\ndf['age_group'] = df['age'].apply(lambda x: 'Young' if x < 30 else 'Experienced')\n\nprint(f\"\\nDataFrame with new columns:\\n{df}\")\n\n# Data cleaning and handling missing values\n# Create sample data with missing values\ndirty_data = {\n    'product': ['A', 'B', 'C', 'D', 'E'],\n    'price': [10.5, None, 15.0, 12.5, None],\n    'quantity': [100, 200, None, 150, 300],\n    'category': ['Electronics', 'Books', '', 'Electronics', 'Books']\n}\ndirty_df = pd.DataFrame(dirty_data)\nprint(f\"\\nData with missing values:\\n{dirty_df}\")\n\n# Handle missing values\nprint(f\"\\nMissing values count:\\n{dirty_df.isnull().sum()}\")\n\n# Fill missing values\nclean_df = dirty_df.copy()\nclean_df['price'].fillna(clean_df['price'].mean(), inplace=True)\nclean_df['quantity'].fillna(clean_df['quantity'].median(), inplace=True)\nclean_df['category'].replace('', 'Unknown', inplace=True)\n\nprint(f\"\\nCleaned data:\\n{clean_df}\")\n\n# Grouping and aggregation\ngrouped = df.groupby('city').agg({\n    'salary': ['mean', 'max', 'min'],\n    'age': 'mean'\n}).round(2)\nprint(f\"\\nGrouped by city:\\n{grouped}\")\n\n# More complex grouping\ncity_stats = df.groupby('city').apply(\n    lambda group: pd.Series({\n        'avg_salary': group['salary'].mean(),\n        'total_people': len(group),\n        'salary_std': group['salary'].std()\n    })\n).round(2)\nprint(f\"\\nCity statistics:\\n{city_stats}\")\n\n# Sorting data\nsorted_df = df.sort_values(['age', 'salary'], ascending=[True, False])\nprint(f\"\\nSorted by age (asc) then salary (desc):\\n{sorted_df}\")\n\n# Merging DataFrames\nadditional_info = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'department': ['Engineering', 'Marketing', 'Sales'],\n    'years_experience': [3, 5, 8]\n})\n\nmerged_df = pd.merge(df, additional_info, on='name', how='left')\nprint(f\"\\nMerged DataFrame:\\n{merged_df}\")\n\n# Pivot tables\npivot = df.pivot_table(\n    values='salary',\n    index='age_group',\n    columns='city',\n    aggfunc='mean',\n    fill_value=0\n)\nprint(f\"\\nPivot table:\\n{pivot}\")\n\n# String operations\ntext_df = pd.DataFrame({\n    'names': ['John Doe', 'jane smith', 'BOB JOHNSON', 'alice brown']\n})\n\ntext_df['first_name'] = text_df['names'].str.split().str[0]\ntext_df['last_name'] = text_df['names'].str.split().str[1]\ntext_df['names_upper'] = text_df['names'].str.upper()\ntext_df['names_title'] = text_df['names'].str.title()\n\nprint(f\"\\nString operations:\\n{text_df}\")\n\n# DateTime operations\ndates_df = pd.DataFrame({\n    'date_string': ['2023-01-15', '2023-02-20', '2023-03-25']\n})\n\ndates_df['date'] = pd.to_datetime(dates_df['date_string'])\ndates_df['year'] = dates_df['date'].dt.year\ndates_df['month'] = dates_df['date'].dt.month\ndates_df['day_name'] = dates_df['date'].dt.day_name()\n\nprint(f\"\\nDateTime operations:\\n{dates_df}\")\n\n# Performance tips\n# Use vectorized operations instead of apply when possible\n# Use categorical data type for repeated strings\n# Use appropriate data types (int32 instead of int64 if possible)\n\n# Convert to categorical for memory efficiency\ndf['city'] = df['city'].astype('category')\nprint(f\"\\nMemory usage after categorical conversion:\\n{df.memory_usage(deep=True)}\")",
      "difficulty": "intermediate",
      "categorySlug": "data-science",
      "xpReward": 26,
      "tags": [
        "pandas",
        "dataframes",
        "data-manipulation",
        "analysis"
      ],
      "estimatedMinutes": 9,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Data Visualization with Matplotlib and Seaborn",
      "content": "Creating effective visualizations is crucial for data analysis and communication. Matplotlib provides the foundation, while Seaborn offers higher-level statistical plotting functions.",
      "codeExample": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\n\n# Set style for better-looking plots\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n\n# Create sample data\nnp.random.seed(42)\ndata = pd.DataFrame({\n    'x': np.random.normal(0, 1, 1000),\n    'y': np.random.normal(0, 1, 1000),\n    'category': np.random.choice(['A', 'B', 'C'], 1000),\n    'value': np.random.exponential(2, 1000)\n})\n\n# Basic Matplotlib plots\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Line plot\nx = np.linspace(0, 10, 100)\ny1 = np.sin(x)\ny2 = np.cos(x)\n\naxes[0, 0].plot(x, y1, label='sin(x)', linewidth=2)\naxes[0, 0].plot(x, y2, label='cos(x)', linewidth=2)\naxes[0, 0].set_title('Trigonometric Functions')\naxes[0, 0].set_xlabel('x')\naxes[0, 0].set_ylabel('y')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Scatter plot\naxes[0, 1].scatter(data['x'], data['y'], alpha=0.6, c=data['value'], cmap='viridis')\naxes[0, 1].set_title('Scatter Plot with Color Mapping')\naxes[0, 1].set_xlabel('X values')\naxes[0, 1].set_ylabel('Y values')\n\n# Histogram\naxes[1, 0].hist(data['value'], bins=30, alpha=0.7, edgecolor='black')\naxes[1, 0].set_title('Distribution of Values')\naxes[1, 0].set_xlabel('Value')\naxes[1, 0].set_ylabel('Frequency')\n\n# Box plot\ncategory_data = [data[data['category'] == cat]['value'] for cat in ['A', 'B', 'C']]\naxes[1, 1].boxplot(category_data, labels=['A', 'B', 'C'])\naxes[1, 1].set_title('Value Distribution by Category')\naxes[1, 1].set_xlabel('Category')\naxes[1, 1].set_ylabel('Value')\n\nplt.tight_layout()\nplt.show()\n\n# Seaborn statistical plots\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# Distribution plot\nsns.histplot(data=data, x='value', hue='category', ax=axes[0, 0])\naxes[0, 0].set_title('Distribution by Category')\n\n# Violin plot\nsns.violinplot(data=data, x='category', y='value', ax=axes[0, 1])\naxes[0, 1].set_title('Violin Plot')\n\n# Correlation heatmap\ncorrelation_data = data.select_dtypes(include=[np.number]).corr()\nsns.heatmap(correlation_data, annot=True, cmap='coolwarm', ax=axes[0, 2])\naxes[0, 2].set_title('Correlation Matrix')\n\n# Pair plot (create smaller dataset for clarity)\nsample_data = data.sample(200)\nsns.scatterplot(data=sample_data, x='x', y='y', hue='category', ax=axes[1, 0])\naxes[1, 0].set_title('Scatter Plot by Category')\n\n# Regression plot\nsns.regplot(data=sample_data, x='x', y='value', ax=axes[1, 1])\naxes[1, 1].set_title('Regression Plot')\n\n# Count plot\nsns.countplot(data=data, x='category', ax=axes[1, 2])\naxes[1, 2].set_title('Count by Category')\n\nplt.tight_layout()\nplt.show()\n\n# Advanced plotting techniques\ndef create_advanced_plots():\n    # Create time series data\n    dates = pd.date_range('2023-01-01', periods=365, freq='D')\n    ts_data = pd.DataFrame({\n        'date': dates,\n        'temperature': 20 + 10 * np.sin(2 * np.pi * np.arange(365) / 365) + np.random.normal(0, 2, 365),\n        'humidity': 50 + 20 * np.cos(2 * np.pi * np.arange(365) / 365) + np.random.normal(0, 5, 365)\n    })\n    \n    # Multiple y-axes plot\n    fig, ax1 = plt.subplots(figsize=(12, 6))\n    \n    color = 'tab:red'\n    ax1.set_xlabel('Date')\n    ax1.set_ylabel('Temperature (¬∞C)', color=color)\n    ax1.plot(ts_data['date'], ts_data['temperature'], color=color, linewidth=1)\n    ax1.tick_params(axis='y', labelcolor=color)\n    \n    ax2 = ax1.twinx()\n    color = 'tab:blue'\n    ax2.set_ylabel('Humidity (%)', color=color)\n    ax2.plot(ts_data['date'], ts_data['humidity'], color=color, linewidth=1)\n    ax2.tick_params(axis='y', labelcolor=color)\n    \n    plt.title('Temperature and Humidity Over Time')\n    plt.tight_layout()\n    plt.show()\n\n# Customizing plots\ndef create_custom_plot():\n    # Create sample data\n    categories = ['Product A', 'Product B', 'Product C', 'Product D']\n    sales_q1 = [23, 17, 35, 29]\n    sales_q2 = [25, 19, 38, 31]\n    \n    x = np.arange(len(categories))\n    width = 0.35\n    \n    fig, ax = plt.subplots(figsize=(10, 6))\n    \n    bars1 = ax.bar(x - width/2, sales_q1, width, label='Q1', color='skyblue', edgecolor='navy')\n    bars2 = ax.bar(x + width/2, sales_q2, width, label='Q2', color='lightcoral', edgecolor='darkred')\n    \n    # Customize the plot\n    ax.set_xlabel('Products', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Sales (thousands)', fontsize=12, fontweight='bold')\n    ax.set_title('Quarterly Sales Comparison', fontsize=14, fontweight='bold')\n    ax.set_xticks(x)\n    ax.set_xticklabels(categories)\n    ax.legend()\n    \n    # Add value labels on bars\n    def add_value_labels(bars):\n        for bar in bars:\n            height = bar.get_height()\n            ax.annotate(f'{height}',\n                       xy=(bar.get_x() + bar.get_width() / 2, height),\n                       xytext=(0, 3),  # 3 points vertical offset\n                       textcoords=\"offset points\",\n                       ha='center', va='bottom')\n    \n    add_value_labels(bars1)\n    add_value_labels(bars2)\n    \n    plt.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n\n# Saving plots\ndef save_plots():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3, 4], [1, 4, 2, 3])\n    \n    # Save in different formats\n    plt.savefig('plot.png', dpi=300, bbox_inches='tight')\n    plt.savefig('plot.pdf', bbox_inches='tight')\n    plt.savefig('plot.svg', bbox_inches='tight')\n    \n    plt.show()\n\n# Interactive plots with plotly (alternative)\n# import plotly.express as px\n# import plotly.graph_objects as go\n\n# def create_interactive_plot():\n#     fig = px.scatter(data, x='x', y='y', color='category',\n#                     size='value', hover_data=['value'])\n#     fig.update_layout(title='Interactive Scatter Plot')\n#     fig.show()\n\nprint(\"Visualization examples created. Run the functions to see the plots.\")",
      "difficulty": "intermediate",
      "categorySlug": "data-science",
      "xpReward": 28,
      "tags": [
        "matplotlib",
        "seaborn",
        "visualization",
        "plotting"
      ],
      "estimatedMinutes": 10,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Machine Learning with Scikit-learn",
      "content": "Scikit-learn provides simple and efficient tools for machine learning. Understanding the basic workflow of data preprocessing, model training, and evaluation is essential for ML projects.",
      "codeExample": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\nfrom sklearn.datasets import make_classification, make_regression, load_iris\nimport matplotlib.pyplot as plt\n\n# Generate sample datasets\n# Classification dataset\nX_clf, y_clf = make_classification(n_samples=1000, n_features=20, n_informative=10,\n                                  n_redundant=10, n_clusters_per_class=1, random_state=42)\n\n# Regression dataset\nX_reg, y_reg = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n\n# Load real dataset (Iris)\niris = load_iris()\niris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\niris_df['target'] = iris.target\niris_df['species'] = iris_df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n\nprint(\"Sample datasets created\")\nprint(f\"Classification dataset shape: {X_clf.shape}\")\nprint(f\"Regression dataset shape: {X_reg.shape}\")\nprint(f\"Iris dataset shape: {iris_df.shape}\")\n\n# Data preprocessing pipeline\nclass DataPreprocessor:\n    def __init__(self):\n        self.scaler = StandardScaler()\n        self.label_encoder = LabelEncoder()\n        \n    def preprocess_features(self, X_train, X_test):\n        \"\"\"Scale numerical features\"\"\"\n        X_train_scaled = self.scaler.fit_transform(X_train)\n        X_test_scaled = self.scaler.transform(X_test)\n        return X_train_scaled, X_test_scaled\n    \n    def encode_labels(self, y_train, y_test=None):\n        \"\"\"Encode categorical labels\"\"\"\n        y_train_encoded = self.label_encoder.fit_transform(y_train)\n        if y_test is not None:\n            y_test_encoded = self.label_encoder.transform(y_test)\n            return y_train_encoded, y_test_encoded\n        return y_train_encoded\n\n# Classification example\ndef classification_example():\n    print(\"\\n=== Classification Example ===\")\n    \n    # Split the data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n    )\n    \n    # Preprocess data\n    preprocessor = DataPreprocessor()\n    X_train_scaled, X_test_scaled = preprocessor.preprocess_features(X_train, X_test)\n    \n    # Train different models\n    models = {\n        'Logistic Regression': LogisticRegression(random_state=42),\n        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n        'SVM': SVC(random_state=42)\n    }\n    \n    results = {}\n    \n    for name, model in models.items():\n        # Train model\n        model.fit(X_train_scaled, y_train)\n        \n        # Make predictions\n        y_pred = model.predict(X_test_scaled)\n        \n        # Calculate accuracy\n        accuracy = accuracy_score(y_test, y_pred)\n        results[name] = accuracy\n        \n        print(f\"\\n{name}:\")\n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(\"Classification Report:\")\n        print(classification_report(y_test, y_pred))\n    \n    # Cross-validation\n    print(\"\\n=== Cross-Validation Results ===\")\n    for name, model in models.items():\n        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n        print(f\"{name}: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n\n# Regression example\ndef regression_example():\n    print(\"\\n=== Regression Example ===\")\n    \n    # Split the data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_reg, y_reg, test_size=0.2, random_state=42\n    )\n    \n    # Preprocess data\n    preprocessor = DataPreprocessor()\n    X_train_scaled, X_test_scaled = preprocessor.preprocess_features(X_train, X_test)\n    \n    # Train different models\n    models = {\n        'Linear Regression': LinearRegression(),\n        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n    }\n    \n    for name, model in models.items():\n        # Train model\n        model.fit(X_train_scaled, y_train)\n        \n        # Make predictions\n        y_pred = model.predict(X_test_scaled)\n        \n        # Calculate metrics\n        mse = mean_squared_error(y_test, y_pred)\n        r2 = r2_score(y_test, y_pred)\n        \n        print(f\"\\n{name}:\")\n        print(f\"MSE: {mse:.4f}\")\n        print(f\"R¬≤ Score: {r2:.4f}\")\n        \n        # Plot predictions vs actual (for first model only)\n        if name == 'Linear Regression':\n            plt.figure(figsize=(8, 6))\n            plt.scatter(y_test, y_pred, alpha=0.6)\n            plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n            plt.xlabel('Actual Values')\n            plt.ylabel('Predicted Values')\n            plt.title('Actual vs Predicted Values (Linear Regression)')\n            plt.show()\n\n# Hyperparameter tuning\ndef hyperparameter_tuning_example():\n    print(\"\\n=== Hyperparameter Tuning ===\")\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n    )\n    \n    # Preprocess data\n    preprocessor = DataPreprocessor()\n    X_train_scaled, X_test_scaled = preprocessor.preprocess_features(X_train, X_test)\n    \n    # Define parameter grid for Random Forest\n    param_grid = {\n        'n_estimators': [50, 100, 200],\n        'max_depth': [None, 10, 20],\n        'min_samples_split': [2, 5, 10]\n    }\n    \n    # Grid search with cross-validation\n    rf = RandomForestClassifier(random_state=42)\n    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    grid_search.fit(X_train_scaled, y_train)\n    \n    print(f\"Best parameters: {grid_search.best_params_}\")\n    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n    \n    # Evaluate best model on test set\n    best_model = grid_search.best_estimator_\n    y_pred = best_model.predict(X_test_scaled)\n    test_accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Test accuracy with best model: {test_accuracy:.4f}\")\n\n# Feature importance analysis\ndef feature_importance_example():\n    print(\"\\n=== Feature Importance Analysis ===\")\n    \n    # Use Iris dataset for interpretability\n    X = iris_df.drop(['target', 'species'], axis=1)\n    y = iris_df['target']\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    # Train Random Forest\n    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n    rf.fit(X_train, y_train)\n    \n    # Get feature importances\n    feature_importance = pd.DataFrame({\n        'feature': X.columns,\n        'importance': rf.feature_importances_\n    }).sort_values('importance', ascending=False)\n    \n    print(\"Feature Importances:\")\n    print(feature_importance)\n    \n    # Plot feature importances\n    plt.figure(figsize=(10, 6))\n    plt.barh(feature_importance['feature'], feature_importance['importance'])\n    plt.xlabel('Feature Importance')\n    plt.title('Random Forest Feature Importances (Iris Dataset)')\n    plt.gca().invert_yaxis()\n    plt.tight_layout()\n    plt.show()\n\n# Model evaluation and validation\ndef model_evaluation_example():\n    print(\"\\n=== Model Evaluation ===\")\n    \n    # Use Iris dataset\n    X = iris_df.drop(['target', 'species'], axis=1)\n    y = iris_df['species']  # Use string labels\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    # Train model\n    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n    rf.fit(X_train, y_train)\n    \n    # Predictions\n    y_pred = rf.predict(X_test)\n    y_pred_proba = rf.predict_proba(X_test)\n    \n    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n    print(\"\\nDetailed Classification Report:\")\n    print(classification_report(y_test, y_pred))\n    \n    # Confusion matrix\n    from sklearn.metrics import confusion_matrix\n    import seaborn as sns\n    \n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=rf.classes_, yticklabels=rf.classes_)\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n# Pipeline example\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\ndef pipeline_example():\n    print(\"\\n=== ML Pipeline Example ===\")\n    \n    # Create sample data with mixed types\n    data = pd.DataFrame({\n        'numerical_1': np.random.normal(0, 1, 1000),\n        'numerical_2': np.random.normal(10, 5, 1000),\n        'categorical': np.random.choice(['A', 'B', 'C'], 1000),\n        'target': np.random.choice([0, 1], 1000)\n    })\n    \n    X = data.drop('target', axis=1)\n    y = data['target']\n    \n    # Define preprocessing for different column types\n    numerical_features = ['numerical_1', 'numerical_2']\n    categorical_features = ['categorical']\n    \n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', StandardScaler(), numerical_features),\n            ('cat', OneHotEncoder(drop='first'), categorical_features)\n        ]\n    )\n    \n    # Create pipeline\n    pipeline = Pipeline([\n        ('preprocessor', preprocessor),\n        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n    ])\n    \n    # Split and train\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    # Fit pipeline\n    pipeline.fit(X_train, y_train)\n    \n    # Evaluate\n    accuracy = pipeline.score(X_test, y_test)\n    print(f\"Pipeline accuracy: {accuracy:.4f}\")\n\n# Run examples\nclassification_example()\nregression_example()\nhyperparameter_tuning_example()\nfeature_importance_example()\nmodel_evaluation_example()\npipeline_example()",
      "difficulty": "advanced",
      "categorySlug": "data-science",
      "xpReward": 32,
      "tags": [
        "machine-learning",
        "scikit-learn",
        "classification",
        "regression"
      ],
      "estimatedMinutes": 15,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Statistical Analysis with SciPy",
      "content": "SciPy provides comprehensive statistical functions for data analysis. Understanding basic statistical tests and distributions helps you validate hypotheses and draw conclusions from data.",
      "codeExample": "import numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\n# Generate sample data\nnp.random.seed(42)\nsample_data = np.random.normal(100, 15, 1000)\ngroup_a = np.random.normal(100, 10, 50)\ngroup_b = np.random.normal(105, 12, 50)\n\n# Descriptive statistics\nprint(\"Descriptive Statistics:\")\nprint(f\"Mean: {np.mean(sample_data):.2f}\")\nprint(f\"Median: {np.median(sample_data):.2f}\")\nprint(f\"Standard deviation: {np.std(sample_data):.2f}\")\nprint(f\"Variance: {np.var(sample_data):.2f}\")\n\n# Test for normality\nstatistic, p_value = stats.shapiro(sample_data[:100])  # Use subset for Shapiro-Wilk\nprint(f\"\\nNormality test (Shapiro-Wilk):\")\nprint(f\"Statistic: {statistic:.4f}\")\nprint(f\"P-value: {p_value:.6f}\")\nprint(f\"Normal distribution: {p_value > 0.05}\")\n\n# One-sample t-test\nt_stat, p_val = stats.ttest_1samp(sample_data, 100)\nprint(f\"\\nOne-sample t-test (testing if mean = 100):\")\nprint(f\"T-statistic: {t_stat:.4f}\")\nprint(f\"P-value: {p_val:.6f}\")\n\n# Two-sample t-test\nt_stat, p_val = stats.ttest_ind(group_a, group_b)\nprint(f\"\\nTwo-sample t-test:\")\nprint(f\"Group A mean: {np.mean(group_a):.2f}\")\nprint(f\"Group B mean: {np.mean(group_b):.2f}\")\nprint(f\"T-statistic: {t_stat:.4f}\")\nprint(f\"P-value: {p_val:.6f}\")\n\n# Correlation analysis\nx = np.random.normal(0, 1, 100)\ny = 2 * x + np.random.normal(0, 0.5, 100)\ncorrelation, p_val = stats.pearsonr(x, y)\nprint(f\"\\nPearson correlation:\")\nprint(f\"Correlation coefficient: {correlation:.4f}\")\nprint(f\"P-value: {p_val:.6f}\")\n\n# Confidence intervals\nconfidence_level = 0.95\ndegrees_freedom = len(sample_data) - 1\nsample_mean = np.mean(sample_data)\nsample_se = stats.sem(sample_data)\nci = stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_se)\nprint(f\"\\n95% Confidence interval: ({ci[0]:.2f}, {ci[1]:.2f})\")\n\n# Chi-square test\nobserved = [20, 15, 25, 40]\nexpected = [25, 25, 25, 25]\nchi2_stat, p_val = stats.chisquare(observed, expected)\nprint(f\"\\nChi-square test:\")\nprint(f\"Chi-square statistic: {chi2_stat:.4f}\")\nprint(f\"P-value: {p_val:.6f}\")",
      "difficulty": "advanced",
      "categorySlug": "data-science",
      "xpReward": 30,
      "tags": [
        "statistics",
        "hypothesis-testing",
        "scipy",
        "analysis"
      ],
      "estimatedMinutes": 12,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Unit Testing with unittest and pytest",
      "content": "Writing tests ensures your code works correctly and helps prevent regressions. Python's unittest module and the popular pytest framework make testing straightforward and effective.",
      "codeExample": "# Using unittest (built-in)\nimport unittest\n\ndef add_numbers(a, b):\n    \"\"\"Add two numbers together\"\"\"\n    return a + b\n\ndef divide_numbers(a, b):\n    \"\"\"Divide two numbers\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\nclass Calculator:\n    def multiply(self, a, b):\n        return a * b\n    \n    def power(self, base, exponent):\n        return base ** exponent\n\n# Test class using unittest\nclass TestMathFunctions(unittest.TestCase):\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures before each test method.\"\"\"\n        self.calc = Calculator()\n        self.test_data = [1, 2, 3, 4, 5]\n    \n    def tearDown(self):\n        \"\"\"Clean up after each test method.\"\"\"\n        pass\n    \n    def test_add_numbers(self):\n        \"\"\"Test addition function\"\"\"\n        self.assertEqual(add_numbers(2, 3), 5)\n        self.assertEqual(add_numbers(-1, 1), 0)\n        self.assertEqual(add_numbers(0, 0), 0)\n    \n    def test_divide_numbers(self):\n        \"\"\"Test division function\"\"\"\n        self.assertEqual(divide_numbers(10, 2), 5)\n        self.assertAlmostEqual(divide_numbers(1, 3), 0.333, places=2)\n        \n        # Test exception handling\n        with self.assertRaises(ValueError):\n            divide_numbers(10, 0)\n    \n    def test_calculator_multiply(self):\n        \"\"\"Test calculator multiply method\"\"\"\n        self.assertEqual(self.calc.multiply(3, 4), 12)\n        self.assertEqual(self.calc.multiply(-2, 5), -10)\n    \n    def test_calculator_power(self):\n        \"\"\"Test calculator power method\"\"\"\n        self.assertEqual(self.calc.power(2, 3), 8)\n        self.assertEqual(self.calc.power(5, 0), 1)\n\n# Running tests\nif __name__ == '__main__':\n    unittest.main()\n\n# Alternative: Using pytest (install with: pip install pytest)\n# pytest offers simpler syntax and better output\n\nimport pytest\n\ndef test_add_numbers_pytest():\n    assert add_numbers(2, 3) == 5\n    assert add_numbers(-1, 1) == 0\n    assert add_numbers(0, 0) == 0\n\ndef test_divide_numbers_pytest():\n    assert divide_numbers(10, 2) == 5\n    assert abs(divide_numbers(1, 3) - 0.333) < 0.001\n    \n    with pytest.raises(ValueError):\n        divide_numbers(10, 0)\n\n# Parameterized tests with pytest\n@pytest.mark.parametrize(\"a,b,expected\", [\n    (2, 3, 5),\n    (-1, 1, 0),\n    (0, 0, 0),\n    (100, -50, 50)\n])\ndef test_add_numbers_parametrized(a, b, expected):\n    assert add_numbers(a, b) == expected\n\n# Fixtures in pytest\n@pytest.fixture\ndef calculator():\n    return Calculator()\n\n@pytest.fixture\ndef sample_data():\n    return [1, 2, 3, 4, 5]\n\ndef test_with_fixtures(calculator, sample_data):\n    result = calculator.multiply(sample_data[0], sample_data[1])\n    assert result == 2\n\n# Mock testing example\nfrom unittest.mock import Mock, patch\n\nclass DatabaseUser:\n    def __init__(self, db_connection):\n        self.db = db_connection\n    \n    def get_user(self, user_id):\n        result = self.db.query(f\"SELECT * FROM users WHERE id = {user_id}\")\n        return result\n\ndef test_database_user_with_mock():\n    # Create a mock database connection\n    mock_db = Mock()\n    mock_db.query.return_value = {\"id\": 1, \"name\": \"Alice\"}\n    \n    user_service = DatabaseUser(mock_db)\n    result = user_service.get_user(1)\n    \n    # Verify the result\n    assert result[\"name\"] == \"Alice\"\n    \n    # Verify that query was called with correct parameters\n    mock_db.query.assert_called_once_with(\"SELECT * FROM users WHERE id = 1\")\n\n# Testing with patches\ndef get_current_time():\n    from datetime import datetime\n    return datetime.now()\n\ndef test_with_patch():\n    with patch('datetime.datetime') as mock_datetime:\n        mock_datetime.now.return_value = \"2023-01-01 12:00:00\"\n        result = get_current_time()\n        assert result == \"2023-01-01 12:00:00\"\n\n# Run tests:\n# python -m unittest test_file.py\n# or\n# pytest test_file.py",
      "difficulty": "intermediate",
      "categorySlug": "testing-debugging",
      "xpReward": 22,
      "tags": [
        "testing",
        "unittest",
        "pytest",
        "mocking"
      ],
      "estimatedMinutes": 8,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Debugging Techniques and Tools",
      "content": "Effective debugging is crucial for finding and fixing bugs. Python provides several tools and techniques for debugging code, from simple print statements to powerful debuggers.",
      "codeExample": "import pdb\nimport traceback\nimport logging\n\n# 1. Print debugging (simple but effective)\ndef calculate_average(numbers):\n    print(f\"Input: {numbers}\")  # Debug print\n    \n    if not numbers:\n        print(\"Empty list detected\")  # Debug print\n        return 0\n    \n    total = sum(numbers)\n    count = len(numbers)\n    average = total / count\n    \n    print(f\"Total: {total}, Count: {count}, Average: {average}\")  # Debug print\n    return average\n\n# 2. Using assertions for debugging\ndef process_age(age):\n    assert isinstance(age, int), f\"Age must be an integer, got {type(age)}\"\n    assert 0 <= age <= 150, f\"Age must be between 0 and 150, got {age}\"\n    \n    if age < 18:\n        return \"minor\"\n    elif age < 65:\n        return \"adult\"\n    else:\n        return \"senior\"\n\n# 3. Exception handling with detailed error information\ndef safe_divide(a, b):\n    try:\n        result = a / b\n        return result\n    except ZeroDivisionError as e:\n        print(f\"Error: {e}\")\n        print(f\"Attempted to divide {a} by {b}\")\n        traceback.print_exc()  # Print full traceback\n        return None\n    except TypeError as e:\n        print(f\"Type error: {e}\")\n        print(f\"a={a} (type: {type(a)}), b={b} (type: {type(b)})\")\n        return None\n\n# 4. Using the Python debugger (pdb)\ndef buggy_function(data):\n    result = []\n    for item in data:\n        # Set breakpoint here\n        pdb.set_trace()  # Debugger will stop here\n        \n        processed = item * 2\n        if processed > 10:\n            result.append(processed)\n    \n    return result\n\n# 5. Logging for debugging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\n\ndef process_user_data(users):\n    logging.info(\"Starting user data processing\")\n    logging.debug(f\"Processing {len(users)} users\")\n    \n    processed_users = []\n    \n    for i, user in enumerate(users):\n        logging.debug(f\"Processing user {i}: {user}\")\n        \n        try:\n            if 'name' not in user:\n                logging.warning(f\"User {i} missing name field\")\n                continue\n            \n            if 'age' not in user:\n                logging.warning(f\"User {i} missing age field\")\n                user['age'] = 0\n            \n            processed_user = {\n                'name': user['name'].strip().title(),\n                'age': int(user['age']),\n                'status': 'processed'\n            }\n            \n            processed_users.append(processed_user)\n            logging.debug(f\"Successfully processed user: {processed_user}\")\n            \n        except Exception as e:\n            logging.error(f\"Error processing user {i}: {e}\")\n            logging.debug(f\"User data: {user}\")\n    \n    logging.info(f\"Completed processing. {len(processed_users)} users processed successfully\")\n    return processed_users\n\n# 6. Custom debugging decorator\ndef debug_calls(func):\n    def wrapper(*args, **kwargs):\n        print(f\"Calling {func.__name__} with args: {args}, kwargs: {kwargs}\")\n        \n        try:\n            result = func(*args, **kwargs)\n            print(f\"{func.__name__} returned: {result}\")\n            return result\n        except Exception as e:\n            print(f\"{func.__name__} raised exception: {e}\")\n            raise\n    \n    return wrapper\n\n@debug_calls\ndef add_numbers(a, b):\n    return a + b\n\n# 7. Memory and performance debugging\nimport time\nimport tracemalloc\n\ndef memory_debug_example():\n    # Start tracing memory allocations\n    tracemalloc.start()\n    \n    # Some memory-intensive operation\n    large_list = [i for i in range(1000000)]\n    \n    # Get memory usage\n    current, peak = tracemalloc.get_traced_memory()\n    print(f\"Current memory usage: {current / 1024 / 1024:.2f} MB\")\n    print(f\"Peak memory usage: {peak / 1024 / 1024:.2f} MB\")\n    \n    tracemalloc.stop()\n\ndef timing_debug_example():\n    start_time = time.time()\n    \n    # Some operation to time\n    result = sum(i*i for i in range(100000))\n    \n    end_time = time.time()\n    print(f\"Operation took {end_time - start_time:.4f} seconds\")\n    \n    return result\n\n# 8. Context manager for debugging\nclass DebugContext:\n    def __init__(self, name):\n        self.name = name\n    \n    def __enter__(self):\n        print(f\"Entering {self.name}\")\n        self.start_time = time.time()\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        end_time = time.time()\n        print(f\"Exiting {self.name} (took {end_time - self.start_time:.4f}s)\")\n        \n        if exc_type:\n            print(f\"Exception in {self.name}: {exc_val}\")\n        \n        return False  # Don't suppress exceptions\n\n# Usage example\nwith DebugContext(\"data processing\"):\n    data = [1, 2, 3, 4, 5]\n    result = [x * 2 for x in data]\n\n# 9. Interactive debugging with IPython\n# Install with: pip install ipython\n# In your code, add:\n# from IPython import embed\n# embed()  # Drops into IPython shell\n\n# 10. Unit test debugging\nclass DebuggableCalculator:\n    def __init__(self, debug=False):\n        self.debug = debug\n    \n    def _log(self, message):\n        if self.debug:\n            print(f\"DEBUG: {message}\")\n    \n    def divide(self, a, b):\n        self._log(f\"Dividing {a} by {b}\")\n        \n        if b == 0:\n            self._log(\"Division by zero detected\")\n            raise ValueError(\"Cannot divide by zero\")\n        \n        result = a / b\n        self._log(f\"Result: {result}\")\n        return result\n\n# Debugging tips:\n# - Use meaningful variable names\n# - Add type hints\n# - Write small, testable functions\n# - Use logging instead of print for production code\n# - Learn your IDE's debugging features\n# - Use version control to track when bugs were introduced",
      "difficulty": "intermediate",
      "categorySlug": "testing-debugging",
      "xpReward": 20,
      "tags": [
        "debugging",
        "pdb",
        "logging",
        "troubleshooting"
      ],
      "estimatedMinutes": 7,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Error Handling and Exception Strategies",
      "content": "Proper error handling makes your applications robust and user-friendly. Understanding different types of exceptions and handling strategies helps you build reliable software.",
      "codeExample": "# Built-in exception types\ndef demonstrate_exceptions():\n    # ValueError - invalid value for operation\n    try:\n        int(\"not_a_number\")\n    except ValueError as e:\n        print(f\"ValueError: {e}\")\n    \n    # TypeError - wrong type for operation\n    try:\n        \"string\" + 5\n    except TypeError as e:\n        print(f\"TypeError: {e}\")\n    \n    # IndexError - list index out of range\n    try:\n        my_list = [1, 2, 3]\n        print(my_list[10])\n    except IndexError as e:\n        print(f\"IndexError: {e}\")\n    \n    # KeyError - dictionary key not found\n    try:\n        my_dict = {\"a\": 1, \"b\": 2}\n        print(my_dict[\"c\"])\n    except KeyError as e:\n        print(f\"KeyError: {e}\")\n    \n    # FileNotFoundError - file doesn't exist\n    try:\n        with open(\"nonexistent_file.txt\", \"r\") as f:\n            content = f.read()\n    except FileNotFoundError as e:\n        print(f\"FileNotFoundError: {e}\")\n\n# Custom exception classes\nclass ValidationError(Exception):\n    \"\"\"Raised when data validation fails\"\"\"\n    def __init__(self, message, field_name=None):\n        super().__init__(message)\n        self.field_name = field_name\n\nclass BusinessLogicError(Exception):\n    \"\"\"Raised when business rules are violated\"\"\"\n    pass\n\nclass ConfigurationError(Exception):\n    \"\"\"Raised when configuration is invalid\"\"\"\n    def __init__(self, message, config_key=None):\n        super().__init__(message)\n        self.config_key = config_key\n\n# Exception handling strategies\nclass UserValidator:\n    @staticmethod\n    def validate_email(email):\n        if not email:\n            raise ValidationError(\"Email is required\", \"email\")\n        \n        if \"@\" not in email:\n            raise ValidationError(\"Invalid email format\", \"email\")\n        \n        return True\n    \n    @staticmethod\n    def validate_age(age):\n        if not isinstance(age, int):\n            raise ValidationError(\"Age must be an integer\", \"age\")\n        \n        if age < 0 or age > 150:\n            raise ValidationError(\"Age must be between 0 and 150\", \"age\")\n        \n        return True\n\n# Error handling with multiple exception types\ndef process_user_registration(user_data):\n    try:\n        # Validate required fields\n        UserValidator.validate_email(user_data.get(\"email\"))\n        UserValidator.validate_age(user_data.get(\"age\"))\n        \n        # Simulate business logic\n        if user_data.get(\"age\", 0) < 13:\n            raise BusinessLogicError(\"Users must be at least 13 years old\")\n        \n        return {\"status\": \"success\", \"user_id\": 12345}\n        \n    except ValidationError as e:\n        return {\n            \"status\": \"validation_error\",\n            \"message\": str(e),\n            \"field\": e.field_name\n        }\n    \n    except BusinessLogicError as e:\n        return {\n            \"status\": \"business_error\",\n            \"message\": str(e)\n        }\n    \n    except Exception as e:\n        # Catch-all for unexpected errors\n        return {\n            \"status\": \"internal_error\",\n            \"message\": \"An unexpected error occurred\"\n        }\n\n# Context manager for exception handling\nclass ErrorHandler:\n    def __init__(self, operation_name):\n        self.operation_name = operation_name\n        self.errors = []\n    \n    def __enter__(self):\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type:\n            error_info = {\n                \"operation\": self.operation_name,\n                \"exception_type\": exc_type.__name__,\n                \"message\": str(exc_val)\n            }\n            self.errors.append(error_info)\n            print(f\"Error in {self.operation_name}: {exc_val}\")\n            return True  # Suppress the exception\n        return False\n\n# Usage of error handler context manager\ndef process_data_with_error_handling():\n    results = []\n    \n    with ErrorHandler(\"data processing\") as handler:\n        # Simulate some operations that might fail\n        data = [1, 2, \"invalid\", 4, 5]\n        \n        for item in data:\n            try:\n                result = int(item) * 2\n                results.append(result)\n            except ValueError:\n                print(f\"Skipping invalid item: {item}\")\n    \n    return results\n\n# Retry mechanism with exponential backoff\nimport time\nimport random\n\ndef retry_with_backoff(max_retries=3, base_delay=1, max_delay=60):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            for attempt in range(max_retries):\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    if attempt == max_retries - 1:\n                        # Last attempt, re-raise the exception\n                        raise e\n                    \n                    # Calculate delay with exponential backoff\n                    delay = min(base_delay * (2 ** attempt), max_delay)\n                    jitter = random.uniform(0, 0.1) * delay\n                    total_delay = delay + jitter\n                    \n                    print(f\"Attempt {attempt + 1} failed: {e}\")\n                    print(f\"Retrying in {total_delay:.2f} seconds...\")\n                    time.sleep(total_delay)\n            \n        return wrapper\n    return decorator\n\n@retry_with_backoff(max_retries=3)\ndef unreliable_network_call():\n    # Simulate a network call that might fail\n    if random.random() < 0.7:  # 70% chance of failure\n        raise ConnectionError(\"Network timeout\")\n    \n    return {\"status\": \"success\", \"data\": \"Important data\"}\n\n# Graceful degradation\nclass DataService:\n    def __init__(self):\n        self.cache_enabled = True\n        self.fallback_enabled = True\n    \n    def get_data(self, key):\n        # Try primary data source\n        try:\n            return self._get_from_primary(key)\n        except Exception as e:\n            print(f\"Primary source failed: {e}\")\n            \n            # Try cache\n            if self.cache_enabled:\n                try:\n                    return self._get_from_cache(key)\n                except Exception as e:\n                    print(f\"Cache failed: {e}\")\n            \n            # Try fallback\n            if self.fallback_enabled:\n                try:\n                    return self._get_from_fallback(key)\n                except Exception as e:\n                    print(f\"Fallback failed: {e}\")\n            \n            # All options exhausted\n            raise Exception(\"All data sources unavailable\")\n    \n    def _get_from_primary(self, key):\n        # Simulate primary data source\n        if random.random() < 0.3:  # 30% failure rate\n            raise Exception(\"Primary source unavailable\")\n        return f\"Primary data for {key}\"\n    \n    def _get_from_cache(self, key):\n        # Simulate cache\n        if random.random() < 0.1:  # 10% failure rate\n            raise Exception(\"Cache miss\")\n        return f\"Cached data for {key}\"\n    \n    def _get_from_fallback(self, key):\n        # Simulate fallback\n        return f\"Fallback data for {key}\"\n\n# Exception logging\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef logged_operation(data):\n    try:\n        # Some risky operation\n        result = process_complex_data(data)\n        logger.info(f\"Operation completed successfully: {result}\")\n        return result\n        \n    except ValidationError as e:\n        logger.warning(f\"Validation failed: {e}\")\n        raise\n        \n    except Exception as e:\n        logger.error(f\"Unexpected error in logged_operation: {e}\", exc_info=True)\n        raise\n\ndef process_complex_data(data):\n    if not data:\n        raise ValidationError(\"Data cannot be empty\")\n    \n    if len(data) > 1000:\n        raise ValidationError(\"Data too large\")\n    \n    return f\"Processed {len(data)} items\"\n\n# Example usage\ntry:\n    result = process_user_registration({\n        \"email\": \"test@example.com\",\n        \"age\": 25\n    })\n    print(result)\nexcept Exception as e:\n    print(f\"Registration failed: {e}\")",
      "difficulty": "intermediate",
      "categorySlug": "testing-debugging",
      "xpReward": 24,
      "tags": [
        "exceptions",
        "error-handling",
        "validation",
        "robustness"
      ],
      "estimatedMinutes": 9,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Code Quality and Static Analysis",
      "content": "Maintaining code quality through static analysis tools, linting, and formatting helps prevent bugs and makes code more maintainable. These tools catch issues before runtime.",
      "codeExample": "# Code quality tools overview:\n# 1. pylint - comprehensive code analysis\n# 2. flake8 - style guide enforcement\n# 3. black - automatic code formatting\n# 4. mypy - static type checking\n# 5. bandit - security vulnerability scanner\n\n# Install tools:\n# pip install pylint flake8 black mypy bandit\n\n# Example code with various quality issues\nimport os\nimport sys\n\n# Bad practices (will be caught by linters)\ndef badFunction(x,y):  # Bad naming, spacing\n    z=x+y  # No spaces around operators\n    return z\n\n# Good practices\ndef calculate_sum(first_number: int, second_number: int) -> int:\n    \"\"\"Calculate the sum of two numbers.\n    \n    Args:\n        first_number: The first number to add\n        second_number: The second number to add\n        \n    Returns:\n        The sum of the two numbers\n    \"\"\"\n    result = first_number + second_number\n    return result\n\n# Type hints for better code quality\nfrom typing import List, Dict, Optional, Union\n\nclass UserManager:\n    \"\"\"Manages user operations with proper type hints and documentation.\"\"\"\n    \n    def __init__(self) -> None:\n        self.users: Dict[int, Dict[str, Union[str, int]]] = {}\n        self.next_id: int = 1\n    \n    def add_user(self, name: str, email: str, age: int) -> int:\n        \"\"\"Add a new user to the system.\n        \n        Args:\n            name: User's full name\n            email: User's email address\n            age: User's age\n            \n        Returns:\n            The ID of the newly created user\n            \n        Raises:\n            ValueError: If any input is invalid\n        \"\"\"\n        if not name or not email:\n            raise ValueError(\"Name and email are required\")\n        \n        if age < 0 or age > 150:\n            raise ValueError(\"Age must be between 0 and 150\")\n        \n        user_id = self.next_id\n        self.users[user_id] = {\n            \"name\": name,\n            \"email\": email,\n            \"age\": age\n        }\n        self.next_id += 1\n        \n        return user_id\n    \n    def get_user(self, user_id: int) -> Optional[Dict[str, Union[str, int]]]:\n        \"\"\"Get user by ID.\n        \n        Args:\n            user_id: The ID of the user to retrieve\n            \n        Returns:\n            User data if found, None otherwise\n        \"\"\"\n        return self.users.get(user_id)\n    \n    def get_users_by_age_range(\n        self,\n        min_age: int,\n        max_age: int\n    ) -> List[Dict[str, Union[str, int]]]:\n        \"\"\"Get all users within a specific age range.\n        \n        Args:\n            min_age: Minimum age (inclusive)\n            max_age: Maximum age (inclusive)\n            \n        Returns:\n            List of users within the age range\n        \"\"\"\n        result = []\n        for user in self.users.values():\n            user_age = user[\"age\"]\n            if isinstance(user_age, int) and min_age <= user_age <= max_age:\n                result.append(user)\n        \n        return result\n\n# Configuration for tools (put in separate files)\n\n# .pylintrc configuration example\nPYLINT_CONFIG = \"\"\"\n[MASTER]\nextension-pkg-whitelist=pydantic\n\n[MESSAGES CONTROL]\ndisable=missing-docstring,line-too-long\n\n[FORMAT]\nmax-line-length=88\n\n[DESIGN]\nmax-args=7\nmax-locals=15\n\"\"\"\n\n# setup.cfg for flake8\nFLAKE8_CONFIG = \"\"\"\n[flake8]\nmax-line-length = 88\nextend-ignore = E203, W503\nexclude = .git,__pycache__,docs/source/conf.py,old,build,dist\n\"\"\"\n\n# pyproject.toml for black\nPYPROJECT_TOML = \"\"\"\n[tool.black]\nline-length = 88\ntarget-version = ['py38']\ninclude = '\\.pyi?$'\nextend-exclude = '''\n/(\n  # directories\n  \\.eggs\n  | \\.git\n  | \\.hg\n  | \\.mypy_cache\n  | \\.tox\n  | \\.venv\n  | build\n  | dist\n)/\n'''\n\"\"\"\n\n# mypy configuration in mypy.ini\nMYPY_CONFIG = \"\"\"\n[mypy]\npython_version = 3.8\nwarn_return_any = True\nwarn_unused_configs = True\ndisallow_untyped_defs = True\n\n[mypy-requests.*]\nignore_missing_imports = True\n\"\"\"\n\n# Example of code analysis functions\ndef analyze_code_complexity():\n    \"\"\"Example of measuring code complexity.\"\"\"\n    \n    # Simple function (low complexity)\n    def simple_function(x):\n        return x * 2\n    \n    # Complex function (high complexity - should be refactored)\n    def complex_function(data, filters, options):\n        results = []\n        if data:\n            for item in data:\n                if filters:\n                    for filter_key, filter_value in filters.items():\n                        if item.get(filter_key) == filter_value:\n                            if options:\n                                if options.get(\"include_metadata\"):\n                                    item[\"metadata\"] = {\"processed\": True}\n                                if options.get(\"sort\"):\n                                    # Complex sorting logic\n                                    pass\n                            results.append(item)\n                            break\n                else:\n                    results.append(item)\n        return results\n    \n    # Better approach - split into smaller functions\n    def filter_items(items, filters):\n        if not filters:\n            return items\n        \n        filtered = []\n        for item in items:\n            if matches_filters(item, filters):\n                filtered.append(item)\n        \n        return filtered\n    \n    def matches_filters(item, filters):\n        for filter_key, filter_value in filters.items():\n            if item.get(filter_key) != filter_value:\n                return False\n        return True\n    \n    def add_metadata(items, options):\n        if not options or not options.get(\"include_metadata\"):\n            return items\n        \n        for item in items:\n            item[\"metadata\"] = {\"processed\": True}\n        \n        return items\n    \n    def process_items_better(data, filters=None, options=None):\n        if not data:\n            return []\n        \n        results = filter_items(data, filters)\n        results = add_metadata(results, options)\n        \n        if options and options.get(\"sort\"):\n            results = sorted(results, key=lambda x: x.get(\"name\", \"\"))\n        \n        return results\n\n# Pre-commit hooks configuration (.pre-commit-config.yaml)\nPRE_COMMIT_CONFIG = \"\"\"\nrepos:\n  - repo: https://github.com/psf/black\n    rev: 22.3.0\n    hooks:\n      - id: black\n\n  - repo: https://github.com/pycqa/flake8\n    rev: 4.0.1\n    hooks:\n      - id: flake8\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v0.950\n    hooks:\n      - id: mypy\n\n  - repo: https://github.com/pycqa/bandit\n    rev: 1.7.4\n    hooks:\n      - id: bandit\n\"\"\"\n\n# Example of docstring standards (Google style)\ndef example_function(\n    param1: str,\n    param2: int,\n    param3: Optional[bool] = None\n) -> Dict[str, Union[str, int]]:\n    \"\"\"Example function with proper documentation.\n    \n    This function demonstrates proper docstring formatting\n    following Google style guidelines.\n    \n    Args:\n        param1: Description of the first parameter\n        param2: Description of the second parameter\n        param3: Optional description of the third parameter\n        \n    Returns:\n        Dictionary containing processed results with string keys\n        and string or integer values\n        \n    Raises:\n        ValueError: If param1 is empty\n        TypeError: If param2 is not an integer\n        \n    Example:\n        >>> result = example_function(\"test\", 42)\n        >>> print(result[\"status\"])\n        success\n    \"\"\"\n    if not param1:\n        raise ValueError(\"param1 cannot be empty\")\n    \n    if not isinstance(param2, int):\n        raise TypeError(\"param2 must be an integer\")\n    \n    return {\n        \"status\": \"success\",\n        \"input_length\": len(param1),\n        \"multiplied_value\": param2 * 2\n    }\n\n# Running quality checks:\n# pylint your_module.py\n# flake8 your_module.py\n# black your_module.py\n# mypy your_module.py\n# bandit -r your_project/",
      "difficulty": "intermediate",
      "categorySlug": "testing-debugging",
      "xpReward": 26,
      "tags": [
        "code-quality",
        "linting",
        "static-analysis",
        "formatting"
      ],
      "estimatedMinutes": 10,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Memory Optimization and Profiling",
      "content": "Understanding memory usage and optimizing it is crucial for building efficient applications. Python provides tools to monitor and optimize memory consumption.",
      "codeExample": "import sys\nimport gc\nimport tracemalloc\nfrom memory_profiler import profile\n\n# Memory-efficient data structures\n# Use __slots__ to reduce memory overhead\nclass RegularClass:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\nclass OptimizedClass:\n    __slots__ = ['x', 'y']  # Reduces memory overhead\n    \n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n# Compare memory usage\ndef compare_memory_usage():\n    import pympler.asizeof as asizeof\n    \n    regular_obj = RegularClass(1, 2)\n    optimized_obj = OptimizedClass(1, 2)\n    \n    print(f\"Regular class size: {asizeof.asizeof(regular_obj)} bytes\")\n    print(f\"Optimized class size: {asizeof.asizeof(optimized_obj)} bytes\")\n\n# Memory profiling with tracemalloc\ndef memory_profiling_example():\n    tracemalloc.start()\n    \n    # Memory-intensive operation\n    large_list = []\n    for i in range(100000):\n        large_list.append(f\"Item {i}\")\n    \n    # Get current memory usage\n    current, peak = tracemalloc.get_traced_memory()\n    print(f\"Current memory: {current / 1024 / 1024:.2f} MB\")\n    print(f\"Peak memory: {peak / 1024 / 1024:.2f} MB\")\n    \n    # Get top memory allocations\n    snapshot = tracemalloc.take_snapshot()\n    top_stats = snapshot.statistics('lineno')\n    \n    print(\"Top 3 memory allocations:\")\n    for stat in top_stats[:3]:\n        print(stat)\n    \n    tracemalloc.stop()\n\n# Generator vs List - memory comparison\ndef memory_efficient_processing():\n    # Memory-intensive (loads all data)\n    def process_with_list(n):\n        data = [i * i for i in range(n)]\n        return sum(data)\n    \n    # Memory-efficient (processes one at a time)\n    def process_with_generator(n):\n        data = (i * i for i in range(n))\n        return sum(data)\n    \n    # Compare memory usage\n    print(\"List approach:\")\n    tracemalloc.start()\n    result1 = process_with_list(100000)\n    current, peak = tracemalloc.get_traced_memory()\n    print(f\"Peak memory: {peak / 1024:.2f} KB\")\n    tracemalloc.stop()\n    \n    print(\"\\nGenerator approach:\")\n    tracemalloc.start()\n    result2 = process_with_generator(100000)\n    current, peak = tracemalloc.get_traced_memory()\n    print(f\"Peak memory: {peak / 1024:.2f} KB\")\n    tracemalloc.stop()\n\n# Object pooling for frequent allocations\nclass ObjectPool:\n    def __init__(self, create_func, reset_func, initial_size=10):\n        self.create_func = create_func\n        self.reset_func = reset_func\n        self.pool = [create_func() for _ in range(initial_size)]\n    \n    def get(self):\n        if self.pool:\n            return self.pool.pop()\n        return self.create_func()\n    \n    def release(self, obj):\n        self.reset_func(obj)\n        self.pool.append(obj)\n\n# Example usage of object pooling\nclass ExpensiveObject:\n    def __init__(self):\n        self.data = [0] * 1000  # Simulate expensive object\n        self.processed = False\n    \n    def reset(self):\n        self.data = [0] * 1000\n        self.processed = False\n\ndef create_expensive_object():\n    return ExpensiveObject()\n\ndef reset_expensive_object(obj):\n    obj.reset()\n\n# Use object pool\npool = ObjectPool(create_expensive_object, reset_expensive_object)\n\ndef use_object_pool():\n    obj = pool.get()\n    # Use the object\n    obj.processed = True\n    # Return to pool when done\n    pool.release(obj)\n\n# Weak references to avoid memory leaks\nimport weakref\n\nclass Observer:\n    def __init__(self):\n        self.observers = weakref.WeakSet()\n    \n    def add_observer(self, observer):\n        self.observers.add(observer)\n    \n    def notify(self, message):\n        for observer in self.observers:\n            observer.handle(message)\n\n# Manual garbage collection\ndef manual_gc_example():\n    # Create objects that might create cycles\n    class Node:\n        def __init__(self, value):\n            self.value = value\n            self.children = []\n            self.parent = None\n    \n    # Create a structure with potential cycles\n    root = Node(\"root\")\n    child1 = Node(\"child1\")\n    child2 = Node(\"child2\")\n    \n    root.children = [child1, child2]\n    child1.parent = root\n    child2.parent = root\n    \n    # Force garbage collection\n    gc.collect()\n    \n    print(f\"Garbage collector stats: {gc.get_stats()}\")",
      "difficulty": "advanced",
      "categorySlug": "performance",
      "xpReward": 28,
      "tags": [
        "memory",
        "profiling",
        "optimization",
        "gc"
      ],
      "estimatedMinutes": 10,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Algorithm Optimization and Big O",
      "content": "Understanding algorithm complexity and choosing the right data structures can dramatically improve performance. Learn to analyze and optimize your algorithms.",
      "codeExample": "import time\nfrom collections import defaultdict, deque\nimport bisect\n\n# Time complexity examples\ndef demonstrate_time_complexity():\n    # O(1) - Constant time\n    def constant_time_operation(data):\n        return data[0] if data else None  # Always same time\n    \n    # O(n) - Linear time\n    def linear_search(data, target):\n        for i, item in enumerate(data):\n            if item == target:\n                return i\n        return -1\n    \n    # O(log n) - Logarithmic time\n    def binary_search(sorted_data, target):\n        left, right = 0, len(sorted_data) - 1\n        \n        while left <= right:\n            mid = (left + right) // 2\n            if sorted_data[mid] == target:\n                return mid\n            elif sorted_data[mid] < target:\n                left = mid + 1\n            else:\n                right = mid - 1\n        \n        return -1\n    \n    # O(n log n) - Efficient sorting\n    def merge_sort(arr):\n        if len(arr) <= 1:\n            return arr\n        \n        mid = len(arr) // 2\n        left = merge_sort(arr[:mid])\n        right = merge_sort(arr[mid:])\n        \n        return merge(left, right)\n    \n    def merge(left, right):\n        result = []\n        i = j = 0\n        \n        while i < len(left) and j < len(right):\n            if left[i] <= right[j]:\n                result.append(left[i])\n                i += 1\n            else:\n                result.append(right[j])\n                j += 1\n        \n        result.extend(left[i:])\n        result.extend(right[j:])\n        return result\n    \n    # O(n¬≤) - Quadratic time (inefficient for large datasets)\n    def bubble_sort(arr):\n        n = len(arr)\n        for i in range(n):\n            for j in range(0, n - i - 1):\n                if arr[j] > arr[j + 1]:\n                    arr[j], arr[j + 1] = arr[j + 1], arr[j]\n        return arr\n\n# Data structure optimization\ndef optimize_data_structures():\n    # Wrong: Using list for frequent lookups\n    def slow_membership_test(items, targets):\n        results = []\n        for target in targets:\n            if target in items:  # O(n) for each lookup\n                results.append(target)\n        return results\n    \n    # Better: Using set for O(1) lookups\n    def fast_membership_test(items, targets):\n        item_set = set(items)  # Convert once\n        results = []\n        for target in targets:\n            if target in item_set:  # O(1) for each lookup\n                results.append(target)\n        return results\n    \n    # Demonstrate performance difference\n    large_list = list(range(10000))\n    test_items = [100, 5000, 9999] * 1000\n    \n    start = time.time()\n    slow_result = slow_membership_test(large_list, test_items)\n    slow_time = time.time() - start\n    \n    start = time.time()\n    fast_result = fast_membership_test(large_list, test_items)\n    fast_time = time.time() - start\n    \n    print(f\"Slow method: {slow_time:.4f} seconds\")\n    print(f\"Fast method: {fast_time:.4f} seconds\")\n    print(f\"Speedup: {slow_time / fast_time:.1f}x\")\n\n# Cache optimization\nfrom functools import lru_cache\n\n# Without caching - exponential time complexity\ndef fibonacci_slow(n):\n    if n < 2:\n        return n\n    return fibonacci_slow(n - 1) + fibonacci_slow(n - 2)\n\n# With caching - linear time complexity\n@lru_cache(maxsize=None)\ndef fibonacci_fast(n):\n    if n < 2:\n        return n\n    return fibonacci_fast(n - 1) + fibonacci_fast(n - 2)\n\ndef compare_fibonacci_performance():\n    n = 35\n    \n    start = time.time()\n    result_slow = fibonacci_slow(n)\n    slow_time = time.time() - start\n    \n    start = time.time()\n    result_fast = fibonacci_fast(n)\n    fast_time = time.time() - start\n    \n    print(f\"Fibonacci({n}) = {result_slow}\")\n    print(f\"Without cache: {slow_time:.4f} seconds\")\n    print(f\"With cache: {fast_time:.6f} seconds\")\n    print(f\"Speedup: {slow_time / fast_time:.0f}x\")\n\n# Efficient string operations\ndef string_optimization():\n    # Slow: String concatenation in loop\n    def slow_string_building(items):\n        result = \"\"\n        for item in items:\n            result += str(item) + \", \"\n        return result[:-2]  # Remove last comma\n    \n    # Fast: Using join\n    def fast_string_building(items):\n        return \", \".join(str(item) for item in items)\n    \n    # Even faster: Pre-allocate with list\n    def fastest_string_building(items):\n        parts = []\n        for item in items:\n            parts.append(str(item))\n        return \", \".join(parts)\n    \n    test_items = list(range(10000))\n    \n    start = time.time()\n    slow_result = slow_string_building(test_items)\n    slow_time = time.time() - start\n    \n    start = time.time()\n    fast_result = fast_string_building(test_items)\n    fast_time = time.time() - start\n    \n    print(f\"Slow concatenation: {slow_time:.4f} seconds\")\n    print(f\"Fast join: {fast_time:.4f} seconds\")\n    print(f\"Speedup: {slow_time / fast_time:.1f}x\")\n\n# Algorithm selection for different use cases\nclass OptimizedDataProcessor:\n    def __init__(self):\n        self.data = []\n        self.sorted_data = []\n        self.data_set = set()\n        self.counter = defaultdict(int)\n    \n    def add_item(self, item):\n        # Choose appropriate data structure for operations\n        self.data.append(item)\n        self.data_set.add(item)\n        self.counter[item] += 1\n        \n        # Keep sorted version for binary search\n        bisect.insort(self.sorted_data, item)\n    \n    def exists(self, item):\n        # O(1) lookup using set\n        return item in self.data_set\n    \n    def find_position(self, item):\n        # O(log n) binary search on sorted data\n        return bisect.bisect_left(self.sorted_data, item)\n    \n    def get_frequency(self, item):\n        # O(1) lookup using defaultdict\n        return self.counter[item]\n    \n    def get_top_k_frequent(self, k):\n        # O(n log k) using heap for top-k\n        import heapq\n        return heapq.nlargest(k, self.counter.items(), key=lambda x: x[1])\n\n# Batch processing for better performance\ndef batch_processing_example():\n    # Inefficient: Process one at a time\n    def process_individually(items):\n        results = []\n        for item in items:\n            # Simulate expensive operation\n            processed = expensive_operation(item)\n            results.append(processed)\n        return results\n    \n    # Efficient: Process in batches\n    def process_in_batches(items, batch_size=100):\n        results = []\n        for i in range(0, len(items), batch_size):\n            batch = items[i:i + batch_size]\n            # Process entire batch at once\n            batch_results = expensive_batch_operation(batch)\n            results.extend(batch_results)\n        return results\n\ndef expensive_operation(item):\n    # Simulate expensive operation\n    return item * 2\n\ndef expensive_batch_operation(batch):\n    # Simulate batch operation (more efficient)\n    return [item * 2 for item in batch]\n\n# Memory-efficient iteration\ndef memory_efficient_file_processing(filename):\n    # Bad: Load entire file into memory\n    def process_entire_file():\n        with open(filename, 'r') as f:\n            lines = f.readlines()  # Loads everything\n            return [line.strip().upper() for line in lines]\n    \n    # Good: Process line by line\n    def process_line_by_line():\n        results = []\n        with open(filename, 'r') as f:\n            for line in f:  # Generator - one line at a time\n                processed = line.strip().upper()\n                results.append(processed)\n        return results\n    \n    # Best: Generator function\n    def process_as_generator():\n        with open(filename, 'r') as f:\n            for line in f:\n                yield line.strip().upper()\n\n# Performance measurement decorator\ndef measure_performance(func):\n    def wrapper(*args, **kwargs):\n        start_time = time.time()\n        start_memory = tracemalloc.get_traced_memory()[0]\n        \n        result = func(*args, **kwargs)\n        \n        end_time = time.time()\n        end_memory = tracemalloc.get_traced_memory()[0]\n        \n        print(f\"{func.__name__}:\")\n        print(f\"  Time: {end_time - start_time:.4f} seconds\")\n        print(f\"  Memory: {(end_memory - start_memory) / 1024:.2f} KB\")\n        \n        return result\n    return wrapper",
      "difficulty": "advanced",
      "categorySlug": "performance",
      "xpReward": 30,
      "tags": [
        "algorithms",
        "big-o",
        "optimization",
        "data-structures"
      ],
      "estimatedMinutes": 12,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Concurrency and Parallel Processing",
      "content": "Python offers several approaches to concurrency and parallelism. Understanding when to use threading, multiprocessing, or async programming can significantly improve performance.",
      "codeExample": "import threading\nimport multiprocessing\nimport asyncio\nimport concurrent.futures\nimport time\nimport requests\n\n# Threading for I/O-bound tasks\ndef threading_example():\n    def io_bound_task(task_id, duration):\n        print(f\"Task {task_id} starting\")\n        time.sleep(duration)  # Simulate I/O operation\n        print(f\"Task {task_id} completed\")\n        return f\"Result from task {task_id}\"\n    \n    # Sequential execution\n    def sequential_execution():\n        start_time = time.time()\n        results = []\n        for i in range(5):\n            result = io_bound_task(i, 1)\n            results.append(result)\n        \n        end_time = time.time()\n        print(f\"Sequential execution took: {end_time - start_time:.2f} seconds\")\n        return results\n    \n    # Threaded execution\n    def threaded_execution():\n        start_time = time.time()\n        results = []\n        threads = []\n        \n        def worker(task_id, duration, results, index):\n            result = io_bound_task(task_id, duration)\n            results[index] = result\n        \n        # Pre-allocate results list\n        results = [None] * 5\n        \n        # Create and start threads\n        for i in range(5):\n            thread = threading.Thread(target=worker, args=(i, 1, results, i))\n            threads.append(thread)\n            thread.start()\n        \n        # Wait for all threads to complete\n        for thread in threads:\n            thread.join()\n        \n        end_time = time.time()\n        print(f\"Threaded execution took: {end_time - start_time:.2f} seconds\")\n        return results\n\n# Multiprocessing for CPU-bound tasks\ndef multiprocessing_example():\n    def cpu_bound_task(n):\n        # Simulate CPU-intensive work\n        total = 0\n        for i in range(n * 1000000):\n            total += i * i\n        return total\n    \n    # Sequential execution\n    def sequential_cpu_work():\n        start_time = time.time()\n        results = []\n        \n        for i in range(4):\n            result = cpu_bound_task(100)\n            results.append(result)\n        \n        end_time = time.time()\n        print(f\"Sequential CPU work took: {end_time - start_time:.2f} seconds\")\n        return results\n    \n    # Multiprocessing execution\n    def parallel_cpu_work():\n        start_time = time.time()\n        \n        with multiprocessing.Pool() as pool:\n            results = pool.map(cpu_bound_task, [100] * 4)\n        \n        end_time = time.time()\n        print(f\"Parallel CPU work took: {end_time - start_time:.2f} seconds\")\n        return results\n\n# AsyncIO for asynchronous programming\nasync def asyncio_example():\n    async def async_fetch(session, url, task_id):\n        print(f\"Fetching {task_id}\")\n        try:\n            async with session.get(url) as response:\n                data = await response.text()\n                print(f\"Completed {task_id}\")\n                return len(data)\n        except Exception as e:\n            print(f\"Error in {task_id}: {e}\")\n            return 0\n    \n    async def fetch_multiple_urls():\n        import aiohttp\n        \n        urls = [\n            \"https://httpbin.org/delay/1\",\n            \"https://httpbin.org/delay/1\",\n            \"https://httpbin.org/delay/1\",\n            \"https://httpbin.org/delay/1\"\n        ]\n        \n        start_time = time.time()\n        \n        async with aiohttp.ClientSession() as session:\n            tasks = [async_fetch(session, url, i) for i, url in enumerate(urls)]\n            results = await asyncio.gather(*tasks)\n        \n        end_time = time.time()\n        print(f\"Async execution took: {end_time - start_time:.2f} seconds\")\n        return results\n\n# ThreadPoolExecutor and ProcessPoolExecutor\ndef executor_examples():\n    def download_url(url):\n        response = requests.get(url)\n        return len(response.content)\n    \n    # Using ThreadPoolExecutor for I/O-bound tasks\n    def concurrent_downloads():\n        urls = [\n            \"https://httpbin.org/bytes/1024\",\n            \"https://httpbin.org/bytes/2048\",\n            \"https://httpbin.org/bytes/4096\"\n        ]\n        \n        start_time = time.time()\n        \n        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n            future_to_url = {executor.submit(download_url, url): url for url in urls}\n            results = []\n            \n            for future in concurrent.futures.as_completed(future_to_url):\n                url = future_to_url[future]\n                try:\n                    result = future.result()\n                    results.append(result)\n                    print(f\"Downloaded {result} bytes from {url}\")\n                except Exception as e:\n                    print(f\"Error downloading {url}: {e}\")\n        \n        end_time = time.time()\n        print(f\"Concurrent downloads took: {end_time - start_time:.2f} seconds\")\n        return results\n    \n    # Using ProcessPoolExecutor for CPU-bound tasks\n    def concurrent_computation():\n        def fibonacci(n):\n            if n < 2:\n                return n\n            return fibonacci(n-1) + fibonacci(n-2)\n        \n        numbers = [30, 31, 32, 33]\n        start_time = time.time()\n        \n        with concurrent.futures.ProcessPoolExecutor() as executor:\n            results = list(executor.map(fibonacci, numbers))\n        \n        end_time = time.time()\n        print(f\"Concurrent computation took: {end_time - start_time:.2f} seconds\")\n        return results\n\n# Producer-Consumer pattern with queue\ndef producer_consumer_example():\n    import queue\n    \n    def producer(q, num_items):\n        for i in range(num_items):\n            item = f\"item_{i}\"\n            q.put(item)\n            print(f\"Produced: {item}\")\n            time.sleep(0.1)\n        \n        # Signal end of production\n        q.put(None)\n    \n    def consumer(q, consumer_id):\n        while True:\n            item = q.get()\n            if item is None:\n                q.put(None)  # Re-queue sentinel for other consumers\n                break\n            \n            print(f\"Consumer {consumer_id} processing: {item}\")\n            time.sleep(0.2)  # Simulate processing\n            q.task_done()\n    \n    # Create queue and threads\n    q = queue.Queue()\n    \n    # Start producer\n    producer_thread = threading.Thread(target=producer, args=(q, 10))\n    producer_thread.start()\n    \n    # Start consumers\n    consumers = []\n    for i in range(3):\n        consumer_thread = threading.Thread(target=consumer, args=(q, i))\n        consumers.append(consumer_thread)\n        consumer_thread.start()\n    \n    # Wait for completion\n    producer_thread.join()\n    q.join()  # Wait for all tasks to be done\n\n# Thread-safe operations\nclass ThreadSafeCounter:\n    def __init__(self):\n        self._count = 0\n        self._lock = threading.Lock()\n    \n    def increment(self):\n        with self._lock:\n            self._count += 1\n    \n    def get_count(self):\n        with self._lock:\n            return self._count\n\ndef thread_safety_example():\n    counter = ThreadSafeCounter()\n    \n    def worker():\n        for _ in range(1000):\n            counter.increment()\n    \n    # Create multiple threads\n    threads = []\n    for _ in range(10):\n        thread = threading.Thread(target=worker)\n        threads.append(thread)\n        thread.start()\n    \n    # Wait for all threads\n    for thread in threads:\n        thread.join()\n    \n    print(f\"Final count: {counter.get_count()}\")  # Should be 10,000\n\n# Performance comparison\ndef compare_concurrency_approaches():\n    def cpu_task(n):\n        return sum(i*i for i in range(n))\n    \n    def io_task():\n        time.sleep(0.1)\n        return \"completed\"\n    \n    # Test different approaches\n    tasks = [100000] * 4\n    \n    print(\"CPU-bound tasks:\")\n    \n    # Sequential\n    start = time.time()\n    results = [cpu_task(n) for n in tasks]\n    print(f\"Sequential: {time.time() - start:.2f}s\")\n    \n    # Multiprocessing\n    start = time.time()\n    with multiprocessing.Pool() as pool:\n        results = pool.map(cpu_task, tasks)\n    print(f\"Multiprocessing: {time.time() - start:.2f}s\")\n    \n    print(\"\\nI/O-bound tasks:\")\n    \n    # Sequential\n    start = time.time()\n    results = [io_task() for _ in range(10)]\n    print(f\"Sequential: {time.time() - start:.2f}s\")\n    \n    # Threading\n    start = time.time()\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        results = list(executor.map(lambda _: io_task(), range(10)))\n    print(f\"Threading: {time.time() - start:.2f}s\")",
      "difficulty": "advanced",
      "categorySlug": "performance",
      "xpReward": 32,
      "tags": [
        "concurrency",
        "threading",
        "multiprocessing",
        "asyncio"
      ],
      "estimatedMinutes": 14,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    },
    {
      "title": "Code Profiling and Performance Monitoring",
      "content": "Identifying performance bottlenecks requires proper profiling tools. Learn to measure, analyze, and optimize your code's performance systematically.",
      "codeExample": "import cProfile\nimport pstats\nimport time\nimport functools\nfrom line_profiler import LineProfiler\n\n# Basic timing decorator\ndef timer(func):\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        start_time = time.perf_counter()\n        result = func(*args, **kwargs)\n        end_time = time.perf_counter()\n        print(f\"{func.__name__} took {end_time - start_time:.6f} seconds\")\n        return result\n    return wrapper\n\n# Performance monitoring class\nclass PerformanceMonitor:\n    def __init__(self):\n        self.timings = {}\n        self.call_counts = {}\n    \n    def time_function(self, func_name):\n        def decorator(func):\n            @functools.wraps(func)\n            def wrapper(*args, **kwargs):\n                start_time = time.perf_counter()\n                result = func(*args, **kwargs)\n                end_time = time.perf_counter()\n                \n                execution_time = end_time - start_time\n                \n                if func_name not in self.timings:\n                    self.timings[func_name] = []\n                    self.call_counts[func_name] = 0\n                \n                self.timings[func_name].append(execution_time)\n                self.call_counts[func_name] += 1\n                \n                return result\n            return wrapper\n        return decorator\n    \n    def get_stats(self):\n        stats = {}\n        for func_name, times in self.timings.items():\n            stats[func_name] = {\n                'total_time': sum(times),\n                'average_time': sum(times) / len(times),\n                'min_time': min(times),\n                'max_time': max(times),\n                'call_count': self.call_counts[func_name]\n            }\n        return stats\n    \n    def print_stats(self):\n        print(\"\\nPerformance Statistics:\")\n        print(\"-\" * 60)\n        for func_name, stats in self.get_stats().items():\n            print(f\"Function: {func_name}\")\n            print(f\"  Total time: {stats['total_time']:.6f}s\")\n            print(f\"  Average time: {stats['average_time']:.6f}s\")\n            print(f\"  Min time: {stats['min_time']:.6f}s\")\n            print(f\"  Max time: {stats['max_time']:.6f}s\")\n            print(f\"  Call count: {stats['call_count']}\")\n            print()\n\n# Example usage of performance monitor\nmonitor = PerformanceMonitor()\n\n@monitor.time_function(\"data_processing\")\n@timer\ndef process_data(data):\n    # Simulate data processing\n    result = []\n    for item in data:\n        result.append(item * 2 + 1)\n    return result\n\n@monitor.time_function(\"data_analysis\")\n@timer\ndef analyze_data(data):\n    # Simulate data analysis\n    return {\n        'sum': sum(data),\n        'avg': sum(data) / len(data),\n        'max': max(data),\n        'min': min(data)\n    }\n\n# cProfile usage\ndef profile_with_cprofile():\n    def slow_function():\n        # Simulate slow operations\n        time.sleep(0.1)\n        return sum(i*i for i in range(10000))\n    \n    def another_slow_function():\n        time.sleep(0.05)\n        return [i for i in range(5000) if i % 2 == 0]\n    \n    def main_function():\n        result1 = slow_function()\n        result2 = another_slow_function()\n        return result1, len(result2)\n    \n    # Profile the code\n    profiler = cProfile.Profile()\n    profiler.enable()\n    \n    result = main_function()\n    \n    profiler.disable()\n    \n    # Analyze results\n    stats = pstats.Stats(profiler)\n    stats.sort_stats('cumulative')\n    stats.print_stats(10)  # Top 10 functions\n    \n    return result\n\n# Memory profiling\nimport tracemalloc\n\nclass MemoryProfiler:\n    def __init__(self):\n        self.snapshots = []\n    \n    def start(self):\n        tracemalloc.start()\n    \n    def take_snapshot(self, label):\n        snapshot = tracemalloc.take_snapshot()\n        self.snapshots.append((label, snapshot))\n    \n    def compare_snapshots(self, label1, label2):\n        snap1 = None\n        snap2 = None\n        \n        for label, snapshot in self.snapshots:\n            if label == label1:\n                snap1 = snapshot\n            elif label == label2:\n                snap2 = snapshot\n        \n        if snap1 and snap2:\n            top_stats = snap2.compare_to(snap1, 'lineno')\n            print(f\"\\nMemory comparison: {label1} -> {label2}\")\n            print(\"Top 10 differences:\")\n            for stat in top_stats[:10]:\n                print(stat)\n    \n    def print_current_usage(self):\n        current, peak = tracemalloc.get_traced_memory()\n        print(f\"Current memory usage: {current / 1024 / 1024:.2f} MB\")\n        print(f\"Peak memory usage: {peak / 1024 / 1024:.2f} MB\")\n\n# Line profiling (requires line_profiler package)\ndef line_profiling_example():\n    profiler = LineProfiler()\n    \n    @profiler\n    def function_to_profile():\n        # This function will be profiled line by line\n        data = []\n        for i in range(1000):\n            data.append(i * 2)  # Line 1\n        \n        result = sum(data)  # Line 2\n        \n        processed = []\n        for item in data:  # Line 3\n            if item % 4 == 0:  # Line 4\n                processed.append(item)  # Line 5\n        \n        return result, len(processed)\n    \n    # Run the function\n    result = function_to_profile()\n    \n    # Print line-by-line profile\n    profiler.print_stats()\n    \n    return result\n\n# Context manager for profiling\nclass ProfileContext:\n    def __init__(self, name, enable_memory=True):\n        self.name = name\n        self.enable_memory = enable_memory\n        self.profiler = cProfile.Profile()\n    \n    def __enter__(self):\n        if self.enable_memory:\n            tracemalloc.start()\n        \n        self.start_time = time.perf_counter()\n        self.profiler.enable()\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.profiler.disable()\n        self.end_time = time.perf_counter()\n        \n        print(f\"\\nProfile results for: {self.name}\")\n        print(f\"Execution time: {self.end_time - self.start_time:.6f} seconds\")\n        \n        if self.enable_memory:\n            current, peak = tracemalloc.get_traced_memory()\n            print(f\"Peak memory usage: {peak / 1024 / 1024:.2f} MB\")\n            tracemalloc.stop()\n        \n        # Show top functions\n        stats = pstats.Stats(self.profiler)\n        stats.sort_stats('cumulative')\n        stats.print_stats(5)\n\n# Example usage of profiling tools\ndef demonstrate_profiling():\n    # Basic timing\n    data = list(range(100000))\n    \n    processed = process_data(data)\n    analysis = analyze_data(processed)\n    \n    # Show performance monitor stats\n    monitor.print_stats()\n    \n    # Memory profiling example\n    memory_profiler = MemoryProfiler()\n    memory_profiler.start()\n    \n    memory_profiler.take_snapshot(\"start\")\n    \n    # Create large data structure\n    large_data = [i * i for i in range(100000)]\n    \n    memory_profiler.take_snapshot(\"after_creation\")\n    \n    # Process data\n    processed_data = [x for x in large_data if x % 2 == 0]\n    \n    memory_profiler.take_snapshot(\"after_processing\")\n    \n    # Compare memory usage\n    memory_profiler.compare_snapshots(\"start\", \"after_creation\")\n    memory_profiler.compare_snapshots(\"after_creation\", \"after_processing\")\n    \n    # Context manager profiling\n    with ProfileContext(\"complex_operation\"):\n        result = complex_operation(1000)\n\ndef complex_operation(n):\n    # Simulate complex operation\n    data = []\n    for i in range(n):\n        for j in range(100):\n            data.append(i * j)\n    \n    return sum(data)\n\n# Performance regression testing\nclass PerformanceTest:\n    def __init__(self, tolerance=0.1):  # 10% tolerance\n        self.tolerance = tolerance\n        self.baselines = {}\n    \n    def set_baseline(self, test_name, func, *args, **kwargs):\n        start_time = time.perf_counter()\n        result = func(*args, **kwargs)\n        end_time = time.perf_counter()\n        \n        execution_time = end_time - start_time\n        self.baselines[test_name] = execution_time\n        \n        print(f\"Baseline set for {test_name}: {execution_time:.6f}s\")\n        return result\n    \n    def test_performance(self, test_name, func, *args, **kwargs):\n        if test_name not in self.baselines:\n            raise ValueError(f\"No baseline set for {test_name}\")\n        \n        start_time = time.perf_counter()\n        result = func(*args, **kwargs)\n        end_time = time.perf_counter()\n        \n        execution_time = end_time - start_time\n        baseline = self.baselines[test_name]\n        \n        ratio = execution_time / baseline\n        \n        if ratio > (1 + self.tolerance):\n            print(f\"PERFORMANCE REGRESSION in {test_name}!\")\n            print(f\"  Current: {execution_time:.6f}s\")\n            print(f\"  Baseline: {baseline:.6f}s\")\n            print(f\"  Ratio: {ratio:.2f}x slower\")\n        else:\n            print(f\"Performance OK for {test_name} (ratio: {ratio:.2f})\")\n        \n        return result\n\n# Usage example\nperf_test = PerformanceTest()\n\n# Set baseline\ntest_data = list(range(50000))\nperf_test.set_baseline(\"data_processing\", process_data, test_data)\n\n# Test performance (simulate after code changes)\nperf_test.test_performance(\"data_processing\", process_data, test_data)",
      "difficulty": "advanced",
      "categorySlug": "performance",
      "xpReward": 34,
      "tags": [
        "profiling",
        "monitoring",
        "performance-testing",
        "optimization"
      ],
      "estimatedMinutes": 15,
      "prerequisites": [],
      "relatedTips": [],
      "slug": null,
      "metaDescription": null,
      "metaKeywords": null,
      "socialImageUrl": null,
      "isActive": true,
      "publishDate": null
    }
  ]
}